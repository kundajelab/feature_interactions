{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainModels_PoissonLoss.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kundajelab/feature_interactions/blob/master/softplus_poisson/TrainModels_PoissonLoss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy6uELUUxZpx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d654dc4-ddf8-4a20-b045-522b891ccd1b"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikdAjY7YxzBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "10cd369e-3a9d-4e08-a343-ec1f45b61546"
      },
      "source": [
        "#download raw data\n",
        "!wget https://github.com/kundajelab/feature_interactions/raw/f761fd8/av/data/train_simulation.simdata.gz\n",
        "!wget https://github.com/kundajelab/feature_interactions/raw/f761fd8/av/data/train_neg_labels.txt.gz\n",
        "!wget https://github.com/kundajelab/feature_interactions/raw/f761fd8/av/data/train_pos_labels.txt.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-24 20:19:47--  https://github.com/kundajelab/feature_interactions/raw/f761fd8/av/data/train_simulation.simdata.gz\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/feature_interactions/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/train_simulation.simdata.gz [following]\n",
            "--2020-06-24 20:19:48--  https://raw.githubusercontent.com/kundajelab/feature_interactions/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/train_simulation.simdata.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2104123 (2.0M) [application/octet-stream]\n",
            "Saving to: ‘train_simulation.simdata.gz’\n",
            "\n",
            "train_simulation.si 100%[===================>]   2.01M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-06-24 20:19:48 (18.0 MB/s) - ‘train_simulation.simdata.gz’ saved [2104123/2104123]\n",
            "\n",
            "--2020-06-24 20:19:49--  https://github.com/kundajelab/feature_interactions/raw/f761fd8/av/data/train_neg_labels.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/feature_interactions/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/train_neg_labels.txt.gz [following]\n",
            "--2020-06-24 20:19:50--  https://raw.githubusercontent.com/kundajelab/feature_interactions/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/train_neg_labels.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 523531 (511K) [application/octet-stream]\n",
            "Saving to: ‘train_neg_labels.txt.gz’\n",
            "\n",
            "train_neg_labels.tx 100%[===================>] 511.26K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-06-24 20:19:50 (14.6 MB/s) - ‘train_neg_labels.txt.gz’ saved [523531/523531]\n",
            "\n",
            "--2020-06-24 20:19:51--  https://github.com/kundajelab/feature_interactions/raw/f761fd8/av/data/train_pos_labels.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/feature_interactions/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/train_pos_labels.txt.gz [following]\n",
            "--2020-06-24 20:19:52--  https://raw.githubusercontent.com/kundajelab/feature_interactions/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/train_pos_labels.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 518850 (507K) [application/octet-stream]\n",
            "Saving to: ‘train_pos_labels.txt.gz’\n",
            "\n",
            "train_pos_labels.tx 100%[===================>] 506.69K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-06-24 20:19:52 (10.0 MB/s) - ‘train_pos_labels.txt.gz’ saved [518850/518850]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ-uVDc2tO38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gunzip *.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhBwM80nyOa8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "46e07b4c-6bd1-4ab3-da2c-d06f28f7c9b7"
      },
      "source": [
        "!md5sum *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "md5sum: sample_data: Is a directory\n",
            "1f2ddf5f3a74e3db548c5d2180d29a45  train_neg_labels.txt\n",
            "262ca284f5f8676b16c8bf92047cfe70  train_pos_labels.txt\n",
            "fb82dd3c7dc4b53d34b4fd456394de42  train_simulation.simdata\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBtXarlUynn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "aa551755-2058-40bd-87b4-06ff65386928"
      },
      "source": [
        "!pip install simdna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: simdna in /usr/local/lib/python3.6/dist-packages (0.4.3.2)\n",
            "Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.6/dist-packages (from simdna) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from simdna) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from simdna) (1.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->simdna) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->simdna) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->simdna) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->simdna) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->simdna) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a-rv5JUzGhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import simdna\n",
        "from simdna import synthetic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDo9TZkQzKCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = synthetic.read_simdata_file(\"train_simulation.simdata\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMQPKHf1zL-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "#this is set up for 1d convolutions where examples\n",
        "#have dimensions (len, num_channels) \n",
        "#the channel axis is the axis for one-hot encoding.\n",
        "def one_hot_encode_along_channel_axis(sequence):\n",
        "    to_return = np.zeros((len(sequence),4), dtype=np.int8)\n",
        "    seq_to_one_hot_fill_in_array(zeros_array=to_return,\n",
        "                                 sequence=sequence, one_hot_axis=1)\n",
        "    return to_return\n",
        "\n",
        "\n",
        "def seq_to_one_hot_fill_in_array(zeros_array, sequence, one_hot_axis):\n",
        "    assert one_hot_axis==0 or one_hot_axis==1\n",
        "    if (one_hot_axis==0):\n",
        "        assert zeros_array.shape[1] == len(sequence)\n",
        "    elif (one_hot_axis==1): \n",
        "        assert zeros_array.shape[0] == len(sequence)\n",
        "    #will mutate zeros_array\n",
        "    for (i,char) in enumerate(sequence):\n",
        "        if (char==\"A\" or char==\"a\"):\n",
        "            char_idx = 0\n",
        "        elif (char==\"C\" or char==\"c\"):\n",
        "            char_idx = 1\n",
        "        elif (char==\"G\" or char==\"g\"):\n",
        "            char_idx = 2\n",
        "        elif (char==\"T\" or char==\"t\"):\n",
        "            char_idx = 3\n",
        "        elif (char==\"N\" or char==\"n\"):\n",
        "            continue #leave that pos as all 0's\n",
        "        else:\n",
        "            raise RuntimeError(\"Unsupported character: \"+str(char))\n",
        "        if (one_hot_axis==0):\n",
        "            zeros_array[char_idx,i] = 1\n",
        "        elif (one_hot_axis==1):\n",
        "            zeros_array[i,char_idx] = 1\n",
        "\n",
        "\n",
        "def read_labels_and_oracle(filename):\n",
        "  labels = np.array([float(x.split(\"\\t\")[0]) for\n",
        "                                          x in open(filename)])\n",
        "  oracle = np.array([float(x.split(\"\\t\")[1]) for\n",
        "                                          x in open(filename)])\n",
        "  return labels, oracle\n",
        "\n",
        "\n",
        "train_onehot_data = np.array([one_hot_encode_along_channel_axis(seq)\n",
        "                              for seq in train_data.sequences])\n",
        "\n",
        "train_pos_labels, train_pos_oracle =\\\n",
        "  read_labels_and_oracle(\"train_pos_labels.txt\")\n",
        "train_neg_labels, train_neg_oracle =\\\n",
        "  read_labels_and_oracle(\"train_neg_labels.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARK27HEQzqrn",
        "colab_type": "text"
      },
      "source": [
        "Train models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq1mcODizcry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define model architectures\n",
        "\n",
        "import keras\n",
        "import string\n",
        "import random\n",
        "import numpy as np\n",
        "from keras import backend as B\n",
        "\n",
        "def steeper_softplus():\n",
        "  return keras.layers.Activation(\"softplus\") #stick to standard for now\n",
        "  #log_scalefactor = np.log(10)\n",
        "  #return keras.layers.Lambda(lambda x: B.log(\n",
        "  #    1+B.exp(log_scalefactor*x))/log_scalefactor)\n",
        "\n",
        "\n",
        "#This model is a sanity check - it cannot learn interactions between motifs\n",
        "# except ones that are within the same receptive field. I am giving it a\n",
        "# wide receptive field on the first layer so it can likely learn the full\n",
        "# motif properly.\n",
        "def model_arch_sanitycheck(l1_reg):\n",
        "  inputs = keras.layers.Input(shape=(100,4))\n",
        "  conv = keras.layers.Conv1D(filters=64, kernel_size=25,\n",
        "                activation='sigmoid', padding='valid',\n",
        "                kernel_regularizer=keras.regularizers.l1(l1_reg))(inputs)\n",
        "  conv_out = keras.layers.GlobalAveragePooling1D()(conv)\n",
        "  #\n",
        "  predictions = steeper_softplus()(\n",
        "                 keras.layers.Dense(1, kernel_initializer=\"he_normal\",\n",
        "                 kernel_regularizer=keras.regularizers.l1(l1_reg))(conv_out))\n",
        "  model = keras.models.Model(inputs=inputs, outputs=predictions)\n",
        "  model.compile(optimizer='adam', loss=keras.losses.poisson,\n",
        "                metrics=[\"mse\"])\n",
        "  return model\n",
        "\n",
        "#This model can learn the ground truth via a skip connection, but also\n",
        "# has the capacity to learn interactions\n",
        "def model_arch_skipconn(l1_reg):\n",
        "  inputs = keras.layers.Input(shape=(100,4))\n",
        "  conv = keras.layers.Conv1D(filters=64, kernel_size=25,\n",
        "                activation='sigmoid', padding='valid',\n",
        "                kernel_regularizer=keras.regularizers.l1(l1_reg))(inputs)\n",
        "  conv_out = keras.layers.GlobalAveragePooling1D()(conv)\n",
        "  output_part1 = keras.layers.Dense(1,\n",
        "                 kernel_initializer=\"he_normal\",\n",
        "                 activation='linear',\n",
        "                 kernel_regularizer=keras.regularizers.l1(l1_reg))(conv_out)\n",
        "  dense_1 = keras.layers.Dense(64, activation='relu',\n",
        "                  kernel_initializer=\"he_normal\",\n",
        "                  kernel_regularizer=keras.regularizers.l1(l1_reg))(conv_out)\n",
        "  output_part2 = keras.layers.Dense(1,\n",
        "                 kernel_initializer=\"he_normal\",\n",
        "                 activation='linear',\n",
        "                 kernel_regularizer=keras.regularizers.l1(l1_reg))(dense_1)\n",
        "  combined_output = keras.layers.add([output_part1, output_part2])\n",
        "  predictions = steeper_softplus()(combined_output)\n",
        "  model = keras.models.Model(inputs=inputs, outputs=predictions)\n",
        "  model.compile(optimizer='adam', loss=keras.losses.poisson,\n",
        "                metrics=[\"mse\"])\n",
        "  return model\n",
        "\n",
        "\n",
        "#This model has one dense layer and no slip connection\n",
        "def model_arch_onelayer(l1_reg):\n",
        "  inputs = keras.layers.Input(shape=(100,4))\n",
        "  conv = keras.layers.Conv1D(filters=64, kernel_size=25,\n",
        "                activation='sigmoid', padding='valid',\n",
        "                kernel_regularizer=keras.regularizers.l1(l1_reg))(inputs)\n",
        "  conv_out = keras.layers.GlobalAveragePooling1D()(conv)\n",
        "  dense_1 = keras.layers.Dense(64, activation='relu', kernel_initializer=\"he_normal\",\n",
        "                  kernel_regularizer=keras.regularizers.l1(l1_reg))(conv_out)\n",
        "  predictions = steeper_softplus()(keras.layers.Dense(1,\n",
        "                 kernel_initializer=\"he_normal\",\n",
        "                 activation='linear',\n",
        "                 kernel_regularizer=keras.regularizers.l1(l1_reg))(dense_1))\n",
        "  model = keras.models.Model(inputs=inputs, outputs=predictions)\n",
        "  model.compile(optimizer='adam', loss=keras.losses.poisson,\n",
        "                metrics=[\"mse\"])\n",
        "  return model\n",
        "\n",
        "\n",
        "def train_and_save_model(model_constructor, prefix, X_train, y_train,\n",
        "                         X_valid, y_valid, seed):\n",
        "  \n",
        "  barcode = ''.join(random.choice(string.ascii_lowercase) for i in range(5))\n",
        "  np.random.seed(seed)\n",
        "  model = model_constructor()\n",
        "  save_filename = prefix+\"_\"+barcode+\".h5\"\n",
        "  print(\"Training model\", save_filename)\n",
        "  print(model.summary())\n",
        "  model.fit(x=X_train, y=y_train, batch_size=200,\n",
        "            epochs=1000,\n",
        "            validation_data=(X_valid, y_valid),\n",
        "            callbacks=[keras.callbacks.EarlyStopping(\n",
        "                        monitor='val_loss',\n",
        "                        patience=15,\n",
        "                        restore_best_weights=True)])\n",
        "  \n",
        "  print(\"Save file name\", save_filename)\n",
        "  model.save(save_filename)\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9GIVdNb2Zk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "40fd4cc7-23cc-498c-c215-b8b852f1e5fb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIreSCrC374p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ln -s /content/drive/My\\ Drive/colab_notebook_data/ ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I65o3pOoFO7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p colab_notebook_data/feature_interactions/trained_models/poissonloss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxMH1hCHDAXb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5a20cde6-5423-4d0b-c8ff-2a6d07ea6d8e"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.hist(train_pos_labels, density=True, bins=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ee4yVMX3ISx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba68ce8c-134d-4752-eda1-dab16eac72bd"
      },
      "source": [
        "#train the models\n",
        "\n",
        "indices_train = np.arange(0, int(0.8 * train_onehot_data.shape[0]))\n",
        "indices_valid = np.arange(int(0.8 * train_onehot_data.shape[0]),\n",
        "                              train_onehot_data.shape[0])\n",
        "\n",
        "SAVEDIR = \"colab_notebook_data/feature_interactions/trained_models/poissonloss\"\n",
        "\n",
        "for seed in [100, 200, 300, 400, 500]:\n",
        "  for l1_reg in [0.0, 0.00001, 0.0001]:\n",
        "    for model_constructor, archname in [(model_arch_sanitycheck, 'sanitycheck'),\n",
        "                                        (model_arch_skipconn, 'skipconn'),\n",
        "                                        (model_arch_onelayer, 'onelayer')]:\n",
        "        train_and_save_model(\n",
        "            model_constructor=lambda: model_constructor(l1_reg),\n",
        "            prefix=(SAVEDIR+\"/poscontrol_model-\"+archname\n",
        "                    +\"_l1reg-\"+str(l1_reg)+\"_seed\"+str(seed)),\n",
        "            X_train=train_onehot_data[indices_train],\n",
        "            y_train=train_pos_labels[indices_train],\n",
        "            X_valid=train_onehot_data[indices_valid],\n",
        "            y_valid=train_pos_labels[indices_valid],\n",
        "            seed=seed) #vary the seed for initialization diversity\n",
        "        \n",
        "        train_and_save_model(\n",
        "            model_constructor=lambda: model_constructor(l1_reg),\n",
        "            prefix=(SAVEDIR+\"/negcontrol_model-\"+archname\n",
        "                    +\"_l1reg-\"+str(l1_reg)+\"_seed\"+str(seed)),\n",
        "            X_train=train_onehot_data[indices_train],\n",
        "            y_train=train_neg_labels[indices_train],\n",
        "            X_valid=train_onehot_data[indices_valid],\n",
        "            y_valid=train_neg_labels[indices_valid],\n",
        "            seed=seed) #vary the seed for initialization diversity\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 626/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -531.7143 - mse: 3577.8521 - val_loss: -531.2018 - val_mse: 3648.0208\n",
            "Epoch 627/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -531.7235 - mse: 3576.3904 - val_loss: -531.2068 - val_mse: 3652.2805\n",
            "Epoch 628/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -531.7318 - mse: 3575.1587 - val_loss: -531.2208 - val_mse: 3635.0420\n",
            "Epoch 629/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -531.7458 - mse: 3570.0664 - val_loss: -531.2171 - val_mse: 3657.4197\n",
            "Epoch 630/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -531.7517 - mse: 3571.7507 - val_loss: -531.2247 - val_mse: 3656.6721\n",
            "Epoch 631/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -531.7627 - mse: 3569.8228 - val_loss: -531.2407 - val_mse: 3647.7900\n",
            "Epoch 632/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -531.7757 - mse: 3567.4355 - val_loss: -531.2460 - val_mse: 3615.4707\n",
            "Epoch 633/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -531.7810 - mse: 3562.5012 - val_loss: -531.2611 - val_mse: 3642.9067\n",
            "Epoch 634/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -531.7950 - mse: 3561.3047 - val_loss: -531.2524 - val_mse: 3655.4231\n",
            "Epoch 635/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -531.7995 - mse: 3561.7432 - val_loss: -531.2770 - val_mse: 3641.0759\n",
            "Epoch 636/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -531.8125 - mse: 3555.8235 - val_loss: -531.2747 - val_mse: 3648.7285\n",
            "Epoch 637/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -531.8196 - mse: 3556.9805 - val_loss: -531.2999 - val_mse: 3632.4651\n",
            "Epoch 638/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -531.8312 - mse: 3553.4033 - val_loss: -531.2982 - val_mse: 3640.7944\n",
            "Epoch 639/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -531.8401 - mse: 3551.2764 - val_loss: -531.3162 - val_mse: 3631.1135\n",
            "Epoch 640/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -531.8523 - mse: 3547.9756 - val_loss: -531.3097 - val_mse: 3641.1184\n",
            "Epoch 641/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -531.8594 - mse: 3549.8660 - val_loss: -531.3341 - val_mse: 3600.1724\n",
            "Epoch 642/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -531.8704 - mse: 3543.9409 - val_loss: -531.3480 - val_mse: 3618.9204\n",
            "Epoch 643/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -531.8791 - mse: 3542.8164 - val_loss: -531.3495 - val_mse: 3625.6245\n",
            "Epoch 644/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -531.8930 - mse: 3539.8276 - val_loss: -531.3487 - val_mse: 3630.9485\n",
            "Epoch 645/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -531.8958 - mse: 3540.9497 - val_loss: -531.3650 - val_mse: 3589.3020\n",
            "Epoch 646/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -531.9073 - mse: 3536.5879 - val_loss: -531.3821 - val_mse: 3612.8096\n",
            "Epoch 647/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -531.9198 - mse: 3534.9128 - val_loss: -531.3910 - val_mse: 3609.4668\n",
            "Epoch 648/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -531.9256 - mse: 3532.1345 - val_loss: -531.3874 - val_mse: 3620.1292\n",
            "Epoch 649/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -531.9358 - mse: 3530.4436 - val_loss: -531.3897 - val_mse: 3623.4976\n",
            "Epoch 650/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -531.9409 - mse: 3532.3748 - val_loss: -531.4200 - val_mse: 3600.5249\n",
            "Epoch 651/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -531.9542 - mse: 3525.9575 - val_loss: -531.4300 - val_mse: 3597.1443\n",
            "Epoch 652/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -531.9640 - mse: 3523.9429 - val_loss: -531.4243 - val_mse: 3611.6687\n",
            "Epoch 653/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -531.9765 - mse: 3522.0957 - val_loss: -531.4166 - val_mse: 3621.2112\n",
            "Epoch 654/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -531.9770 - mse: 3525.2288 - val_loss: -531.4551 - val_mse: 3579.0183\n",
            "Epoch 655/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -531.9897 - mse: 3518.2505 - val_loss: -531.4441 - val_mse: 3610.3020\n",
            "Epoch 656/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -531.9958 - mse: 3519.2461 - val_loss: -531.4736 - val_mse: 3585.0652\n",
            "Epoch 657/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.0078 - mse: 3514.6516 - val_loss: -531.4803 - val_mse: 3586.4116\n",
            "Epoch 658/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.0186 - mse: 3513.2480 - val_loss: -531.4901 - val_mse: 3583.5708\n",
            "Epoch 659/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.0274 - mse: 3510.6365 - val_loss: -531.4986 - val_mse: 3572.0952\n",
            "Epoch 660/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.0373 - mse: 3509.9824 - val_loss: -531.5081 - val_mse: 3574.5237\n",
            "Epoch 661/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.0477 - mse: 3506.1653 - val_loss: -531.5160 - val_mse: 3568.3567\n",
            "Epoch 662/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.0553 - mse: 3505.7180 - val_loss: -531.5256 - val_mse: 3572.8933\n",
            "Epoch 663/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.0657 - mse: 3502.8748 - val_loss: -531.5336 - val_mse: 3569.9993\n",
            "Epoch 664/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.0703 - mse: 3502.7017 - val_loss: -531.5426 - val_mse: 3567.5715\n",
            "Epoch 665/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.0821 - mse: 3498.8552 - val_loss: -531.5509 - val_mse: 3564.4575\n",
            "Epoch 666/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.0916 - mse: 3498.1953 - val_loss: -531.5534 - val_mse: 3574.6121\n",
            "Epoch 667/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.1010 - mse: 3495.4055 - val_loss: -531.5669 - val_mse: 3557.9875\n",
            "Epoch 668/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.1082 - mse: 3493.3232 - val_loss: -531.5580 - val_mse: 3581.6443\n",
            "Epoch 669/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.1186 - mse: 3493.4363 - val_loss: -531.5764 - val_mse: 3570.5415\n",
            "Epoch 670/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.1248 - mse: 3490.6887 - val_loss: -531.5912 - val_mse: 3557.0525\n",
            "Epoch 671/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.1364 - mse: 3487.9551 - val_loss: -531.5990 - val_mse: 3552.8792\n",
            "Epoch 672/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.1444 - mse: 3484.7964 - val_loss: -531.6061 - val_mse: 3558.1929\n",
            "Epoch 673/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.1484 - mse: 3486.7607 - val_loss: -531.6082 - val_mse: 3537.8140\n",
            "Epoch 674/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.1584 - mse: 3483.7983 - val_loss: -531.6238 - val_mse: 3549.6128\n",
            "Epoch 675/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -532.1684 - mse: 3481.4963 - val_loss: -531.6234 - val_mse: 3561.1189\n",
            "Epoch 676/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.1785 - mse: 3478.9429 - val_loss: -531.6302 - val_mse: 3560.8108\n",
            "Epoch 677/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.1878 - mse: 3478.0032 - val_loss: -531.6482 - val_mse: 3545.7207\n",
            "Epoch 678/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.1905 - mse: 3476.8037 - val_loss: -531.6557 - val_mse: 3537.9016\n",
            "Epoch 679/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.2055 - mse: 3471.9775 - val_loss: -531.6638 - val_mse: 3541.2412\n",
            "Epoch 680/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.2136 - mse: 3471.5708 - val_loss: -531.6667 - val_mse: 3548.5488\n",
            "Epoch 681/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -532.2209 - mse: 3470.1721 - val_loss: -531.6723 - val_mse: 3523.0684\n",
            "Epoch 682/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.2288 - mse: 3468.2839 - val_loss: -531.6852 - val_mse: 3540.2681\n",
            "Epoch 683/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.2358 - mse: 3467.2583 - val_loss: -531.6934 - val_mse: 3538.7681\n",
            "Epoch 684/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.2426 - mse: 3462.2593 - val_loss: -531.6792 - val_mse: 3557.5828\n",
            "Epoch 685/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.2526 - mse: 3466.1201 - val_loss: -531.7109 - val_mse: 3530.9895\n",
            "Epoch 686/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.2598 - mse: 3460.4951 - val_loss: -531.7102 - val_mse: 3541.1235\n",
            "Epoch 687/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.2728 - mse: 3460.0012 - val_loss: -531.7171 - val_mse: 3540.0515\n",
            "Epoch 688/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.2776 - mse: 3456.8372 - val_loss: -531.7029 - val_mse: 3554.5652\n",
            "Epoch 689/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.2903 - mse: 3456.9956 - val_loss: -531.7192 - val_mse: 3503.5493\n",
            "Epoch 690/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.2940 - mse: 3454.7131 - val_loss: -531.7483 - val_mse: 3522.2480\n",
            "Epoch 691/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.3057 - mse: 3451.2305 - val_loss: -531.7567 - val_mse: 3516.4299\n",
            "Epoch 692/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.3096 - mse: 3451.8672 - val_loss: -531.7621 - val_mse: 3522.2852\n",
            "Epoch 693/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.3175 - mse: 3447.9851 - val_loss: -531.7611 - val_mse: 3530.8965\n",
            "Epoch 694/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.3297 - mse: 3448.3904 - val_loss: -531.7777 - val_mse: 3506.8088\n",
            "Epoch 695/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.3366 - mse: 3443.5464 - val_loss: -531.7694 - val_mse: 3531.8020\n",
            "Epoch 696/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.3442 - mse: 3446.4236 - val_loss: -531.7872 - val_mse: 3499.3665\n",
            "Epoch 697/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.3543 - mse: 3441.2180 - val_loss: -531.8010 - val_mse: 3505.8601\n",
            "Epoch 698/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.3632 - mse: 3438.9175 - val_loss: -531.7984 - val_mse: 3520.7900\n",
            "Epoch 699/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.3701 - mse: 3439.1819 - val_loss: -531.8153 - val_mse: 3508.5295\n",
            "Epoch 700/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.3773 - mse: 3435.6628 - val_loss: -531.8133 - val_mse: 3518.8660\n",
            "Epoch 701/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.3854 - mse: 3434.9092 - val_loss: -531.8273 - val_mse: 3510.0803\n",
            "Epoch 702/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.3922 - mse: 3434.9944 - val_loss: -531.8375 - val_mse: 3501.1672\n",
            "Epoch 703/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.3990 - mse: 3430.5425 - val_loss: -531.8430 - val_mse: 3505.7595\n",
            "Epoch 704/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.4120 - mse: 3430.6299 - val_loss: -531.8506 - val_mse: 3488.0127\n",
            "Epoch 705/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -532.4176 - mse: 3425.6123 - val_loss: -531.8590 - val_mse: 3497.5835\n",
            "Epoch 706/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.4267 - mse: 3428.8025 - val_loss: -531.8570 - val_mse: 3479.2224\n",
            "Epoch 707/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -532.4343 - mse: 3422.5061 - val_loss: -531.8733 - val_mse: 3495.4949\n",
            "Epoch 708/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -532.4416 - mse: 3422.5017 - val_loss: -531.8822 - val_mse: 3490.9175\n",
            "Epoch 709/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -532.4510 - mse: 3422.7417 - val_loss: -531.8873 - val_mse: 3491.6609\n",
            "Epoch 710/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -532.4570 - mse: 3418.6829 - val_loss: -531.8961 - val_mse: 3482.6567\n",
            "Epoch 711/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -532.4657 - mse: 3418.8245 - val_loss: -531.9028 - val_mse: 3482.5452\n",
            "Epoch 712/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -532.4735 - mse: 3415.7532 - val_loss: -531.9102 - val_mse: 3483.3352\n",
            "Epoch 713/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.4793 - mse: 3414.2759 - val_loss: -531.9020 - val_mse: 3500.6179\n",
            "Epoch 714/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -532.4897 - mse: 3413.2380 - val_loss: -531.9248 - val_mse: 3477.8916\n",
            "Epoch 715/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -532.4964 - mse: 3411.8489 - val_loss: -531.8675 - val_mse: 3524.6160\n",
            "Epoch 716/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -532.5025 - mse: 3410.6672 - val_loss: -531.9270 - val_mse: 3492.6155\n",
            "Epoch 717/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -532.5119 - mse: 3409.5676 - val_loss: -531.9425 - val_mse: 3481.8115\n",
            "Epoch 718/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -532.5196 - mse: 3406.3955 - val_loss: -531.9470 - val_mse: 3482.9312\n",
            "Epoch 719/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -532.5298 - mse: 3404.3853 - val_loss: -531.9599 - val_mse: 3473.1504\n",
            "Epoch 720/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.5396 - mse: 3402.4485 - val_loss: -531.9605 - val_mse: 3481.1221\n",
            "Epoch 721/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.5433 - mse: 3401.5596 - val_loss: -531.9710 - val_mse: 3475.8652\n",
            "Epoch 722/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.5514 - mse: 3400.1121 - val_loss: -531.9797 - val_mse: 3471.5527\n",
            "Epoch 723/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.5615 - mse: 3397.7317 - val_loss: -531.9822 - val_mse: 3475.1812\n",
            "Epoch 724/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.5665 - mse: 3396.4211 - val_loss: -531.9948 - val_mse: 3464.8740\n",
            "Epoch 725/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.5744 - mse: 3394.2908 - val_loss: -531.9997 - val_mse: 3468.0740\n",
            "Epoch 726/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.5842 - mse: 3393.9355 - val_loss: -532.0062 - val_mse: 3451.3308\n",
            "Epoch 727/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.5894 - mse: 3390.2903 - val_loss: -531.9787 - val_mse: 3490.1953\n",
            "Epoch 728/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.5964 - mse: 3391.1924 - val_loss: -532.0166 - val_mse: 3466.2185\n",
            "Epoch 729/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.6045 - mse: 3387.9529 - val_loss: -532.0264 - val_mse: 3461.4409\n",
            "Epoch 730/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.6131 - mse: 3387.1013 - val_loss: -532.0194 - val_mse: 3472.6599\n",
            "Epoch 731/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.6195 - mse: 3384.8821 - val_loss: -532.0207 - val_mse: 3474.3477\n",
            "Epoch 732/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.6241 - mse: 3386.9619 - val_loss: -532.0481 - val_mse: 3454.5332\n",
            "Epoch 733/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.6334 - mse: 3381.2896 - val_loss: -532.0548 - val_mse: 3441.2625\n",
            "Epoch 734/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.6439 - mse: 3380.0784 - val_loss: -532.0492 - val_mse: 3465.1692\n",
            "Epoch 735/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.6529 - mse: 3378.1399 - val_loss: -532.0660 - val_mse: 3453.2375\n",
            "Epoch 736/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.6605 - mse: 3378.2400 - val_loss: -532.0768 - val_mse: 3443.1741\n",
            "Epoch 737/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.6627 - mse: 3376.4651 - val_loss: -532.0672 - val_mse: 3427.0947\n",
            "Epoch 738/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.6776 - mse: 3371.8943 - val_loss: -532.0592 - val_mse: 3468.9736\n",
            "Epoch 739/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.6790 - mse: 3374.8269 - val_loss: -532.0947 - val_mse: 3443.1421\n",
            "Epoch 740/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.6901 - mse: 3370.7195 - val_loss: -532.0959 - val_mse: 3425.1453\n",
            "Epoch 741/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.6947 - mse: 3368.3848 - val_loss: -532.0962 - val_mse: 3452.9204\n",
            "Epoch 742/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.7035 - mse: 3368.0540 - val_loss: -532.1138 - val_mse: 3426.2639\n",
            "Epoch 743/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.7117 - mse: 3366.0044 - val_loss: -532.1221 - val_mse: 3435.9844\n",
            "Epoch 744/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.7207 - mse: 3363.5105 - val_loss: -532.1247 - val_mse: 3440.2300\n",
            "Epoch 745/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.7261 - mse: 3363.8364 - val_loss: -532.1357 - val_mse: 3425.0632\n",
            "Epoch 746/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.7382 - mse: 3360.1743 - val_loss: -532.1414 - val_mse: 3431.8345\n",
            "Epoch 747/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.7423 - mse: 3359.9104 - val_loss: -532.1361 - val_mse: 3442.3784\n",
            "Epoch 748/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.7516 - mse: 3358.7705 - val_loss: -532.1311 - val_mse: 3448.4529\n",
            "Epoch 749/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.7554 - mse: 3357.0952 - val_loss: -532.1611 - val_mse: 3422.3196\n",
            "Epoch 750/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.7659 - mse: 3354.5669 - val_loss: -532.1675 - val_mse: 3425.8735\n",
            "Epoch 751/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.7742 - mse: 3353.4792 - val_loss: -532.1657 - val_mse: 3432.5432\n",
            "Epoch 752/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.7823 - mse: 3351.6946 - val_loss: -532.1821 - val_mse: 3418.1641\n",
            "Epoch 753/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.7869 - mse: 3349.8169 - val_loss: -532.1726 - val_mse: 3435.0107\n",
            "Epoch 754/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.7973 - mse: 3348.7188 - val_loss: -532.1917 - val_mse: 3421.5349\n",
            "Epoch 755/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.8102 - mse: 3346.0349 - val_loss: -532.1766 - val_mse: 3436.8516\n",
            "Epoch 756/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.8141 - mse: 3343.4561 - val_loss: -532.1875 - val_mse: 3431.7769\n",
            "Epoch 757/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.8226 - mse: 3343.9072 - val_loss: -532.2030 - val_mse: 3425.1467\n",
            "Epoch 758/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.8287 - mse: 3342.1636 - val_loss: -532.1912 - val_mse: 3435.2468\n",
            "Epoch 759/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.8342 - mse: 3339.2390 - val_loss: -532.2249 - val_mse: 3414.7432\n",
            "Epoch 760/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.8415 - mse: 3338.2898 - val_loss: -532.2292 - val_mse: 3415.2664\n",
            "Epoch 761/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.8518 - mse: 3337.4954 - val_loss: -532.2412 - val_mse: 3406.2175\n",
            "Epoch 762/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.8562 - mse: 3335.8801 - val_loss: -532.2468 - val_mse: 3399.6340\n",
            "Epoch 763/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.8662 - mse: 3334.2493 - val_loss: -532.2535 - val_mse: 3394.1428\n",
            "Epoch 764/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.8725 - mse: 3332.1729 - val_loss: -532.2615 - val_mse: 3396.0833\n",
            "Epoch 765/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.8805 - mse: 3329.6213 - val_loss: -532.2491 - val_mse: 3416.6392\n",
            "Epoch 766/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.8921 - mse: 3328.9097 - val_loss: -532.2721 - val_mse: 3399.4260\n",
            "Epoch 767/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.9003 - mse: 3327.0215 - val_loss: -532.2745 - val_mse: 3404.0056\n",
            "Epoch 768/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.9100 - mse: 3323.9800 - val_loss: -532.2827 - val_mse: 3401.4895\n",
            "Epoch 769/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.9174 - mse: 3324.2795 - val_loss: -532.2944 - val_mse: 3390.6057\n",
            "Epoch 770/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.9188 - mse: 3322.7107 - val_loss: -532.2800 - val_mse: 3409.9417\n",
            "Epoch 771/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.9306 - mse: 3320.3542 - val_loss: -532.3069 - val_mse: 3385.8589\n",
            "Epoch 772/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.9397 - mse: 3318.6614 - val_loss: -532.2994 - val_mse: 3373.7363\n",
            "Epoch 773/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.9433 - mse: 3318.4199 - val_loss: -532.3203 - val_mse: 3384.6453\n",
            "Epoch 774/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.9532 - mse: 3315.5720 - val_loss: -532.3277 - val_mse: 3377.9724\n",
            "Epoch 775/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.9619 - mse: 3313.4094 - val_loss: -532.3349 - val_mse: 3378.5017\n",
            "Epoch 776/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.9717 - mse: 3311.2417 - val_loss: -532.3387 - val_mse: 3383.1465\n",
            "Epoch 777/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.9794 - mse: 3309.8452 - val_loss: -532.3378 - val_mse: 3391.5684\n",
            "Epoch 778/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -532.9878 - mse: 3308.5537 - val_loss: -532.3442 - val_mse: 3389.8232\n",
            "Epoch 779/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -532.9951 - mse: 3307.4561 - val_loss: -532.3499 - val_mse: 3388.7771\n",
            "Epoch 780/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.0019 - mse: 3304.6924 - val_loss: -532.3671 - val_mse: 3378.4983\n",
            "Epoch 781/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.0099 - mse: 3303.8088 - val_loss: -532.3671 - val_mse: 3382.5112\n",
            "Epoch 782/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.0172 - mse: 3302.9250 - val_loss: -532.3824 - val_mse: 3366.3228\n",
            "Epoch 783/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.0261 - mse: 3300.7354 - val_loss: -532.3849 - val_mse: 3374.2212\n",
            "Epoch 784/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.0318 - mse: 3298.5032 - val_loss: -532.3954 - val_mse: 3366.6848\n",
            "Epoch 785/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.0410 - mse: 3297.6938 - val_loss: -532.3869 - val_mse: 3381.2913\n",
            "Epoch 786/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.0484 - mse: 3296.2598 - val_loss: -532.4043 - val_mse: 3369.9888\n",
            "Epoch 787/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.0560 - mse: 3294.0293 - val_loss: -532.4043 - val_mse: 3374.1003\n",
            "Epoch 788/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.0634 - mse: 3291.6602 - val_loss: -532.4137 - val_mse: 3369.9631\n",
            "Epoch 789/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.0719 - mse: 3291.5845 - val_loss: -532.4276 - val_mse: 3359.0225\n",
            "Epoch 790/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.0799 - mse: 3288.2119 - val_loss: -532.4215 - val_mse: 3373.0576\n",
            "Epoch 791/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.0892 - mse: 3287.2336 - val_loss: -532.4197 - val_mse: 3374.8577\n",
            "Epoch 792/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.0958 - mse: 3286.7126 - val_loss: -532.4470 - val_mse: 3351.3860\n",
            "Epoch 793/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.1035 - mse: 3283.8010 - val_loss: -532.4479 - val_mse: 3358.3577\n",
            "Epoch 794/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.1097 - mse: 3281.9363 - val_loss: -532.4390 - val_mse: 3371.7588\n",
            "Epoch 795/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.1195 - mse: 3281.8274 - val_loss: -532.4668 - val_mse: 3348.5310\n",
            "Epoch 796/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.1249 - mse: 3277.7820 - val_loss: -532.4316 - val_mse: 3379.3376\n",
            "Epoch 797/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.1317 - mse: 3280.3181 - val_loss: -532.4765 - val_mse: 3349.7529\n",
            "Epoch 798/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.1407 - mse: 3277.6443 - val_loss: -532.4840 - val_mse: 3344.7139\n",
            "Epoch 799/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.1454 - mse: 3273.7097 - val_loss: -532.4600 - val_mse: 3368.4749\n",
            "Epoch 800/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.1511 - mse: 3274.0657 - val_loss: -532.4943 - val_mse: 3346.5044\n",
            "Epoch 801/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.1585 - mse: 3272.2561 - val_loss: -532.4941 - val_mse: 3352.6538\n",
            "Epoch 802/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.1680 - mse: 3270.7334 - val_loss: -532.5007 - val_mse: 3350.5193\n",
            "Epoch 803/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.1779 - mse: 3267.2090 - val_loss: -532.4483 - val_mse: 3379.7200\n",
            "Epoch 804/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.1832 - mse: 3270.3137 - val_loss: -532.5045 - val_mse: 3323.3813\n",
            "Epoch 805/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.1882 - mse: 3266.1638 - val_loss: -532.5249 - val_mse: 3338.7876\n",
            "Epoch 806/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.2002 - mse: 3264.0413 - val_loss: -532.5234 - val_mse: 3345.3877\n",
            "Epoch 807/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.2101 - mse: 3261.8845 - val_loss: -532.5360 - val_mse: 3335.6738\n",
            "Epoch 808/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.2158 - mse: 3262.4688 - val_loss: -532.5372 - val_mse: 3321.1304\n",
            "Epoch 809/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.2146 - mse: 3258.5220 - val_loss: -532.5058 - val_mse: 3360.2937\n",
            "Epoch 810/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.2284 - mse: 3258.9443 - val_loss: -532.5486 - val_mse: 3338.0564\n",
            "Epoch 811/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.2343 - mse: 3256.6643 - val_loss: -532.5622 - val_mse: 3329.1843\n",
            "Epoch 812/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.2406 - mse: 3255.8103 - val_loss: -532.5542 - val_mse: 3339.5901\n",
            "Epoch 813/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.2513 - mse: 3252.0647 - val_loss: -532.5656 - val_mse: 3332.0105\n",
            "Epoch 814/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.2582 - mse: 3252.1931 - val_loss: -532.5798 - val_mse: 3321.1895\n",
            "Epoch 815/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.2637 - mse: 3250.4414 - val_loss: -532.5828 - val_mse: 3325.1299\n",
            "Epoch 816/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.2698 - mse: 3250.1299 - val_loss: -532.5919 - val_mse: 3321.7439\n",
            "Epoch 817/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.2792 - mse: 3247.2751 - val_loss: -532.5808 - val_mse: 3333.6306\n",
            "Epoch 818/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.2829 - mse: 3246.4319 - val_loss: -532.5966 - val_mse: 3325.8718\n",
            "Epoch 819/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.2916 - mse: 3244.5535 - val_loss: -532.6122 - val_mse: 3313.2051\n",
            "Epoch 820/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.2991 - mse: 3243.3862 - val_loss: -532.6094 - val_mse: 3320.6362\n",
            "Epoch 821/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.3045 - mse: 3241.6787 - val_loss: -532.6112 - val_mse: 3323.2375\n",
            "Epoch 822/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.3149 - mse: 3241.3403 - val_loss: -532.6269 - val_mse: 3313.7170\n",
            "Epoch 823/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.3174 - mse: 3238.9338 - val_loss: -532.6185 - val_mse: 3323.1602\n",
            "Epoch 824/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.3272 - mse: 3236.5347 - val_loss: -532.6183 - val_mse: 3325.9336\n",
            "Epoch 825/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.3321 - mse: 3236.0640 - val_loss: -532.5862 - val_mse: 3343.8081\n",
            "Epoch 826/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.3389 - mse: 3236.3779 - val_loss: -532.6509 - val_mse: 3306.2722\n",
            "Epoch 827/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.3475 - mse: 3232.9189 - val_loss: -532.6309 - val_mse: 3323.6797\n",
            "Epoch 828/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.3556 - mse: 3230.2097 - val_loss: -532.6479 - val_mse: 3317.3040\n",
            "Epoch 829/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.3652 - mse: 3230.4302 - val_loss: -532.6667 - val_mse: 3304.2036\n",
            "Epoch 830/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.3620 - mse: 3229.2397 - val_loss: -532.6696 - val_mse: 3306.5730\n",
            "Epoch 831/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.3790 - mse: 3227.1228 - val_loss: -532.6789 - val_mse: 3289.8054\n",
            "Epoch 832/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.3813 - mse: 3225.7688 - val_loss: -532.6805 - val_mse: 3302.8665\n",
            "Epoch 833/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.3885 - mse: 3223.8943 - val_loss: -532.6908 - val_mse: 3298.2859\n",
            "Epoch 834/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.3971 - mse: 3222.3167 - val_loss: -532.6935 - val_mse: 3301.0725\n",
            "Epoch 835/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.4035 - mse: 3221.1658 - val_loss: -532.6999 - val_mse: 3298.4517\n",
            "Epoch 836/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.4117 - mse: 3218.8762 - val_loss: -532.7008 - val_mse: 3301.0476\n",
            "Epoch 837/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.4218 - mse: 3218.0901 - val_loss: -532.7030 - val_mse: 3303.0183\n",
            "Epoch 838/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.4266 - mse: 3217.6367 - val_loss: -532.7232 - val_mse: 3282.6113\n",
            "Epoch 839/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.4331 - mse: 3215.8586 - val_loss: -532.7287 - val_mse: 3284.6152\n",
            "Epoch 840/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.4377 - mse: 3213.2874 - val_loss: -532.7243 - val_mse: 3294.5205\n",
            "Epoch 841/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.4472 - mse: 3212.7620 - val_loss: -532.7355 - val_mse: 3289.1555\n",
            "Epoch 842/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.4557 - mse: 3210.2256 - val_loss: -532.7323 - val_mse: 3294.6677\n",
            "Epoch 843/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.4620 - mse: 3209.7930 - val_loss: -532.7463 - val_mse: 3287.8225\n",
            "Epoch 844/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.4650 - mse: 3207.8735 - val_loss: -532.7444 - val_mse: 3291.6321\n",
            "Epoch 845/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.4740 - mse: 3207.4717 - val_loss: -532.7636 - val_mse: 3276.7654\n",
            "Epoch 846/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.4823 - mse: 3204.0813 - val_loss: -532.7571 - val_mse: 3288.5017\n",
            "Epoch 847/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.4870 - mse: 3204.6726 - val_loss: -532.7714 - val_mse: 3278.5854\n",
            "Epoch 848/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.4947 - mse: 3201.2437 - val_loss: -532.7272 - val_mse: 3306.4148\n",
            "Epoch 849/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.4986 - mse: 3202.2002 - val_loss: -532.7777 - val_mse: 3280.6309\n",
            "Epoch 850/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.5055 - mse: 3200.8147 - val_loss: -532.7803 - val_mse: 3281.5110\n",
            "Epoch 851/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.5130 - mse: 3198.1956 - val_loss: -532.7997 - val_mse: 3269.7185\n",
            "Epoch 852/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.5205 - mse: 3197.4768 - val_loss: -532.7963 - val_mse: 3275.1980\n",
            "Epoch 853/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.5303 - mse: 3196.1841 - val_loss: -532.8079 - val_mse: 3260.3037\n",
            "Epoch 854/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.5352 - mse: 3192.5493 - val_loss: -532.7647 - val_mse: 3296.4419\n",
            "Epoch 855/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.5419 - mse: 3192.8723 - val_loss: -532.7871 - val_mse: 3286.1333\n",
            "Epoch 856/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.5488 - mse: 3191.5608 - val_loss: -532.8153 - val_mse: 3271.3916\n",
            "Epoch 857/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.5568 - mse: 3190.1746 - val_loss: -532.8307 - val_mse: 3256.4673\n",
            "Epoch 858/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.5612 - mse: 3188.3762 - val_loss: -532.8347 - val_mse: 3261.3413\n",
            "Epoch 859/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.5662 - mse: 3185.9541 - val_loss: -532.8379 - val_mse: 3261.6624\n",
            "Epoch 860/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.5664 - mse: 3187.8284 - val_loss: -532.8470 - val_mse: 3255.8726\n",
            "Epoch 861/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.5816 - mse: 3183.7637 - val_loss: -532.8244 - val_mse: 3276.0806\n",
            "Epoch 862/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.5894 - mse: 3184.3489 - val_loss: -532.8551 - val_mse: 3249.1167\n",
            "Epoch 863/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.5942 - mse: 3179.6746 - val_loss: -532.7789 - val_mse: 3298.2642\n",
            "Epoch 864/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.5994 - mse: 3181.1775 - val_loss: -532.8473 - val_mse: 3267.5923\n",
            "Epoch 865/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.6077 - mse: 3179.1321 - val_loss: -532.8670 - val_mse: 3257.6487\n",
            "Epoch 866/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.6148 - mse: 3177.9026 - val_loss: -532.8769 - val_mse: 3244.2632\n",
            "Epoch 867/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.6239 - mse: 3174.4915 - val_loss: -532.8449 - val_mse: 3272.7527\n",
            "Epoch 868/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.6266 - mse: 3174.9519 - val_loss: -532.8676 - val_mse: 3264.0222\n",
            "Epoch 869/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.6259 - mse: 3175.8132 - val_loss: -532.8921 - val_mse: 3243.5183\n",
            "Epoch 870/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.6410 - mse: 3171.0930 - val_loss: -532.8953 - val_mse: 3248.4062\n",
            "Epoch 871/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.6458 - mse: 3171.3940 - val_loss: -532.9023 - val_mse: 3237.4622\n",
            "Epoch 872/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.6532 - mse: 3169.3069 - val_loss: -532.9065 - val_mse: 3240.7065\n",
            "Epoch 873/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.6616 - mse: 3168.1853 - val_loss: -532.9129 - val_mse: 3234.2346\n",
            "Epoch 874/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.6695 - mse: 3164.8611 - val_loss: -532.8420 - val_mse: 3281.0005\n",
            "Epoch 875/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.6716 - mse: 3167.4292 - val_loss: -532.9221 - val_mse: 3240.9072\n",
            "Epoch 876/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.6794 - mse: 3163.0237 - val_loss: -532.9283 - val_mse: 3234.1921\n",
            "Epoch 877/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.6844 - mse: 3162.4592 - val_loss: -532.9108 - val_mse: 3252.4729\n",
            "Epoch 878/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.6909 - mse: 3161.3325 - val_loss: -532.9161 - val_mse: 3251.9648\n",
            "Epoch 879/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.6956 - mse: 3161.2891 - val_loss: -532.9182 - val_mse: 3251.2598\n",
            "Epoch 880/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.7030 - mse: 3159.3037 - val_loss: -532.9490 - val_mse: 3230.5500\n",
            "Epoch 881/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.7089 - mse: 3158.4102 - val_loss: -532.9375 - val_mse: 3244.3889\n",
            "Epoch 882/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.7203 - mse: 3155.7183 - val_loss: -532.9413 - val_mse: 3243.7083\n",
            "Epoch 883/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.7225 - mse: 3154.9216 - val_loss: -532.9535 - val_mse: 3237.1423\n",
            "Epoch 884/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.7291 - mse: 3151.7883 - val_loss: -532.9524 - val_mse: 3241.5759\n",
            "Epoch 885/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.7358 - mse: 3153.3784 - val_loss: -532.9729 - val_mse: 3227.4634\n",
            "Epoch 886/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.7418 - mse: 3149.9727 - val_loss: -532.9607 - val_mse: 3239.1917\n",
            "Epoch 887/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.7502 - mse: 3148.3000 - val_loss: -532.9254 - val_mse: 3257.0278\n",
            "Epoch 888/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.7546 - mse: 3149.2195 - val_loss: -532.9840 - val_mse: 3227.4839\n",
            "Epoch 889/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.7600 - mse: 3147.5439 - val_loss: -532.9879 - val_mse: 3229.7986\n",
            "Epoch 890/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.7662 - mse: 3145.9153 - val_loss: -533.0015 - val_mse: 3217.3975\n",
            "Epoch 891/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.7751 - mse: 3144.1575 - val_loss: -533.0050 - val_mse: 3210.1855\n",
            "Epoch 892/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.7839 - mse: 3142.2295 - val_loss: -533.0027 - val_mse: 3223.2405\n",
            "Epoch 893/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.7889 - mse: 3140.7139 - val_loss: -533.0044 - val_mse: 3226.7817\n",
            "Epoch 894/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.7930 - mse: 3139.6260 - val_loss: -532.9879 - val_mse: 3236.5842\n",
            "Epoch 895/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.7994 - mse: 3139.5012 - val_loss: -532.9909 - val_mse: 3236.3538\n",
            "Epoch 896/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.8025 - mse: 3139.3840 - val_loss: -533.0320 - val_mse: 3208.9221\n",
            "Epoch 897/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.8102 - mse: 3134.1235 - val_loss: -532.9978 - val_mse: 3235.1785\n",
            "Epoch 898/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.8203 - mse: 3136.3071 - val_loss: -533.0372 - val_mse: 3214.3772\n",
            "Epoch 899/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.8253 - mse: 3133.7029 - val_loss: -533.0163 - val_mse: 3229.5928\n",
            "Epoch 900/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.8261 - mse: 3134.4353 - val_loss: -533.0535 - val_mse: 3204.8413\n",
            "Epoch 901/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.8386 - mse: 3130.9570 - val_loss: -533.0592 - val_mse: 3205.4326\n",
            "Epoch 902/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.8455 - mse: 3128.7742 - val_loss: -533.0561 - val_mse: 3212.4077\n",
            "Epoch 903/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.8473 - mse: 3129.5513 - val_loss: -533.0609 - val_mse: 3211.0786\n",
            "Epoch 904/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.8534 - mse: 3127.7986 - val_loss: -533.0732 - val_mse: 3205.0938\n",
            "Epoch 905/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.8585 - mse: 3126.3594 - val_loss: -533.0738 - val_mse: 3205.6008\n",
            "Epoch 906/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.8658 - mse: 3126.9448 - val_loss: -533.0776 - val_mse: 3204.4258\n",
            "Epoch 907/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.8678 - mse: 3123.5391 - val_loss: -533.0660 - val_mse: 3215.9819\n",
            "Epoch 908/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.8786 - mse: 3122.2722 - val_loss: -533.0919 - val_mse: 3201.4622\n",
            "Epoch 909/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.8825 - mse: 3122.8269 - val_loss: -533.1000 - val_mse: 3194.8267\n",
            "Epoch 910/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.8890 - mse: 3119.2041 - val_loss: -533.0988 - val_mse: 3201.6245\n",
            "Epoch 911/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.8973 - mse: 3118.1902 - val_loss: -533.0877 - val_mse: 3210.0447\n",
            "Epoch 912/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.8972 - mse: 3119.1545 - val_loss: -533.0918 - val_mse: 3209.0652\n",
            "Epoch 913/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.9056 - mse: 3115.9355 - val_loss: -533.0901 - val_mse: 3211.0847\n",
            "Epoch 914/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.9091 - mse: 3116.4363 - val_loss: -533.0878 - val_mse: 3213.5767\n",
            "Epoch 915/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.9154 - mse: 3114.6597 - val_loss: -533.0938 - val_mse: 3211.2173\n",
            "Epoch 916/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.9172 - mse: 3115.1946 - val_loss: -533.1308 - val_mse: 3192.7637\n",
            "Epoch 917/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.9286 - mse: 3111.9951 - val_loss: -533.1421 - val_mse: 3182.7566\n",
            "Epoch 918/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.9323 - mse: 3112.0701 - val_loss: -533.1422 - val_mse: 3187.4316\n",
            "Epoch 919/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.9409 - mse: 3109.2991 - val_loss: -533.1473 - val_mse: 3187.0049\n",
            "Epoch 920/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.9402 - mse: 3109.9177 - val_loss: -533.1492 - val_mse: 3187.2937\n",
            "Epoch 921/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.9483 - mse: 3109.2427 - val_loss: -533.1582 - val_mse: 3176.7681\n",
            "Epoch 922/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.9536 - mse: 3106.8311 - val_loss: -533.1505 - val_mse: 3193.0801\n",
            "Epoch 923/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.9597 - mse: 3104.8506 - val_loss: -533.1510 - val_mse: 3193.3032\n",
            "Epoch 924/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.9622 - mse: 3106.0073 - val_loss: -533.1719 - val_mse: 3170.0063\n",
            "Epoch 925/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.9707 - mse: 3102.6907 - val_loss: -533.1770 - val_mse: 3180.8237\n",
            "Epoch 926/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.9774 - mse: 3101.7156 - val_loss: -533.1867 - val_mse: 3172.1377\n",
            "Epoch 927/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -533.9811 - mse: 3101.3530 - val_loss: -533.1747 - val_mse: 3187.9924\n",
            "Epoch 928/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.9899 - mse: 3101.2705 - val_loss: -533.1919 - val_mse: 3166.0024\n",
            "Epoch 929/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -533.9906 - mse: 3097.8933 - val_loss: -533.1598 - val_mse: 3195.9045\n",
            "Epoch 930/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.0005 - mse: 3097.2722 - val_loss: -533.1915 - val_mse: 3182.5327\n",
            "Epoch 931/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.0040 - mse: 3096.9160 - val_loss: -533.2115 - val_mse: 3166.3921\n",
            "Epoch 932/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.0092 - mse: 3095.5869 - val_loss: -533.1697 - val_mse: 3196.2258\n",
            "Epoch 933/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.0143 - mse: 3095.1360 - val_loss: -533.2167 - val_mse: 3171.1292\n",
            "Epoch 934/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.0199 - mse: 3093.0933 - val_loss: -533.1933 - val_mse: 3186.9199\n",
            "Epoch 935/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -534.0263 - mse: 3092.3418 - val_loss: -533.2266 - val_mse: 3169.1270\n",
            "Epoch 936/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.0290 - mse: 3090.9792 - val_loss: -533.2057 - val_mse: 3181.6655\n",
            "Epoch 937/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -534.0361 - mse: 3090.2334 - val_loss: -533.1763 - val_mse: 3196.1577\n",
            "Epoch 938/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.0416 - mse: 3090.0471 - val_loss: -533.2402 - val_mse: 3166.9485\n",
            "Epoch 939/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.0498 - mse: 3087.2605 - val_loss: -533.2464 - val_mse: 3162.1091\n",
            "Epoch 940/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.0498 - mse: 3086.7329 - val_loss: -533.2515 - val_mse: 3156.4971\n",
            "Epoch 941/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.0576 - mse: 3086.1055 - val_loss: -533.2431 - val_mse: 3168.6919\n",
            "Epoch 942/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.0625 - mse: 3084.2329 - val_loss: -533.2460 - val_mse: 3168.9580\n",
            "Epoch 943/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.0667 - mse: 3083.4976 - val_loss: -533.2628 - val_mse: 3159.4883\n",
            "Epoch 944/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.0732 - mse: 3083.0645 - val_loss: -533.2652 - val_mse: 3161.3843\n",
            "Epoch 945/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.0810 - mse: 3079.8176 - val_loss: -533.2501 - val_mse: 3171.9170\n",
            "Epoch 946/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.0855 - mse: 3080.3765 - val_loss: -533.2682 - val_mse: 3164.4106\n",
            "Epoch 947/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.0902 - mse: 3079.8818 - val_loss: -533.2858 - val_mse: 3151.0957\n",
            "Epoch 948/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.0961 - mse: 3077.0249 - val_loss: -533.2859 - val_mse: 3156.4746\n",
            "Epoch 949/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.0985 - mse: 3077.4648 - val_loss: -533.2631 - val_mse: 3169.9299\n",
            "Epoch 950/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.1034 - mse: 3074.4028 - val_loss: -533.2946 - val_mse: 3155.7544\n",
            "Epoch 951/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.1120 - mse: 3074.8579 - val_loss: -533.2633 - val_mse: 3171.6001\n",
            "Epoch 952/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.1155 - mse: 3075.2605 - val_loss: -533.3051 - val_mse: 3150.8315\n",
            "Epoch 953/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.1222 - mse: 3072.3716 - val_loss: -533.3144 - val_mse: 3138.9817\n",
            "Epoch 954/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.1257 - mse: 3070.3428 - val_loss: -533.3104 - val_mse: 3152.0493\n",
            "Epoch 955/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.1323 - mse: 3070.1184 - val_loss: -533.3255 - val_mse: 3140.6123\n",
            "Epoch 956/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.1333 - mse: 3070.1174 - val_loss: -533.3180 - val_mse: 3150.3196\n",
            "Epoch 957/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.1427 - mse: 3067.8645 - val_loss: -533.3231 - val_mse: 3150.2729\n",
            "Epoch 958/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.1497 - mse: 3067.1858 - val_loss: -533.3226 - val_mse: 3151.2166\n",
            "Epoch 959/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.1515 - mse: 3066.8464 - val_loss: -533.3391 - val_mse: 3140.2024\n",
            "Epoch 960/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.1591 - mse: 3064.3965 - val_loss: -533.3352 - val_mse: 3147.2483\n",
            "Epoch 961/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.1641 - mse: 3063.2131 - val_loss: -533.3412 - val_mse: 3146.1338\n",
            "Epoch 962/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.1697 - mse: 3062.1311 - val_loss: -533.2906 - val_mse: 3169.3896\n",
            "Epoch 963/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.1718 - mse: 3063.3147 - val_loss: -533.3608 - val_mse: 3134.4602\n",
            "Epoch 964/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.1779 - mse: 3060.1584 - val_loss: -533.3599 - val_mse: 3137.2595\n",
            "Epoch 965/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.1812 - mse: 3060.7166 - val_loss: -533.3387 - val_mse: 3151.2708\n",
            "Epoch 966/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.1899 - mse: 3058.4551 - val_loss: -533.3615 - val_mse: 3142.4932\n",
            "Epoch 967/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.1941 - mse: 3058.2771 - val_loss: -533.3661 - val_mse: 3139.0771\n",
            "Epoch 968/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.1985 - mse: 3055.8726 - val_loss: -533.3735 - val_mse: 3137.6406\n",
            "Epoch 969/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.2060 - mse: 3055.1792 - val_loss: -533.3867 - val_mse: 3124.8818\n",
            "Epoch 970/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.2086 - mse: 3055.1250 - val_loss: -533.3857 - val_mse: 3131.4507\n",
            "Epoch 971/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.2162 - mse: 3053.6833 - val_loss: -533.3940 - val_mse: 3121.6265\n",
            "Epoch 972/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.2212 - mse: 3052.3911 - val_loss: -533.3949 - val_mse: 3128.8784\n",
            "Epoch 973/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.2254 - mse: 3051.9775 - val_loss: -533.3729 - val_mse: 3141.9731\n",
            "Epoch 974/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.2307 - mse: 3050.0425 - val_loss: -533.4051 - val_mse: 3124.6216\n",
            "Epoch 975/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.2326 - mse: 3049.9094 - val_loss: -533.4097 - val_mse: 3123.5522\n",
            "Epoch 976/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.2389 - mse: 3047.8350 - val_loss: -533.4101 - val_mse: 3127.4084\n",
            "Epoch 977/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.2456 - mse: 3048.8191 - val_loss: -533.4098 - val_mse: 3129.2866\n",
            "Epoch 978/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.2535 - mse: 3043.9417 - val_loss: -533.3821 - val_mse: 3143.6387\n",
            "Epoch 979/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.2533 - mse: 3046.3716 - val_loss: -533.4261 - val_mse: 3121.6057\n",
            "Epoch 980/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.2600 - mse: 3044.1846 - val_loss: -533.4186 - val_mse: 3128.4590\n",
            "Epoch 981/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.2654 - mse: 3044.0920 - val_loss: -533.4247 - val_mse: 3126.3816\n",
            "Epoch 982/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.2705 - mse: 3042.9351 - val_loss: -533.4334 - val_mse: 3121.5378\n",
            "Epoch 983/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.2770 - mse: 3039.9583 - val_loss: -533.4449 - val_mse: 3115.8647\n",
            "Epoch 984/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.2774 - mse: 3040.9763 - val_loss: -533.4431 - val_mse: 3120.5662\n",
            "Epoch 985/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.2839 - mse: 3039.6094 - val_loss: -533.4433 - val_mse: 3120.7803\n",
            "Epoch 986/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.2937 - mse: 3036.0703 - val_loss: -533.3502 - val_mse: 3159.6860\n",
            "Epoch 987/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.2879 - mse: 3039.3916 - val_loss: -533.4618 - val_mse: 3112.1187\n",
            "Epoch 988/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.3009 - mse: 3036.0891 - val_loss: -533.4538 - val_mse: 3121.1580\n",
            "Epoch 989/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.3079 - mse: 3035.4910 - val_loss: -533.4690 - val_mse: 3111.8921\n",
            "Epoch 990/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.3140 - mse: 3033.4363 - val_loss: -533.4640 - val_mse: 3116.0840\n",
            "Epoch 991/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.3161 - mse: 3033.7129 - val_loss: -533.4756 - val_mse: 3110.5549\n",
            "Epoch 992/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.3211 - mse: 3032.9023 - val_loss: -533.4832 - val_mse: 3100.3127\n",
            "Epoch 993/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.3249 - mse: 3031.0120 - val_loss: -533.4816 - val_mse: 3110.0874\n",
            "Epoch 994/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.3323 - mse: 3030.7380 - val_loss: -533.4938 - val_mse: 3100.4402\n",
            "Epoch 995/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.3338 - mse: 3029.0791 - val_loss: -533.4855 - val_mse: 3111.3560\n",
            "Epoch 996/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.3411 - mse: 3029.7395 - val_loss: -533.5014 - val_mse: 3102.7332\n",
            "Epoch 997/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.3457 - mse: 3026.3101 - val_loss: -533.4736 - val_mse: 3119.0144\n",
            "Epoch 998/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.3506 - mse: 3027.5776 - val_loss: -533.5100 - val_mse: 3094.2251\n",
            "Epoch 999/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -534.3525 - mse: 3025.5298 - val_loss: -533.5064 - val_mse: 3104.1775\n",
            "Epoch 1000/1000\n",
            "40000/40000 [==============================] - 1s 17us/step - loss: -534.3578 - mse: 3023.6743 - val_loss: -533.4819 - val_mse: 3118.7185\n",
            "Save file name colab_notebook_data/feature_interactions/trained_models/poissonloss/negcontrol_model-sanitycheck_l1reg-0.0_seed100_dvror.h5\n",
            "Training model colab_notebook_data/feature_interactions/trained_models/poissonloss/poscontrol_model-skipconn_l1reg-0.0_seed100_qzkpt.h5\n",
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_14 (InputLayer)           (None, 100, 4)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 76, 64)       6464        input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_14 (Gl (None, 64)           0           conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 64)           4160        global_average_pooling1d_14[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 1)            65          global_average_pooling1d_14[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 1)            65          dense_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 1)            0           dense_13[0][0]                   \n",
            "                                                                 dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 1)            0           add_1[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 10,754\n",
            "Trainable params: 10,754\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "40000/40000 [==============================] - 1s 28us/step - loss: -259.4418 - mse: 15432.5186 - val_loss: -349.1016 - val_mse: 12174.1963\n",
            "Epoch 2/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -371.6199 - mse: 9938.0527 - val_loss: -384.5887 - val_mse: 8401.5381\n",
            "Epoch 3/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -387.1561 - mse: 7905.3223 - val_loss: -389.0531 - val_mse: 7638.3599\n",
            "Epoch 4/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -388.8234 - mse: 7601.0991 - val_loss: -389.3878 - val_mse: 7570.8599\n",
            "Epoch 5/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -388.9246 - mse: 7580.2559 - val_loss: -389.4095 - val_mse: 7566.2593\n",
            "Epoch 6/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -388.9411 - mse: 7576.7559 - val_loss: -389.4251 - val_mse: 7562.9336\n",
            "Epoch 7/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -388.9577 - mse: 7573.2290 - val_loss: -389.4422 - val_mse: 7559.2778\n",
            "Epoch 8/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -388.9764 - mse: 7569.2402 - val_loss: -389.4629 - val_mse: 7554.9390\n",
            "Epoch 9/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -388.9995 - mse: 7564.3486 - val_loss: -389.4896 - val_mse: 7549.2056\n",
            "Epoch 10/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -389.0307 - mse: 7557.7632 - val_loss: -389.5241 - val_mse: 7541.9082\n",
            "Epoch 11/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -389.0745 - mse: 7548.5337 - val_loss: -389.5654 - val_mse: 7532.8193\n",
            "Epoch 12/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -389.1263 - mse: 7537.4014 - val_loss: -389.6344 - val_mse: 7518.6792\n",
            "Epoch 13/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -389.2106 - mse: 7519.9375 - val_loss: -389.7334 - val_mse: 7497.4121\n",
            "Epoch 14/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -389.3444 - mse: 7491.4678 - val_loss: -389.8936 - val_mse: 7465.0952\n",
            "Epoch 15/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -389.5515 - mse: 7448.5864 - val_loss: -390.1322 - val_mse: 7412.5342\n",
            "Epoch 16/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -389.8520 - mse: 7385.6553 - val_loss: -390.4795 - val_mse: 7340.8672\n",
            "Epoch 17/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -390.2194 - mse: 7309.8799 - val_loss: -390.8511 - val_mse: 7268.4888\n",
            "Epoch 18/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -390.6328 - mse: 7224.8486 - val_loss: -391.2695 - val_mse: 7183.1226\n",
            "Epoch 19/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.0473 - mse: 7140.8721 - val_loss: -391.6007 - val_mse: 7111.5913\n",
            "Epoch 20/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.3370 - mse: 7082.6250 - val_loss: -391.8080 - val_mse: 7078.0410\n",
            "Epoch 21/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.5153 - mse: 7048.1191 - val_loss: -391.9143 - val_mse: 7052.5654\n",
            "Epoch 22/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.5929 - mse: 7032.4624 - val_loss: -391.9722 - val_mse: 7045.7368\n",
            "Epoch 23/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6335 - mse: 7025.3042 - val_loss: -391.9898 - val_mse: 7042.7114\n",
            "Epoch 24/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6266 - mse: 7027.0518 - val_loss: -392.0113 - val_mse: 7038.3481\n",
            "Epoch 25/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6628 - mse: 7019.7642 - val_loss: -392.0128 - val_mse: 7038.8608\n",
            "Epoch 26/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.6630 - mse: 7019.6626 - val_loss: -392.0169 - val_mse: 7038.2114\n",
            "Epoch 27/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.6695 - mse: 7019.0342 - val_loss: -392.0034 - val_mse: 7040.9639\n",
            "Epoch 28/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6661 - mse: 7019.3008 - val_loss: -392.0255 - val_mse: 7036.7002\n",
            "Epoch 29/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.6742 - mse: 7018.6226 - val_loss: -392.0148 - val_mse: 7038.9424\n",
            "Epoch 30/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.6616 - mse: 7021.0874 - val_loss: -392.0159 - val_mse: 7038.8198\n",
            "Epoch 31/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.6659 - mse: 7020.1982 - val_loss: -392.0226 - val_mse: 7037.5591\n",
            "Epoch 32/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.6797 - mse: 7016.4482 - val_loss: -392.0393 - val_mse: 7034.5264\n",
            "Epoch 33/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6731 - mse: 7018.7935 - val_loss: -391.9924 - val_mse: 7044.3032\n",
            "Epoch 34/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.6781 - mse: 7018.3545 - val_loss: -392.0167 - val_mse: 7040.0918\n",
            "Epoch 35/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6752 - mse: 7018.0801 - val_loss: -392.0535 - val_mse: 7031.8262\n",
            "Epoch 36/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.6939 - mse: 7014.5586 - val_loss: -392.0566 - val_mse: 7031.3311\n",
            "Epoch 37/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.7002 - mse: 7013.1895 - val_loss: -392.0613 - val_mse: 7030.4458\n",
            "Epoch 38/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.7115 - mse: 7010.4390 - val_loss: -392.0674 - val_mse: 7029.2222\n",
            "Epoch 39/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.7117 - mse: 7010.6426 - val_loss: -392.0697 - val_mse: 7028.9336\n",
            "Epoch 40/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.7125 - mse: 7011.0898 - val_loss: -392.0074 - val_mse: 7042.8770\n",
            "Epoch 41/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.7185 - mse: 7009.6841 - val_loss: -392.0882 - val_mse: 7025.2231\n",
            "Epoch 42/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.7207 - mse: 7009.0762 - val_loss: -392.0868 - val_mse: 7025.5513\n",
            "Epoch 43/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.7285 - mse: 7008.0938 - val_loss: -392.0799 - val_mse: 7027.7896\n",
            "Epoch 44/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.7494 - mse: 7003.1782 - val_loss: -392.1184 - val_mse: 7019.4990\n",
            "Epoch 45/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.7531 - mse: 7002.9512 - val_loss: -392.1317 - val_mse: 7016.5586\n",
            "Epoch 46/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.7883 - mse: 6995.8071 - val_loss: -392.1189 - val_mse: 7019.2817\n",
            "Epoch 47/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.7980 - mse: 6993.3071 - val_loss: -392.1734 - val_mse: 7008.2402\n",
            "Epoch 48/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -391.8304 - mse: 6987.1670 - val_loss: -392.1968 - val_mse: 7003.3481\n",
            "Epoch 49/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.8818 - mse: 6976.3584 - val_loss: -392.1671 - val_mse: 7009.6074\n",
            "Epoch 50/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.9364 - mse: 6965.0713 - val_loss: -392.3186 - val_mse: 6978.0664\n",
            "Epoch 51/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.9991 - mse: 6952.5151 - val_loss: -392.3857 - val_mse: 6963.6489\n",
            "Epoch 52/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -392.0927 - mse: 6932.8838 - val_loss: -392.4177 - val_mse: 6959.1304\n",
            "Epoch 53/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -392.1833 - mse: 6913.2705 - val_loss: -392.5976 - val_mse: 6919.1665\n",
            "Epoch 54/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -392.3188 - mse: 6886.1880 - val_loss: -392.7330 - val_mse: 6891.8560\n",
            "Epoch 55/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -392.4621 - mse: 6856.0752 - val_loss: -392.8322 - val_mse: 6874.9399\n",
            "Epoch 56/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -392.6123 - mse: 6826.2993 - val_loss: -393.0509 - val_mse: 6824.7622\n",
            "Epoch 57/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -392.8047 - mse: 6786.3638 - val_loss: -393.2598 - val_mse: 6782.6807\n",
            "Epoch 58/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -393.0289 - mse: 6739.7456 - val_loss: -393.4502 - val_mse: 6748.9199\n",
            "Epoch 59/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -393.2747 - mse: 6689.9204 - val_loss: -393.7222 - val_mse: 6680.2808\n",
            "Epoch 60/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -393.5466 - mse: 6633.8906 - val_loss: -393.9469 - val_mse: 6628.3940\n",
            "Epoch 61/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -393.8592 - mse: 6570.5552 - val_loss: -394.3362 - val_mse: 6561.9775\n",
            "Epoch 62/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -394.1755 - mse: 6504.0366 - val_loss: -394.6615 - val_mse: 6486.8677\n",
            "Epoch 63/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -394.5281 - mse: 6434.5127 - val_loss: -395.0091 - val_mse: 6431.4810\n",
            "Epoch 64/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -394.9103 - mse: 6356.1924 - val_loss: -395.3846 - val_mse: 6353.5767\n",
            "Epoch 65/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -395.2977 - mse: 6277.4136 - val_loss: -395.7950 - val_mse: 6261.6797\n",
            "Epoch 66/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -395.6956 - mse: 6196.7798 - val_loss: -396.1380 - val_mse: 6174.2944\n",
            "Epoch 67/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -396.1181 - mse: 6112.1392 - val_loss: -396.2296 - val_mse: 6208.6665\n",
            "Epoch 68/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -396.4774 - mse: 6039.5376 - val_loss: -396.8925 - val_mse: 6017.0586\n",
            "Epoch 69/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -396.8410 - mse: 5961.3486 - val_loss: -397.2848 - val_mse: 5963.1621\n",
            "Epoch 70/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -397.2175 - mse: 5889.4058 - val_loss: -397.6136 - val_mse: 5870.6958\n",
            "Epoch 71/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -397.5495 - mse: 5821.0552 - val_loss: -397.9179 - val_mse: 5823.0518\n",
            "Epoch 72/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -397.8949 - mse: 5748.7803 - val_loss: -397.9002 - val_mse: 5839.3037\n",
            "Epoch 73/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -398.1570 - mse: 5693.5010 - val_loss: -398.5246 - val_mse: 5685.8662\n",
            "Epoch 74/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -398.4661 - mse: 5630.2910 - val_loss: -398.7030 - val_mse: 5653.5640\n",
            "Epoch 75/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -398.7268 - mse: 5576.4756 - val_loss: -399.0481 - val_mse: 5560.0698\n",
            "Epoch 76/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -398.9907 - mse: 5523.7739 - val_loss: -399.2864 - val_mse: 5507.0322\n",
            "Epoch 77/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -399.2041 - mse: 5476.2256 - val_loss: -399.4046 - val_mse: 5524.8022\n",
            "Epoch 78/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -399.4674 - mse: 5425.3818 - val_loss: -399.7973 - val_mse: 5412.6826\n",
            "Epoch 79/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -399.7012 - mse: 5375.2539 - val_loss: -399.8968 - val_mse: 5366.9082\n",
            "Epoch 80/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -399.9385 - mse: 5334.2109 - val_loss: -400.0588 - val_mse: 5389.1567\n",
            "Epoch 81/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -400.1845 - mse: 5285.4297 - val_loss: -400.3989 - val_mse: 5307.6016\n",
            "Epoch 82/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -400.3688 - mse: 5238.5078 - val_loss: -400.6760 - val_mse: 5260.7554\n",
            "Epoch 83/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -400.6028 - mse: 5196.9009 - val_loss: -400.9294 - val_mse: 5209.3262\n",
            "Epoch 84/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -400.9075 - mse: 5143.9390 - val_loss: -401.2213 - val_mse: 5138.9600\n",
            "Epoch 85/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -401.1124 - mse: 5103.9683 - val_loss: -401.4561 - val_mse: 5085.6431\n",
            "Epoch 86/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -401.3214 - mse: 5059.8154 - val_loss: -401.4323 - val_mse: 5112.5474\n",
            "Epoch 87/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -401.5789 - mse: 5008.5737 - val_loss: -401.9112 - val_mse: 4990.6689\n",
            "Epoch 88/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -401.8154 - mse: 4960.3667 - val_loss: -402.0787 - val_mse: 4935.0142\n",
            "Epoch 89/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -402.0301 - mse: 4918.7178 - val_loss: -402.1426 - val_mse: 4903.7847\n",
            "Epoch 90/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -402.2588 - mse: 4875.1699 - val_loss: -402.5340 - val_mse: 4844.4121\n",
            "Epoch 91/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -402.4866 - mse: 4829.7471 - val_loss: -402.8283 - val_mse: 4833.5503\n",
            "Epoch 92/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -402.7607 - mse: 4779.0010 - val_loss: -403.0905 - val_mse: 4759.1152\n",
            "Epoch 93/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -402.9811 - mse: 4738.6855 - val_loss: -403.3019 - val_mse: 4705.3706\n",
            "Epoch 94/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -403.1696 - mse: 4698.9253 - val_loss: -403.5511 - val_mse: 4668.4106\n",
            "Epoch 95/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -403.3930 - mse: 4650.1699 - val_loss: -403.6424 - val_mse: 4621.4199\n",
            "Epoch 96/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -403.6465 - mse: 4610.6626 - val_loss: -403.9778 - val_mse: 4605.6382\n",
            "Epoch 97/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -403.8633 - mse: 4565.8135 - val_loss: -404.1799 - val_mse: 4530.7856\n",
            "Epoch 98/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -404.0503 - mse: 4526.6362 - val_loss: -404.4570 - val_mse: 4497.5229\n",
            "Epoch 99/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -404.3052 - mse: 4480.6460 - val_loss: -404.4173 - val_mse: 4533.5908\n",
            "Epoch 100/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -404.4124 - mse: 4457.3848 - val_loss: -404.8507 - val_mse: 4432.8882\n",
            "Epoch 101/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -404.6911 - mse: 4404.8545 - val_loss: -405.0779 - val_mse: 4374.2524\n",
            "Epoch 102/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -404.8873 - mse: 4368.5796 - val_loss: -405.1935 - val_mse: 4331.1309\n",
            "Epoch 103/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -405.0421 - mse: 4340.5806 - val_loss: -405.2058 - val_mse: 4304.5400\n",
            "Epoch 104/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -405.2700 - mse: 4298.5757 - val_loss: -405.6453 - val_mse: 4266.2183\n",
            "Epoch 105/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -405.4561 - mse: 4255.6572 - val_loss: -405.8534 - val_mse: 4244.4888\n",
            "Epoch 106/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -405.6566 - mse: 4220.9590 - val_loss: -406.0362 - val_mse: 4209.3179\n",
            "Epoch 107/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -405.8592 - mse: 4190.5996 - val_loss: -406.1079 - val_mse: 4208.6196\n",
            "Epoch 108/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -405.9990 - mse: 4157.7090 - val_loss: -406.3624 - val_mse: 4158.3862\n",
            "Epoch 109/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -406.1873 - mse: 4124.5557 - val_loss: -406.4876 - val_mse: 4116.3550\n",
            "Epoch 110/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -406.3244 - mse: 4097.4834 - val_loss: -406.7689 - val_mse: 4064.8040\n",
            "Epoch 111/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -406.5220 - mse: 4062.9995 - val_loss: -406.9298 - val_mse: 4040.1353\n",
            "Epoch 112/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -406.6944 - mse: 4026.7168 - val_loss: -407.0859 - val_mse: 3991.2249\n",
            "Epoch 113/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -406.8291 - mse: 3999.1919 - val_loss: -407.2297 - val_mse: 3980.1492\n",
            "Epoch 114/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -407.0001 - mse: 3974.9053 - val_loss: -407.0746 - val_mse: 3945.6611\n",
            "Epoch 115/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -407.1283 - mse: 3945.1492 - val_loss: -407.5097 - val_mse: 3945.8457\n",
            "Epoch 116/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -407.3106 - mse: 3918.8052 - val_loss: -407.6612 - val_mse: 3875.8528\n",
            "Epoch 117/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -407.3910 - mse: 3896.0527 - val_loss: -407.7162 - val_mse: 3849.7805\n",
            "Epoch 118/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -407.5299 - mse: 3872.3567 - val_loss: -407.7500 - val_mse: 3885.6409\n",
            "Epoch 119/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -407.6594 - mse: 3853.1111 - val_loss: -408.0378 - val_mse: 3798.9441\n",
            "Epoch 120/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -407.8729 - mse: 3813.6333 - val_loss: -407.9922 - val_mse: 3824.4500\n",
            "Epoch 121/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -407.9926 - mse: 3788.4680 - val_loss: -408.3163 - val_mse: 3773.9756\n",
            "Epoch 122/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -408.0910 - mse: 3768.7368 - val_loss: -408.4280 - val_mse: 3746.3127\n",
            "Epoch 123/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -408.2650 - mse: 3741.2236 - val_loss: -408.4453 - val_mse: 3708.5835\n",
            "Epoch 124/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -408.3784 - mse: 3720.4360 - val_loss: -408.6541 - val_mse: 3677.6743\n",
            "Epoch 125/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -408.4721 - mse: 3699.3340 - val_loss: -408.8081 - val_mse: 3662.7593\n",
            "Epoch 126/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -408.6050 - mse: 3675.2581 - val_loss: -408.9159 - val_mse: 3646.3245\n",
            "Epoch 127/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -408.7144 - mse: 3656.3997 - val_loss: -409.0102 - val_mse: 3625.7812\n",
            "Epoch 128/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -408.7196 - mse: 3653.2639 - val_loss: -409.0511 - val_mse: 3642.7268\n",
            "Epoch 129/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -408.9349 - mse: 3618.2437 - val_loss: -409.2416 - val_mse: 3583.1931\n",
            "Epoch 130/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -409.0563 - mse: 3598.6191 - val_loss: -409.3287 - val_mse: 3569.2964\n",
            "Epoch 131/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -409.1683 - mse: 3580.3811 - val_loss: -409.4224 - val_mse: 3556.0332\n",
            "Epoch 132/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -409.2784 - mse: 3555.3489 - val_loss: -409.5644 - val_mse: 3524.2324\n",
            "Epoch 133/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -409.3102 - mse: 3546.9963 - val_loss: -409.6465 - val_mse: 3526.0945\n",
            "Epoch 134/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -409.4735 - mse: 3522.8567 - val_loss: -409.7349 - val_mse: 3507.8948\n",
            "Epoch 135/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -409.5514 - mse: 3509.0083 - val_loss: -409.8556 - val_mse: 3462.4292\n",
            "Epoch 136/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -409.6789 - mse: 3483.7815 - val_loss: -409.9630 - val_mse: 3461.9180\n",
            "Epoch 137/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -409.8185 - mse: 3464.4900 - val_loss: -409.8077 - val_mse: 3474.6052\n",
            "Epoch 138/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -409.8652 - mse: 3451.2417 - val_loss: -410.2008 - val_mse: 3408.7285\n",
            "Epoch 139/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -410.0055 - mse: 3426.9104 - val_loss: -410.2217 - val_mse: 3411.9468\n",
            "Epoch 140/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -410.0731 - mse: 3413.5891 - val_loss: -410.3647 - val_mse: 3365.1079\n",
            "Epoch 141/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -410.2104 - mse: 3392.2749 - val_loss: -410.5092 - val_mse: 3370.8979\n",
            "Epoch 142/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -410.3104 - mse: 3376.8416 - val_loss: -410.5022 - val_mse: 3355.3513\n",
            "Epoch 143/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -410.4682 - mse: 3343.2910 - val_loss: -410.7208 - val_mse: 3303.8674\n",
            "Epoch 144/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -410.5193 - mse: 3335.3765 - val_loss: -410.7959 - val_mse: 3286.5171\n",
            "Epoch 145/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -410.6947 - mse: 3310.5503 - val_loss: -410.9538 - val_mse: 3277.7009\n",
            "Epoch 146/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -410.7802 - mse: 3291.0381 - val_loss: -410.9674 - val_mse: 3250.1240\n",
            "Epoch 147/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -410.8858 - mse: 3273.9456 - val_loss: -411.1211 - val_mse: 3256.8816\n",
            "Epoch 148/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -410.9643 - mse: 3258.5642 - val_loss: -411.3145 - val_mse: 3199.9351\n",
            "Epoch 149/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -411.1264 - mse: 3231.2078 - val_loss: -411.4398 - val_mse: 3194.6770\n",
            "Epoch 150/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -411.2235 - mse: 3215.2830 - val_loss: -411.3249 - val_mse: 3211.1479\n",
            "Epoch 151/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -411.3414 - mse: 3191.9968 - val_loss: -411.6740 - val_mse: 3143.7166\n",
            "Epoch 152/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -411.4678 - mse: 3170.8723 - val_loss: -411.7724 - val_mse: 3137.4392\n",
            "Epoch 153/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -411.6022 - mse: 3148.4009 - val_loss: -411.8363 - val_mse: 3117.1477\n",
            "Epoch 154/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -411.6714 - mse: 3130.7131 - val_loss: -411.9024 - val_mse: 3136.0083\n",
            "Epoch 155/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -411.8110 - mse: 3113.8025 - val_loss: -412.0883 - val_mse: 3060.8379\n",
            "Epoch 156/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -411.9352 - mse: 3088.5901 - val_loss: -412.2130 - val_mse: 3041.7166\n",
            "Epoch 157/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -412.0730 - mse: 3068.6069 - val_loss: -412.2701 - val_mse: 3023.2283\n",
            "Epoch 158/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -412.1871 - mse: 3048.0869 - val_loss: -412.4804 - val_mse: 3006.9224\n",
            "Epoch 159/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -412.2784 - mse: 3019.6765 - val_loss: -412.3436 - val_mse: 2993.0095\n",
            "Epoch 160/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -412.3857 - mse: 3007.9976 - val_loss: -412.6753 - val_mse: 2956.0215\n",
            "Epoch 161/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -412.4716 - mse: 2990.8682 - val_loss: -412.8341 - val_mse: 2957.1355\n",
            "Epoch 162/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -412.6109 - mse: 2968.9055 - val_loss: -412.9663 - val_mse: 2931.9663\n",
            "Epoch 163/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -412.7547 - mse: 2942.5691 - val_loss: -413.0685 - val_mse: 2909.4475\n",
            "Epoch 164/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -412.8823 - mse: 2922.0110 - val_loss: -413.1714 - val_mse: 2875.6189\n",
            "Epoch 165/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -413.0105 - mse: 2898.5095 - val_loss: -413.0979 - val_mse: 2902.5754\n",
            "Epoch 166/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -413.1334 - mse: 2875.5459 - val_loss: -413.3773 - val_mse: 2850.9412\n",
            "Epoch 167/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -413.1780 - mse: 2866.5894 - val_loss: -413.5126 - val_mse: 2806.8899\n",
            "Epoch 168/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -413.3706 - mse: 2833.4658 - val_loss: -413.3570 - val_mse: 2864.6089\n",
            "Epoch 169/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -413.4712 - mse: 2813.3955 - val_loss: -413.7958 - val_mse: 2771.1770\n",
            "Epoch 170/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -413.5996 - mse: 2788.2964 - val_loss: -413.8994 - val_mse: 2741.3625\n",
            "Epoch 171/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -413.7474 - mse: 2769.3650 - val_loss: -413.8748 - val_mse: 2759.4177\n",
            "Epoch 172/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -413.8545 - mse: 2742.8162 - val_loss: -413.9186 - val_mse: 2756.0493\n",
            "Epoch 173/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -414.0059 - mse: 2720.6956 - val_loss: -414.3470 - val_mse: 2672.5459\n",
            "Epoch 174/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -414.1401 - mse: 2692.6165 - val_loss: -414.4244 - val_mse: 2642.1455\n",
            "Epoch 175/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -414.2422 - mse: 2673.7107 - val_loss: -414.6044 - val_mse: 2638.7017\n",
            "Epoch 176/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -414.4043 - mse: 2645.9570 - val_loss: -414.7589 - val_mse: 2605.1255\n",
            "Epoch 177/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -414.5667 - mse: 2614.3584 - val_loss: -414.9251 - val_mse: 2574.4285\n",
            "Epoch 178/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -414.7212 - mse: 2588.2197 - val_loss: -415.0315 - val_mse: 2538.1719\n",
            "Epoch 179/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -414.8531 - mse: 2566.4258 - val_loss: -415.2348 - val_mse: 2519.9434\n",
            "Epoch 180/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -415.0293 - mse: 2534.7771 - val_loss: -415.3392 - val_mse: 2482.1650\n",
            "Epoch 181/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -415.1577 - mse: 2505.5723 - val_loss: -415.3463 - val_mse: 2464.4341\n",
            "Epoch 182/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -415.2815 - mse: 2485.3276 - val_loss: -415.5823 - val_mse: 2466.4277\n",
            "Epoch 183/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -415.5126 - mse: 2444.0938 - val_loss: -415.8527 - val_mse: 2402.9619\n",
            "Epoch 184/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -415.6316 - mse: 2422.2649 - val_loss: -416.0176 - val_mse: 2372.5840\n",
            "Epoch 185/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -415.8131 - mse: 2391.4392 - val_loss: -416.1122 - val_mse: 2332.2205\n",
            "Epoch 186/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -415.9308 - mse: 2362.1265 - val_loss: -416.0416 - val_mse: 2321.6003\n",
            "Epoch 187/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -416.1152 - mse: 2335.2444 - val_loss: -416.5161 - val_mse: 2291.8755\n",
            "Epoch 188/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -416.2471 - mse: 2306.6875 - val_loss: -416.6459 - val_mse: 2286.3535\n",
            "Epoch 189/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -416.4195 - mse: 2278.1460 - val_loss: -416.8354 - val_mse: 2237.3557\n",
            "Epoch 190/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -416.5596 - mse: 2251.4937 - val_loss: -416.9807 - val_mse: 2213.3103\n",
            "Epoch 191/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -416.7363 - mse: 2221.4890 - val_loss: -417.0004 - val_mse: 2176.1555\n",
            "Epoch 192/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -416.8494 - mse: 2197.5027 - val_loss: -417.2632 - val_mse: 2153.5452\n",
            "Epoch 193/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -416.9826 - mse: 2175.3379 - val_loss: -417.3844 - val_mse: 2147.7771\n",
            "Epoch 194/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -417.1495 - mse: 2142.1401 - val_loss: -417.5115 - val_mse: 2124.5527\n",
            "Epoch 195/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -417.2531 - mse: 2124.2178 - val_loss: -417.6896 - val_mse: 2080.7878\n",
            "Epoch 196/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -417.3992 - mse: 2095.2712 - val_loss: -417.7989 - val_mse: 2052.1912\n",
            "Epoch 197/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -417.5260 - mse: 2071.9817 - val_loss: -417.9242 - val_mse: 2042.8832\n",
            "Epoch 198/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -417.6689 - mse: 2045.2675 - val_loss: -418.0679 - val_mse: 2003.2532\n",
            "Epoch 199/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -417.7603 - mse: 2025.6475 - val_loss: -418.2068 - val_mse: 1996.5902\n",
            "Epoch 200/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -417.9216 - mse: 1999.3822 - val_loss: -418.3218 - val_mse: 1962.7930\n",
            "Epoch 201/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -417.9813 - mse: 1984.4166 - val_loss: -418.3370 - val_mse: 1974.7756\n",
            "Epoch 202/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -418.1311 - mse: 1959.5342 - val_loss: -418.5311 - val_mse: 1943.1256\n",
            "Epoch 203/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -418.2773 - mse: 1933.5298 - val_loss: -418.6977 - val_mse: 1905.6971\n",
            "Epoch 204/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -418.3742 - mse: 1912.0354 - val_loss: -418.6176 - val_mse: 1922.7559\n",
            "Epoch 205/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -418.4416 - mse: 1895.9872 - val_loss: -418.8384 - val_mse: 1882.1281\n",
            "Epoch 206/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -418.5866 - mse: 1875.3312 - val_loss: -418.9259 - val_mse: 1863.8820\n",
            "Epoch 207/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -418.7116 - mse: 1850.7686 - val_loss: -419.0580 - val_mse: 1841.2820\n",
            "Epoch 208/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -418.8001 - mse: 1832.7686 - val_loss: -418.9927 - val_mse: 1842.9871\n",
            "Epoch 209/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -418.9181 - mse: 1809.3638 - val_loss: -419.3114 - val_mse: 1785.4252\n",
            "Epoch 210/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -418.9977 - mse: 1793.7148 - val_loss: -419.3185 - val_mse: 1786.2894\n",
            "Epoch 211/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -419.1107 - mse: 1772.5330 - val_loss: -419.5499 - val_mse: 1751.7629\n",
            "Epoch 212/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -419.2215 - mse: 1752.8904 - val_loss: -419.5757 - val_mse: 1739.9202\n",
            "Epoch 213/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -419.3088 - mse: 1732.5126 - val_loss: -419.7438 - val_mse: 1709.6514\n",
            "Epoch 214/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -419.4082 - mse: 1715.8756 - val_loss: -419.8180 - val_mse: 1702.2872\n",
            "Epoch 215/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -419.5144 - mse: 1694.8792 - val_loss: -419.8640 - val_mse: 1695.2046\n",
            "Epoch 216/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -419.5920 - mse: 1679.0404 - val_loss: -420.0388 - val_mse: 1657.2770\n",
            "Epoch 217/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -419.6966 - mse: 1657.8477 - val_loss: -420.1318 - val_mse: 1648.1219\n",
            "Epoch 218/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -419.7854 - mse: 1641.1567 - val_loss: -420.2365 - val_mse: 1619.2740\n",
            "Epoch 219/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -419.8768 - mse: 1622.2983 - val_loss: -420.3163 - val_mse: 1602.4760\n",
            "Epoch 220/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -419.9616 - mse: 1601.9479 - val_loss: -420.4039 - val_mse: 1599.1646\n",
            "Epoch 221/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.0611 - mse: 1586.3184 - val_loss: -420.5296 - val_mse: 1567.0607\n",
            "Epoch 222/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.1611 - mse: 1563.8623 - val_loss: -420.5766 - val_mse: 1559.5785\n",
            "Epoch 223/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.2284 - mse: 1547.7144 - val_loss: -420.7166 - val_mse: 1531.9792\n",
            "Epoch 224/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.3172 - mse: 1531.5474 - val_loss: -420.7957 - val_mse: 1507.4124\n",
            "Epoch 225/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.4016 - mse: 1512.6573 - val_loss: -420.7643 - val_mse: 1502.3781\n",
            "Epoch 226/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.4760 - mse: 1494.6300 - val_loss: -420.9234 - val_mse: 1489.7760\n",
            "Epoch 227/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -420.5562 - mse: 1479.2494 - val_loss: -420.8161 - val_mse: 1487.7805\n",
            "Epoch 228/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.6233 - mse: 1463.9175 - val_loss: -421.0971 - val_mse: 1440.8638\n",
            "Epoch 229/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -420.6690 - mse: 1449.9067 - val_loss: -421.0548 - val_mse: 1443.2253\n",
            "Epoch 230/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.7449 - mse: 1436.2872 - val_loss: -421.1475 - val_mse: 1429.0458\n",
            "Epoch 231/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.7810 - mse: 1427.2812 - val_loss: -421.2225 - val_mse: 1412.1615\n",
            "Epoch 232/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -420.8370 - mse: 1412.0127 - val_loss: -421.2834 - val_mse: 1412.5122\n",
            "Epoch 233/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.8866 - mse: 1405.2773 - val_loss: -421.3565 - val_mse: 1387.2782\n",
            "Epoch 234/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.9296 - mse: 1394.6515 - val_loss: -421.3766 - val_mse: 1383.7292\n",
            "Epoch 235/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.9531 - mse: 1389.0375 - val_loss: -421.4336 - val_mse: 1367.4250\n",
            "Epoch 236/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.0063 - mse: 1377.2039 - val_loss: -421.4659 - val_mse: 1364.7225\n",
            "Epoch 237/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.0263 - mse: 1370.9757 - val_loss: -421.4549 - val_mse: 1366.9796\n",
            "Epoch 238/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.0725 - mse: 1363.4153 - val_loss: -421.5066 - val_mse: 1348.1669\n",
            "Epoch 239/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.1053 - mse: 1354.8690 - val_loss: -421.4786 - val_mse: 1347.5802\n",
            "Epoch 240/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.1168 - mse: 1349.8859 - val_loss: -421.5866 - val_mse: 1337.4733\n",
            "Epoch 241/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.1569 - mse: 1343.0306 - val_loss: -421.6125 - val_mse: 1333.1575\n",
            "Epoch 242/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.1886 - mse: 1339.1060 - val_loss: -421.6282 - val_mse: 1329.2905\n",
            "Epoch 243/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.2059 - mse: 1330.7147 - val_loss: -421.6158 - val_mse: 1336.1941\n",
            "Epoch 244/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.2201 - mse: 1330.3337 - val_loss: -421.6541 - val_mse: 1320.0652\n",
            "Epoch 245/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.2407 - mse: 1325.1709 - val_loss: -421.6971 - val_mse: 1311.1423\n",
            "Epoch 246/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.2522 - mse: 1319.7286 - val_loss: -421.5894 - val_mse: 1319.3859\n",
            "Epoch 247/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.2724 - mse: 1314.1505 - val_loss: -421.7315 - val_mse: 1308.9718\n",
            "Epoch 248/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.3031 - mse: 1312.7467 - val_loss: -421.7223 - val_mse: 1308.3708\n",
            "Epoch 249/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.3362 - mse: 1305.3672 - val_loss: -421.7629 - val_mse: 1302.4204\n",
            "Epoch 250/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.3496 - mse: 1302.4238 - val_loss: -421.7619 - val_mse: 1293.9161\n",
            "Epoch 251/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.3661 - mse: 1298.6089 - val_loss: -421.7377 - val_mse: 1300.8286\n",
            "Epoch 252/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.3850 - mse: 1295.8560 - val_loss: -421.8151 - val_mse: 1291.7692\n",
            "Epoch 253/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.3906 - mse: 1290.4681 - val_loss: -421.7875 - val_mse: 1303.1290\n",
            "Epoch 254/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.4102 - mse: 1289.9274 - val_loss: -421.8424 - val_mse: 1287.5116\n",
            "Epoch 255/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.4126 - mse: 1287.3138 - val_loss: -421.8266 - val_mse: 1285.0920\n",
            "Epoch 256/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.4549 - mse: 1282.1637 - val_loss: -421.8360 - val_mse: 1283.4092\n",
            "Epoch 257/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.4505 - mse: 1280.4247 - val_loss: -421.8841 - val_mse: 1276.5809\n",
            "Epoch 258/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.4690 - mse: 1276.9675 - val_loss: -421.8272 - val_mse: 1290.5497\n",
            "Epoch 259/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.4813 - mse: 1273.7318 - val_loss: -421.8959 - val_mse: 1275.4021\n",
            "Epoch 260/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.5060 - mse: 1271.1100 - val_loss: -421.9057 - val_mse: 1271.6132\n",
            "Epoch 261/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.5159 - mse: 1267.8267 - val_loss: -421.9273 - val_mse: 1277.6421\n",
            "Epoch 262/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.5299 - mse: 1266.1414 - val_loss: -421.7642 - val_mse: 1287.0989\n",
            "Epoch 263/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.5276 - mse: 1265.8165 - val_loss: -421.8846 - val_mse: 1271.9857\n",
            "Epoch 264/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.5536 - mse: 1260.0807 - val_loss: -421.9273 - val_mse: 1266.1979\n",
            "Epoch 265/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.5615 - mse: 1259.1694 - val_loss: -421.9477 - val_mse: 1256.1958\n",
            "Epoch 266/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.5693 - mse: 1256.4247 - val_loss: -421.9763 - val_mse: 1264.2648\n",
            "Epoch 267/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.5864 - mse: 1255.3534 - val_loss: -421.9825 - val_mse: 1256.4370\n",
            "Epoch 268/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.5979 - mse: 1252.1643 - val_loss: -421.9915 - val_mse: 1255.2427\n",
            "Epoch 269/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.5996 - mse: 1248.4164 - val_loss: -422.0062 - val_mse: 1258.2194\n",
            "Epoch 270/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6093 - mse: 1248.8700 - val_loss: -421.9788 - val_mse: 1257.6829\n",
            "Epoch 271/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6259 - mse: 1245.6127 - val_loss: -422.0145 - val_mse: 1251.1755\n",
            "Epoch 272/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6367 - mse: 1244.0461 - val_loss: -421.9884 - val_mse: 1254.0887\n",
            "Epoch 273/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6372 - mse: 1241.5089 - val_loss: -422.0051 - val_mse: 1255.4261\n",
            "Epoch 274/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6254 - mse: 1242.7960 - val_loss: -422.0427 - val_mse: 1245.7296\n",
            "Epoch 275/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6434 - mse: 1239.3478 - val_loss: -422.0449 - val_mse: 1244.2625\n",
            "Epoch 276/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6644 - mse: 1237.1411 - val_loss: -422.0585 - val_mse: 1240.2238\n",
            "Epoch 277/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6718 - mse: 1235.2094 - val_loss: -422.0294 - val_mse: 1250.6936\n",
            "Epoch 278/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.6903 - mse: 1233.1744 - val_loss: -422.0486 - val_mse: 1244.2875\n",
            "Epoch 279/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6930 - mse: 1232.1943 - val_loss: -422.0661 - val_mse: 1244.1582\n",
            "Epoch 280/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7078 - mse: 1229.9950 - val_loss: -422.0640 - val_mse: 1243.1796\n",
            "Epoch 281/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6815 - mse: 1229.2004 - val_loss: -422.0887 - val_mse: 1245.5743\n",
            "Epoch 282/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.7220 - mse: 1228.7729 - val_loss: -422.0104 - val_mse: 1242.5168\n",
            "Epoch 283/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7300 - mse: 1224.9204 - val_loss: -422.0211 - val_mse: 1247.6560\n",
            "Epoch 284/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7384 - mse: 1223.6586 - val_loss: -422.1074 - val_mse: 1236.0669\n",
            "Epoch 285/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7413 - mse: 1222.6508 - val_loss: -422.0438 - val_mse: 1239.0562\n",
            "Epoch 286/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7481 - mse: 1222.2072 - val_loss: -422.1168 - val_mse: 1232.0935\n",
            "Epoch 287/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7492 - mse: 1218.8988 - val_loss: -422.0988 - val_mse: 1230.1267\n",
            "Epoch 288/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7625 - mse: 1219.0070 - val_loss: -422.1040 - val_mse: 1228.9863\n",
            "Epoch 289/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7720 - mse: 1215.9208 - val_loss: -422.1324 - val_mse: 1230.8726\n",
            "Epoch 290/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7790 - mse: 1215.0518 - val_loss: -422.1368 - val_mse: 1226.8671\n",
            "Epoch 291/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7850 - mse: 1215.1707 - val_loss: -422.1409 - val_mse: 1226.6439\n",
            "Epoch 292/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7880 - mse: 1213.1609 - val_loss: -422.1477 - val_mse: 1223.7928\n",
            "Epoch 293/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7941 - mse: 1210.4681 - val_loss: -422.1320 - val_mse: 1232.7692\n",
            "Epoch 294/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.7888 - mse: 1211.7040 - val_loss: -422.1565 - val_mse: 1227.5684\n",
            "Epoch 295/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8188 - mse: 1209.5833 - val_loss: -422.1561 - val_mse: 1227.2764\n",
            "Epoch 296/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8107 - mse: 1209.2201 - val_loss: -422.0953 - val_mse: 1225.5714\n",
            "Epoch 297/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8260 - mse: 1206.3800 - val_loss: -422.1487 - val_mse: 1222.3451\n",
            "Epoch 298/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.8292 - mse: 1204.7469 - val_loss: -422.1726 - val_mse: 1223.1150\n",
            "Epoch 299/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8316 - mse: 1205.4359 - val_loss: -422.1489 - val_mse: 1221.5634\n",
            "Epoch 300/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.8428 - mse: 1203.5995 - val_loss: -422.1599 - val_mse: 1217.5649\n",
            "Epoch 301/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.8394 - mse: 1201.8246 - val_loss: -422.1193 - val_mse: 1224.0493\n",
            "Epoch 302/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.8537 - mse: 1200.2797 - val_loss: -422.1376 - val_mse: 1221.2454\n",
            "Epoch 303/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.8504 - mse: 1200.4896 - val_loss: -422.1878 - val_mse: 1215.7592\n",
            "Epoch 304/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8626 - mse: 1197.0986 - val_loss: -422.1810 - val_mse: 1221.3374\n",
            "Epoch 305/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.8666 - mse: 1198.1510 - val_loss: -422.1688 - val_mse: 1219.4132\n",
            "Epoch 306/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -421.8835 - mse: 1196.4502 - val_loss: -422.2003 - val_mse: 1214.6470\n",
            "Epoch 307/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -421.8824 - mse: 1195.5667 - val_loss: -422.2067 - val_mse: 1218.5782\n",
            "Epoch 308/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.8707 - mse: 1194.6471 - val_loss: -422.1974 - val_mse: 1214.1274\n",
            "Epoch 309/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.8884 - mse: 1193.2148 - val_loss: -422.1324 - val_mse: 1218.7014\n",
            "Epoch 310/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.8796 - mse: 1193.3540 - val_loss: -422.2014 - val_mse: 1214.4913\n",
            "Epoch 311/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.9026 - mse: 1191.7185 - val_loss: -422.2039 - val_mse: 1211.4496\n",
            "Epoch 312/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.8880 - mse: 1190.9564 - val_loss: -422.2132 - val_mse: 1212.1188\n",
            "Epoch 313/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.9174 - mse: 1188.3708 - val_loss: -422.2252 - val_mse: 1213.0828\n",
            "Epoch 314/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9239 - mse: 1189.0021 - val_loss: -422.2187 - val_mse: 1210.5298\n",
            "Epoch 315/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9135 - mse: 1186.1686 - val_loss: -422.1591 - val_mse: 1226.9933\n",
            "Epoch 316/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9219 - mse: 1187.5665 - val_loss: -422.1508 - val_mse: 1217.3488\n",
            "Epoch 317/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.9218 - mse: 1184.6959 - val_loss: -422.0342 - val_mse: 1228.5314\n",
            "Epoch 318/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.9332 - mse: 1184.9602 - val_loss: -422.2108 - val_mse: 1210.0547\n",
            "Epoch 319/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.9407 - mse: 1182.5836 - val_loss: -422.2201 - val_mse: 1213.0844\n",
            "Epoch 320/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9403 - mse: 1183.6444 - val_loss: -422.2154 - val_mse: 1211.2657\n",
            "Epoch 321/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9480 - mse: 1181.9915 - val_loss: -422.2265 - val_mse: 1207.2773\n",
            "Epoch 322/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9480 - mse: 1180.9701 - val_loss: -422.2162 - val_mse: 1212.0317\n",
            "Epoch 323/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9534 - mse: 1181.0176 - val_loss: -422.1998 - val_mse: 1206.5648\n",
            "Epoch 324/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9494 - mse: 1179.2430 - val_loss: -422.2026 - val_mse: 1206.7461\n",
            "Epoch 325/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9647 - mse: 1177.9138 - val_loss: -422.2346 - val_mse: 1204.2164\n",
            "Epoch 326/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9691 - mse: 1176.4873 - val_loss: -422.2500 - val_mse: 1204.7069\n",
            "Epoch 327/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9531 - mse: 1178.8108 - val_loss: -422.2449 - val_mse: 1203.2130\n",
            "Epoch 328/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9782 - mse: 1176.0210 - val_loss: -422.2330 - val_mse: 1203.4120\n",
            "Epoch 329/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9699 - mse: 1175.6512 - val_loss: -422.2305 - val_mse: 1205.9222\n",
            "Epoch 330/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9713 - mse: 1176.9150 - val_loss: -422.2381 - val_mse: 1202.1006\n",
            "Epoch 331/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.9861 - mse: 1172.2426 - val_loss: -422.2251 - val_mse: 1211.4552\n",
            "Epoch 332/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9933 - mse: 1173.8440 - val_loss: -422.2181 - val_mse: 1209.1605\n",
            "Epoch 333/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9960 - mse: 1173.5431 - val_loss: -422.2524 - val_mse: 1198.6512\n",
            "Epoch 334/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9907 - mse: 1171.6034 - val_loss: -422.2711 - val_mse: 1204.8431\n",
            "Epoch 335/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0068 - mse: 1171.3011 - val_loss: -422.2364 - val_mse: 1196.3323\n",
            "Epoch 336/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.9897 - mse: 1170.6172 - val_loss: -422.1036 - val_mse: 1214.1113\n",
            "Epoch 337/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.0036 - mse: 1171.1143 - val_loss: -422.2782 - val_mse: 1194.4801\n",
            "Epoch 338/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0016 - mse: 1167.9420 - val_loss: -422.2420 - val_mse: 1199.2052\n",
            "Epoch 339/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.0187 - mse: 1168.6604 - val_loss: -422.2768 - val_mse: 1194.9054\n",
            "Epoch 340/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0135 - mse: 1168.2332 - val_loss: -422.2610 - val_mse: 1192.3743\n",
            "Epoch 341/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0195 - mse: 1164.1876 - val_loss: -422.2824 - val_mse: 1198.9310\n",
            "Epoch 342/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0278 - mse: 1167.1195 - val_loss: -422.2360 - val_mse: 1202.7156\n",
            "Epoch 343/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0257 - mse: 1165.3126 - val_loss: -422.2884 - val_mse: 1197.8094\n",
            "Epoch 344/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.0323 - mse: 1164.9136 - val_loss: -422.2806 - val_mse: 1198.9989\n",
            "Epoch 345/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0321 - mse: 1163.1055 - val_loss: -422.2888 - val_mse: 1194.0532\n",
            "Epoch 346/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0427 - mse: 1162.9750 - val_loss: -422.2357 - val_mse: 1200.3707\n",
            "Epoch 347/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0494 - mse: 1160.5503 - val_loss: -422.2837 - val_mse: 1204.4550\n",
            "Epoch 348/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0343 - mse: 1162.0123 - val_loss: -422.2953 - val_mse: 1193.8258\n",
            "Epoch 349/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0504 - mse: 1159.7773 - val_loss: -422.2935 - val_mse: 1197.0204\n",
            "Epoch 350/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0463 - mse: 1160.0533 - val_loss: -422.2972 - val_mse: 1192.7083\n",
            "Epoch 351/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0609 - mse: 1159.2743 - val_loss: -422.2713 - val_mse: 1196.7205\n",
            "Epoch 352/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.0519 - mse: 1159.9333 - val_loss: -422.2488 - val_mse: 1195.3151\n",
            "Epoch 353/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0529 - mse: 1158.8551 - val_loss: -422.2932 - val_mse: 1193.1162\n",
            "Epoch 354/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0509 - mse: 1157.5565 - val_loss: -422.2993 - val_mse: 1192.5615\n",
            "Epoch 355/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0668 - mse: 1157.3016 - val_loss: -422.1814 - val_mse: 1198.4478\n",
            "Epoch 356/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0639 - mse: 1156.9962 - val_loss: -422.2251 - val_mse: 1197.1946\n",
            "Epoch 357/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0723 - mse: 1155.7781 - val_loss: -422.2934 - val_mse: 1186.6418\n",
            "Epoch 358/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0841 - mse: 1153.4442 - val_loss: -422.3053 - val_mse: 1189.7506\n",
            "Epoch 359/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.0843 - mse: 1154.5341 - val_loss: -422.3046 - val_mse: 1187.5067\n",
            "Epoch 360/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0858 - mse: 1154.2040 - val_loss: -422.2816 - val_mse: 1189.7822\n",
            "Epoch 361/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0812 - mse: 1153.5468 - val_loss: -422.2712 - val_mse: 1194.4246\n",
            "Epoch 362/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0724 - mse: 1153.4969 - val_loss: -422.2688 - val_mse: 1189.4194\n",
            "Epoch 363/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0832 - mse: 1151.4209 - val_loss: -422.2359 - val_mse: 1190.2830\n",
            "Epoch 364/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0972 - mse: 1150.4581 - val_loss: -422.2997 - val_mse: 1193.7056\n",
            "Epoch 365/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0954 - mse: 1150.1466 - val_loss: -422.2904 - val_mse: 1198.6479\n",
            "Epoch 366/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0983 - mse: 1151.2885 - val_loss: -422.1947 - val_mse: 1190.5613\n",
            "Epoch 367/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0850 - mse: 1148.5667 - val_loss: -422.3130 - val_mse: 1189.0695\n",
            "Epoch 368/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0971 - mse: 1148.6957 - val_loss: -422.1561 - val_mse: 1200.9980\n",
            "Epoch 369/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1042 - mse: 1149.4338 - val_loss: -422.3081 - val_mse: 1182.5789\n",
            "Epoch 370/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1182 - mse: 1145.9894 - val_loss: -422.2950 - val_mse: 1195.3766\n",
            "Epoch 371/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1043 - mse: 1149.9537 - val_loss: -422.2847 - val_mse: 1181.2577\n",
            "Epoch 372/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1214 - mse: 1145.8885 - val_loss: -422.3035 - val_mse: 1181.0188\n",
            "Epoch 373/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1226 - mse: 1144.7249 - val_loss: -422.1801 - val_mse: 1194.7990\n",
            "Epoch 374/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1200 - mse: 1144.9222 - val_loss: -422.2956 - val_mse: 1191.3794\n",
            "Epoch 375/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1110 - mse: 1146.0244 - val_loss: -422.3027 - val_mse: 1187.0161\n",
            "Epoch 376/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1161 - mse: 1143.3090 - val_loss: -422.2982 - val_mse: 1186.2701\n",
            "Epoch 377/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1090 - mse: 1145.0380 - val_loss: -422.1506 - val_mse: 1197.1312\n",
            "Epoch 378/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1305 - mse: 1144.1146 - val_loss: -422.3120 - val_mse: 1180.9550\n",
            "Epoch 379/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.1248 - mse: 1142.2023 - val_loss: -422.3101 - val_mse: 1186.2719\n",
            "Epoch 380/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1198 - mse: 1142.1573 - val_loss: -422.3144 - val_mse: 1183.9319\n",
            "Epoch 381/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.1321 - mse: 1141.2104 - val_loss: -422.3235 - val_mse: 1186.6488\n",
            "Epoch 382/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1330 - mse: 1141.2214 - val_loss: -422.2831 - val_mse: 1191.1042\n",
            "Epoch 383/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.1370 - mse: 1142.8324 - val_loss: -422.2896 - val_mse: 1185.5349\n",
            "Epoch 384/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1339 - mse: 1140.1807 - val_loss: -422.3003 - val_mse: 1186.1157\n",
            "Epoch 385/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1475 - mse: 1138.3044 - val_loss: -422.2632 - val_mse: 1188.7816\n",
            "Epoch 386/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1396 - mse: 1140.5710 - val_loss: -422.3117 - val_mse: 1182.1108\n",
            "Epoch 387/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1558 - mse: 1138.1304 - val_loss: -422.3228 - val_mse: 1185.5129\n",
            "Epoch 388/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1463 - mse: 1138.1783 - val_loss: -422.2560 - val_mse: 1181.2477\n",
            "Epoch 389/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1603 - mse: 1137.2704 - val_loss: -422.3006 - val_mse: 1179.3718\n",
            "Epoch 390/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1502 - mse: 1136.7063 - val_loss: -422.3207 - val_mse: 1184.2898\n",
            "Epoch 391/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1596 - mse: 1137.4866 - val_loss: -422.3166 - val_mse: 1178.4146\n",
            "Epoch 392/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1621 - mse: 1134.6311 - val_loss: -422.3153 - val_mse: 1186.2695\n",
            "Epoch 393/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1503 - mse: 1136.3312 - val_loss: -422.2708 - val_mse: 1184.7924\n",
            "Epoch 394/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1665 - mse: 1134.5782 - val_loss: -422.2932 - val_mse: 1183.3916\n",
            "Epoch 395/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.1449 - mse: 1135.4449 - val_loss: -422.2851 - val_mse: 1182.5883\n",
            "Epoch 396/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1748 - mse: 1132.7294 - val_loss: -422.3240 - val_mse: 1183.0142\n",
            "Epoch 397/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1742 - mse: 1132.2799 - val_loss: -422.3106 - val_mse: 1186.7130\n",
            "Epoch 398/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1722 - mse: 1133.4578 - val_loss: -422.3043 - val_mse: 1186.1259\n",
            "Epoch 399/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.1759 - mse: 1133.1127 - val_loss: -422.3208 - val_mse: 1182.4790\n",
            "Epoch 400/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.1689 - mse: 1132.8055 - val_loss: -422.2923 - val_mse: 1185.2087\n",
            "Epoch 401/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1801 - mse: 1130.9890 - val_loss: -422.3024 - val_mse: 1186.1962\n",
            "Epoch 402/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.1870 - mse: 1130.1339 - val_loss: -422.3179 - val_mse: 1182.4426\n",
            "Epoch 403/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.1903 - mse: 1130.1700 - val_loss: -422.3189 - val_mse: 1182.5934\n",
            "Epoch 404/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.1830 - mse: 1128.8636 - val_loss: -422.2876 - val_mse: 1192.3694\n",
            "Epoch 405/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1801 - mse: 1130.6584 - val_loss: -422.3057 - val_mse: 1180.1552\n",
            "Epoch 406/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1832 - mse: 1128.0636 - val_loss: -422.2929 - val_mse: 1186.8198\n",
            "Epoch 407/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.1926 - mse: 1129.7343 - val_loss: -422.2675 - val_mse: 1181.7102\n",
            "Epoch 408/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1767 - mse: 1128.7120 - val_loss: -422.2986 - val_mse: 1186.2719\n",
            "Epoch 409/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.1947 - mse: 1128.3909 - val_loss: -422.3161 - val_mse: 1176.4354\n",
            "Epoch 410/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.2024 - mse: 1125.9399 - val_loss: -422.3223 - val_mse: 1181.7061\n",
            "Epoch 411/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.2023 - mse: 1128.1217 - val_loss: -422.3204 - val_mse: 1174.4535\n",
            "Save file name colab_notebook_data/feature_interactions/trained_models/poissonloss/poscontrol_model-skipconn_l1reg-0.0_seed100_qzkpt.h5\n",
            "Training model colab_notebook_data/feature_interactions/trained_models/poissonloss/negcontrol_model-skipconn_l1reg-0.0_seed100_sgkcd.h5\n",
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           (None, 100, 4)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 76, 64)       6464        input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_15 (Gl (None, 64)           0           conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 64)           4160        global_average_pooling1d_15[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 1)            65          global_average_pooling1d_15[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 1)            65          dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 1)            0           dense_16[0][0]                   \n",
            "                                                                 dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 1)            0           add_2[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 10,754\n",
            "Trainable params: 10,754\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "40000/40000 [==============================] - 1s 28us/step - loss: -328.2726 - mse: 20319.9219 - val_loss: -446.0805 - val_mse: 15970.5615\n",
            "Epoch 2/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -482.7324 - mse: 12325.1660 - val_loss: -504.8411 - val_mse: 9472.0020\n",
            "Epoch 3/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -512.2069 - mse: 8147.8130 - val_loss: -516.1017 - val_mse: 7334.0000\n",
            "Epoch 4/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -517.3067 - mse: 7082.8208 - val_loss: -517.6553 - val_mse: 6965.1050\n",
            "Epoch 5/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -517.9041 - mse: 6936.0688 - val_loss: -517.7891 - val_mse: 6930.5190\n",
            "Epoch 6/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -517.9550 - mse: 6922.7456 - val_loss: -517.8034 - val_mse: 6926.6978\n",
            "Epoch 7/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -517.9650 - mse: 6920.0654 - val_loss: -517.8110 - val_mse: 6924.6670\n",
            "Epoch 8/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -517.9729 - mse: 6917.9521 - val_loss: -517.8197 - val_mse: 6922.3672\n",
            "Epoch 9/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -517.9823 - mse: 6915.4639 - val_loss: -517.8301 - val_mse: 6919.5713\n",
            "Epoch 10/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -517.9942 - mse: 6912.3096 - val_loss: -517.8429 - val_mse: 6916.1577\n",
            "Epoch 11/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -518.0098 - mse: 6908.1582 - val_loss: -517.8569 - val_mse: 6912.3457\n",
            "Epoch 12/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -518.0267 - mse: 6903.6274 - val_loss: -517.8795 - val_mse: 6906.4575\n",
            "Epoch 13/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -518.0521 - mse: 6896.9658 - val_loss: -517.9052 - val_mse: 6899.5454\n",
            "Epoch 14/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -518.0813 - mse: 6889.0840 - val_loss: -517.9404 - val_mse: 6890.2886\n",
            "Epoch 15/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -518.1235 - mse: 6878.0503 - val_loss: -517.9883 - val_mse: 6877.4814\n",
            "Epoch 16/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -518.1846 - mse: 6861.8218 - val_loss: -518.0610 - val_mse: 6858.2080\n",
            "Epoch 17/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -518.2789 - mse: 6836.9160 - val_loss: -518.1788 - val_mse: 6827.8647\n",
            "Epoch 18/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -518.4274 - mse: 6797.9185 - val_loss: -518.3567 - val_mse: 6780.5898\n",
            "Epoch 19/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -518.6504 - mse: 6739.4961 - val_loss: -518.6049 - val_mse: 6714.9727\n",
            "Epoch 20/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -518.9485 - mse: 6661.8999 - val_loss: -518.9177 - val_mse: 6638.3413\n",
            "Epoch 21/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -519.2836 - mse: 6575.8281 - val_loss: -519.2259 - val_mse: 6553.7061\n",
            "Epoch 22/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -519.5744 - mse: 6500.5728 - val_loss: -519.4851 - val_mse: 6491.6035\n",
            "Epoch 23/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -519.8022 - mse: 6443.8691 - val_loss: -519.6629 - val_mse: 6449.8486\n",
            "Epoch 24/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -519.9370 - mse: 6410.6382 - val_loss: -519.7630 - val_mse: 6425.0342\n",
            "Epoch 25/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.0365 - mse: 6386.7886 - val_loss: -519.7958 - val_mse: 6418.1689\n",
            "Epoch 26/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.0676 - mse: 6379.4917 - val_loss: -519.8276 - val_mse: 6412.7202\n",
            "Epoch 27/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.0817 - mse: 6376.8901 - val_loss: -519.8046 - val_mse: 6419.9160\n",
            "Epoch 28/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.0839 - mse: 6376.2803 - val_loss: -519.8348 - val_mse: 6412.3838\n",
            "Epoch 29/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -520.0914 - mse: 6375.6938 - val_loss: -519.8458 - val_mse: 6409.8105\n",
            "Epoch 30/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -520.0813 - mse: 6378.1118 - val_loss: -519.8339 - val_mse: 6413.0762\n",
            "Epoch 31/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.0885 - mse: 6376.2598 - val_loss: -519.8543 - val_mse: 6408.0649\n",
            "Epoch 32/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -520.0990 - mse: 6373.1172 - val_loss: -519.8591 - val_mse: 6406.8726\n",
            "Epoch 33/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -520.0954 - mse: 6374.6558 - val_loss: -519.8206 - val_mse: 6416.6631\n",
            "Epoch 34/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1003 - mse: 6373.5908 - val_loss: -519.8311 - val_mse: 6414.8706\n",
            "Epoch 35/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -520.0987 - mse: 6373.9502 - val_loss: -519.8642 - val_mse: 6406.0059\n",
            "Epoch 36/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1056 - mse: 6372.3066 - val_loss: -519.8741 - val_mse: 6403.4614\n",
            "Epoch 37/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -520.1137 - mse: 6370.0684 - val_loss: -519.8824 - val_mse: 6401.5073\n",
            "Epoch 38/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1266 - mse: 6366.7622 - val_loss: -519.8868 - val_mse: 6400.4727\n",
            "Epoch 39/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1251 - mse: 6367.2188 - val_loss: -519.8905 - val_mse: 6399.6167\n",
            "Epoch 40/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1288 - mse: 6367.0386 - val_loss: -519.8219 - val_mse: 6418.3735\n",
            "Epoch 41/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -520.1268 - mse: 6367.2197 - val_loss: -519.8983 - val_mse: 6398.0039\n",
            "Epoch 42/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -520.1280 - mse: 6366.6914 - val_loss: -519.8819 - val_mse: 6401.9531\n",
            "Epoch 43/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -520.1368 - mse: 6365.0806 - val_loss: -519.8777 - val_mse: 6404.3418\n",
            "Epoch 44/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -520.1432 - mse: 6362.8647 - val_loss: -519.9097 - val_mse: 6395.6533\n",
            "Epoch 45/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1480 - mse: 6362.1558 - val_loss: -519.9167 - val_mse: 6393.7334\n",
            "Epoch 46/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -520.1655 - mse: 6357.7290 - val_loss: -519.9076 - val_mse: 6396.1450\n",
            "Epoch 47/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1623 - mse: 6358.0879 - val_loss: -519.9309 - val_mse: 6390.3545\n",
            "Epoch 48/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1715 - mse: 6356.1572 - val_loss: -519.9369 - val_mse: 6388.7847\n",
            "Epoch 49/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1877 - mse: 6351.8252 - val_loss: -519.8705 - val_mse: 6405.7549\n",
            "Epoch 50/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -520.1987 - mse: 6349.0830 - val_loss: -519.9514 - val_mse: 6385.1792\n",
            "Epoch 51/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.2138 - mse: 6345.5371 - val_loss: -519.9739 - val_mse: 6379.2773\n",
            "Epoch 52/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.2278 - mse: 6342.0996 - val_loss: -519.9578 - val_mse: 6383.9844\n",
            "Epoch 53/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.2444 - mse: 6336.9976 - val_loss: -520.0191 - val_mse: 6367.7305\n",
            "Epoch 54/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.2774 - mse: 6329.3208 - val_loss: -520.0481 - val_mse: 6360.0620\n",
            "Epoch 55/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.3041 - mse: 6322.0898 - val_loss: -520.0580 - val_mse: 6358.3740\n",
            "Epoch 56/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.3336 - mse: 6315.1846 - val_loss: -520.0883 - val_mse: 6350.6470\n",
            "Epoch 57/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.3698 - mse: 6305.4663 - val_loss: -520.1521 - val_mse: 6333.7178\n",
            "Epoch 58/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -520.4257 - mse: 6291.4434 - val_loss: -520.1742 - val_mse: 6329.4746\n",
            "Epoch 59/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.4816 - mse: 6277.3813 - val_loss: -520.2391 - val_mse: 6309.8374\n",
            "Epoch 60/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.5349 - mse: 6263.4761 - val_loss: -520.2474 - val_mse: 6306.2383\n",
            "Epoch 61/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.6319 - mse: 6238.7451 - val_loss: -520.4019 - val_mse: 6270.4854\n",
            "Epoch 62/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.7124 - mse: 6217.5830 - val_loss: -520.4354 - val_mse: 6257.5718\n",
            "Epoch 63/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.8231 - mse: 6189.6255 - val_loss: -520.5891 - val_mse: 6222.7271\n",
            "Epoch 64/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.9428 - mse: 6158.3994 - val_loss: -520.7286 - val_mse: 6184.9634\n",
            "Epoch 65/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -521.0907 - mse: 6120.9102 - val_loss: -520.8828 - val_mse: 6143.4272\n",
            "Epoch 66/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -521.2514 - mse: 6078.6045 - val_loss: -521.0350 - val_mse: 6100.1519\n",
            "Epoch 67/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -521.4652 - mse: 6023.8335 - val_loss: -521.0604 - val_mse: 6110.9790\n",
            "Epoch 68/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -521.6713 - mse: 5972.0601 - val_loss: -521.4993 - val_mse: 5983.8911\n",
            "Epoch 69/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -521.9336 - mse: 5902.9561 - val_loss: -521.7719 - val_mse: 5915.4424\n",
            "Epoch 70/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -522.2344 - mse: 5826.8628 - val_loss: -522.0672 - val_mse: 5831.6748\n",
            "Epoch 71/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -522.5557 - mse: 5745.8516 - val_loss: -522.3791 - val_mse: 5768.8853\n",
            "Epoch 72/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -522.9304 - mse: 5652.1890 - val_loss: -522.5049 - val_mse: 5756.9873\n",
            "Epoch 73/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -523.2795 - mse: 5564.4565 - val_loss: -523.1378 - val_mse: 5567.2607\n",
            "Epoch 74/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -523.6764 - mse: 5464.4766 - val_loss: -523.4666 - val_mse: 5497.6338\n",
            "Epoch 75/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -524.0683 - mse: 5368.8975 - val_loss: -523.8480 - val_mse: 5372.1787\n",
            "Epoch 76/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -524.4107 - mse: 5283.0605 - val_loss: -524.2328 - val_mse: 5291.6738\n",
            "Epoch 77/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -524.7687 - mse: 5194.8145 - val_loss: -524.5118 - val_mse: 5236.7427\n",
            "Epoch 78/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -525.1002 - mse: 5115.1250 - val_loss: -524.8655 - val_mse: 5131.2759\n",
            "Epoch 79/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -525.4363 - mse: 5033.3662 - val_loss: -525.1493 - val_mse: 5050.0347\n",
            "Epoch 80/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -525.7082 - mse: 4969.1353 - val_loss: -525.3733 - val_mse: 5023.2505\n",
            "Epoch 81/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -526.0019 - mse: 4897.6626 - val_loss: -525.6889 - val_mse: 4930.6929\n",
            "Epoch 82/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -526.2551 - mse: 4832.0020 - val_loss: -525.6698 - val_mse: 4961.1611\n",
            "Epoch 83/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -526.5248 - mse: 4772.7808 - val_loss: -526.1924 - val_mse: 4799.0732\n",
            "Epoch 84/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -526.7695 - mse: 4710.9971 - val_loss: -526.4254 - val_mse: 4747.6084\n",
            "Epoch 85/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -526.9747 - mse: 4665.8418 - val_loss: -526.6430 - val_mse: 4682.4922\n",
            "Epoch 86/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -527.2317 - mse: 4600.7593 - val_loss: -526.7211 - val_mse: 4672.0342\n",
            "Epoch 87/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -527.4618 - mse: 4550.4995 - val_loss: -527.0127 - val_mse: 4590.5371\n",
            "Epoch 88/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -527.6663 - mse: 4497.4556 - val_loss: -527.1334 - val_mse: 4541.5703\n",
            "Epoch 89/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -527.8735 - mse: 4451.3315 - val_loss: -527.3413 - val_mse: 4490.5293\n",
            "Epoch 90/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -528.0731 - mse: 4404.0171 - val_loss: -527.7555 - val_mse: 4412.4883\n",
            "Epoch 91/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -528.2782 - mse: 4356.9023 - val_loss: -527.7256 - val_mse: 4445.1753\n",
            "Epoch 92/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -528.5403 - mse: 4298.9346 - val_loss: -528.1282 - val_mse: 4328.0122\n",
            "Epoch 93/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -528.7320 - mse: 4252.3281 - val_loss: -528.3312 - val_mse: 4272.0928\n",
            "Epoch 94/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -528.8782 - mse: 4220.6841 - val_loss: -528.4926 - val_mse: 4252.5010\n",
            "Epoch 95/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -529.1216 - mse: 4164.7334 - val_loss: -528.6636 - val_mse: 4187.6123\n",
            "Epoch 96/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -529.3391 - mse: 4118.6011 - val_loss: -528.9589 - val_mse: 4133.9434\n",
            "Epoch 97/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -529.4941 - mse: 4077.4287 - val_loss: -529.0386 - val_mse: 4096.6143\n",
            "Epoch 98/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -529.6621 - mse: 4041.3860 - val_loss: -529.3459 - val_mse: 4046.7612\n",
            "Epoch 99/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -529.9165 - mse: 3984.9573 - val_loss: -529.3042 - val_mse: 4083.1165\n",
            "Epoch 100/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -530.0566 - mse: 3954.3865 - val_loss: -529.7062 - val_mse: 3972.7568\n",
            "Epoch 101/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -530.2834 - mse: 3901.9199 - val_loss: -529.8947 - val_mse: 3932.1340\n",
            "Epoch 102/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -530.4160 - mse: 3870.4641 - val_loss: -530.0786 - val_mse: 3892.3999\n",
            "Epoch 103/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -530.5864 - mse: 3834.2205 - val_loss: -530.2518 - val_mse: 3845.6692\n",
            "Epoch 104/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -530.7601 - mse: 3795.4741 - val_loss: -530.3877 - val_mse: 3815.8933\n",
            "Epoch 105/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -530.9207 - mse: 3753.7744 - val_loss: -530.5883 - val_mse: 3773.6399\n",
            "Epoch 106/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -531.0880 - mse: 3720.9153 - val_loss: -530.5386 - val_mse: 3812.8916\n",
            "Epoch 107/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -531.2732 - mse: 3682.6165 - val_loss: -530.8777 - val_mse: 3714.0525\n",
            "Epoch 108/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -531.4324 - mse: 3648.4805 - val_loss: -531.0384 - val_mse: 3681.1685\n",
            "Epoch 109/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -531.5802 - mse: 3611.8113 - val_loss: -531.2075 - val_mse: 3639.5232\n",
            "Epoch 110/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -531.7249 - mse: 3583.3088 - val_loss: -531.3695 - val_mse: 3602.4976\n",
            "Epoch 111/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -531.8949 - mse: 3548.6836 - val_loss: -531.5083 - val_mse: 3577.4504\n",
            "Epoch 112/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -532.0217 - mse: 3513.1812 - val_loss: -531.6664 - val_mse: 3524.1936\n",
            "Epoch 113/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -532.1840 - mse: 3483.8081 - val_loss: -531.8165 - val_mse: 3504.5071\n",
            "Epoch 114/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -532.3395 - mse: 3452.7449 - val_loss: -531.8992 - val_mse: 3468.0901\n",
            "Epoch 115/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -532.4094 - mse: 3434.8391 - val_loss: -531.8233 - val_mse: 3535.2888\n",
            "Epoch 116/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -532.5501 - mse: 3403.3640 - val_loss: -532.2026 - val_mse: 3401.5991\n",
            "Epoch 117/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -532.6736 - mse: 3375.5801 - val_loss: -532.3511 - val_mse: 3375.1360\n",
            "Epoch 118/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -532.8603 - mse: 3338.8047 - val_loss: -532.3266 - val_mse: 3408.3733\n",
            "Epoch 119/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -532.9783 - mse: 3315.2107 - val_loss: -532.5171 - val_mse: 3326.3499\n",
            "Epoch 120/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -533.1377 - mse: 3282.5469 - val_loss: -532.6464 - val_mse: 3334.0059\n",
            "Epoch 121/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -533.2786 - mse: 3252.8640 - val_loss: -532.9135 - val_mse: 3268.7683\n",
            "Epoch 122/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -533.3897 - mse: 3226.9956 - val_loss: -532.9948 - val_mse: 3259.1196\n",
            "Epoch 123/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -533.5250 - mse: 3200.4768 - val_loss: -533.0143 - val_mse: 3227.4441\n",
            "Epoch 124/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -533.6537 - mse: 3176.3083 - val_loss: -533.2901 - val_mse: 3187.9688\n",
            "Epoch 125/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -533.7547 - mse: 3155.5359 - val_loss: -533.4105 - val_mse: 3158.4121\n",
            "Epoch 126/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -533.8679 - mse: 3129.9724 - val_loss: -533.5549 - val_mse: 3140.4707\n",
            "Epoch 127/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -534.0066 - mse: 3102.2771 - val_loss: -533.5284 - val_mse: 3114.7625\n",
            "Epoch 128/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -534.1326 - mse: 3079.1736 - val_loss: -533.7642 - val_mse: 3082.6399\n",
            "Epoch 129/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -534.2694 - mse: 3050.6931 - val_loss: -533.8746 - val_mse: 3057.3811\n",
            "Epoch 130/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -534.4072 - mse: 3024.3499 - val_loss: -534.0387 - val_mse: 3041.1919\n",
            "Epoch 131/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -534.4976 - mse: 3007.6970 - val_loss: -534.1497 - val_mse: 3021.9102\n",
            "Epoch 132/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -534.6408 - mse: 2978.0266 - val_loss: -534.2796 - val_mse: 2987.5288\n",
            "Epoch 133/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -534.7320 - mse: 2958.1790 - val_loss: -534.3793 - val_mse: 2977.7151\n",
            "Epoch 134/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -534.8224 - mse: 2940.0139 - val_loss: -534.5144 - val_mse: 2937.5503\n",
            "Epoch 135/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -534.9251 - mse: 2919.3630 - val_loss: -534.6324 - val_mse: 2921.1252\n",
            "Epoch 136/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -535.0989 - mse: 2889.7266 - val_loss: -534.7247 - val_mse: 2909.9810\n",
            "Epoch 137/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -535.2323 - mse: 2861.6099 - val_loss: -534.7221 - val_mse: 2915.2578\n",
            "Epoch 138/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -535.3125 - mse: 2844.5806 - val_loss: -534.9784 - val_mse: 2842.5891\n",
            "Epoch 139/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -535.4515 - mse: 2815.9087 - val_loss: -535.1248 - val_mse: 2820.3445\n",
            "Epoch 140/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -535.5382 - mse: 2796.4724 - val_loss: -534.9141 - val_mse: 2828.5872\n",
            "Epoch 141/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -535.6520 - mse: 2779.5608 - val_loss: -535.3738 - val_mse: 2769.7617\n",
            "Epoch 142/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -535.8338 - mse: 2741.5476 - val_loss: -535.4572 - val_mse: 2767.5225\n",
            "Epoch 143/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -535.9672 - mse: 2716.0872 - val_loss: -535.6336 - val_mse: 2722.2007\n",
            "Epoch 144/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -536.0535 - mse: 2700.0879 - val_loss: -535.7502 - val_mse: 2690.2405\n",
            "Epoch 145/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -536.2239 - mse: 2667.2820 - val_loss: -535.8361 - val_mse: 2692.1758\n",
            "Epoch 146/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -536.3188 - mse: 2648.4153 - val_loss: -535.9949 - val_mse: 2637.5283\n",
            "Epoch 147/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -536.4644 - mse: 2620.2478 - val_loss: -536.1365 - val_mse: 2628.9409\n",
            "Epoch 148/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -536.5632 - mse: 2599.6450 - val_loss: -536.2661 - val_mse: 2589.5530\n",
            "Epoch 149/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -536.6843 - mse: 2578.4194 - val_loss: -536.4034 - val_mse: 2573.6675\n",
            "Epoch 150/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -536.8303 - mse: 2550.5105 - val_loss: -536.2699 - val_mse: 2607.7722\n",
            "Epoch 151/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -536.9879 - mse: 2519.6072 - val_loss: -536.6528 - val_mse: 2513.7874\n",
            "Epoch 152/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -537.0968 - mse: 2498.0813 - val_loss: -536.7549 - val_mse: 2505.7788\n",
            "Epoch 153/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -537.2191 - mse: 2474.4070 - val_loss: -536.8206 - val_mse: 2494.9944\n",
            "Epoch 154/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -537.3509 - mse: 2451.4016 - val_loss: -536.9181 - val_mse: 2476.9338\n",
            "Epoch 155/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -537.4812 - mse: 2426.5706 - val_loss: -536.9529 - val_mse: 2430.1721\n",
            "Epoch 156/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -537.5851 - mse: 2406.2051 - val_loss: -537.2737 - val_mse: 2387.6765\n",
            "Epoch 157/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -537.7403 - mse: 2377.9597 - val_loss: -537.4022 - val_mse: 2366.4539\n",
            "Epoch 158/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -537.8287 - mse: 2357.3679 - val_loss: -537.5078 - val_mse: 2354.3335\n",
            "Epoch 159/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -537.9458 - mse: 2331.6567 - val_loss: -537.5032 - val_mse: 2319.6833\n",
            "Epoch 160/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -538.0657 - mse: 2309.2671 - val_loss: -537.7634 - val_mse: 2295.7734\n",
            "Epoch 161/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -538.1966 - mse: 2287.3699 - val_loss: -537.8776 - val_mse: 2281.4363\n",
            "Epoch 162/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -538.2933 - mse: 2267.8809 - val_loss: -537.9975 - val_mse: 2246.8391\n",
            "Epoch 163/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -538.4587 - mse: 2239.2432 - val_loss: -538.0976 - val_mse: 2241.6685\n",
            "Epoch 164/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -538.5545 - mse: 2219.7041 - val_loss: -538.2357 - val_mse: 2207.6748\n",
            "Epoch 165/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -538.6773 - mse: 2197.9487 - val_loss: -538.2302 - val_mse: 2217.1360\n",
            "Epoch 166/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -538.7653 - mse: 2179.4070 - val_loss: -538.4434 - val_mse: 2173.9346\n",
            "Epoch 167/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -538.9112 - mse: 2153.7383 - val_loss: -538.5658 - val_mse: 2144.4287\n",
            "Epoch 168/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -539.0081 - mse: 2135.3308 - val_loss: -538.5694 - val_mse: 2154.8518\n",
            "Epoch 169/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -539.1075 - mse: 2116.8599 - val_loss: -538.7857 - val_mse: 2103.6372\n",
            "Epoch 170/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -539.1912 - mse: 2098.5173 - val_loss: -538.8984 - val_mse: 2089.2393\n",
            "Epoch 171/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -539.3165 - mse: 2079.0271 - val_loss: -538.9834 - val_mse: 2074.7874\n",
            "Epoch 172/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -539.4296 - mse: 2057.2524 - val_loss: -539.0740 - val_mse: 2062.1619\n",
            "Epoch 173/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -539.5368 - mse: 2038.4606 - val_loss: -539.2003 - val_mse: 2024.2524\n",
            "Epoch 174/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -539.6132 - mse: 2024.0040 - val_loss: -539.1587 - val_mse: 2022.6432\n",
            "Epoch 175/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -539.7099 - mse: 2004.6062 - val_loss: -539.4169 - val_mse: 1987.3196\n",
            "Epoch 176/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -539.8334 - mse: 1984.0148 - val_loss: -539.4179 - val_mse: 1978.0900\n",
            "Epoch 177/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -539.9317 - mse: 1966.5032 - val_loss: -539.5849 - val_mse: 1970.4530\n",
            "Epoch 178/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -540.0285 - mse: 1949.9583 - val_loss: -539.7190 - val_mse: 1935.6698\n",
            "Epoch 179/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -540.1152 - mse: 1934.6160 - val_loss: -539.7927 - val_mse: 1931.6586\n",
            "Epoch 180/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -540.2296 - mse: 1914.1042 - val_loss: -539.8788 - val_mse: 1901.8956\n",
            "Epoch 181/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -540.3492 - mse: 1893.8848 - val_loss: -540.0173 - val_mse: 1885.8503\n",
            "Epoch 182/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -540.4126 - mse: 1879.8942 - val_loss: -540.0652 - val_mse: 1885.0908\n",
            "Epoch 183/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -540.5341 - mse: 1858.8903 - val_loss: -540.2167 - val_mse: 1854.4493\n",
            "Epoch 184/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -540.5971 - mse: 1849.2798 - val_loss: -540.2881 - val_mse: 1842.8990\n",
            "Epoch 185/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -540.7306 - mse: 1824.3096 - val_loss: -540.4157 - val_mse: 1815.9380\n",
            "Epoch 186/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -540.8137 - mse: 1808.5872 - val_loss: -540.4966 - val_mse: 1793.4176\n",
            "Epoch 187/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -540.9281 - mse: 1786.5938 - val_loss: -540.6243 - val_mse: 1772.7472\n",
            "Epoch 188/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -541.0344 - mse: 1765.6595 - val_loss: -540.7126 - val_mse: 1765.0776\n",
            "Epoch 189/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -541.1421 - mse: 1745.6820 - val_loss: -540.8421 - val_mse: 1730.7087\n",
            "Epoch 190/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -541.2483 - mse: 1722.8588 - val_loss: -540.9359 - val_mse: 1708.2500\n",
            "Epoch 191/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -541.3808 - mse: 1697.4626 - val_loss: -541.0912 - val_mse: 1688.7504\n",
            "Epoch 192/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -541.5212 - mse: 1671.5120 - val_loss: -541.2125 - val_mse: 1665.9976\n",
            "Epoch 193/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -541.5920 - mse: 1652.2555 - val_loss: -541.3517 - val_mse: 1637.6373\n",
            "Epoch 194/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -541.7736 - mse: 1620.9888 - val_loss: -541.4314 - val_mse: 1630.5840\n",
            "Epoch 195/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -541.8899 - mse: 1598.0011 - val_loss: -541.4455 - val_mse: 1599.9504\n",
            "Epoch 196/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -542.0202 - mse: 1572.2822 - val_loss: -541.7251 - val_mse: 1569.4698\n",
            "Epoch 197/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -542.1375 - mse: 1552.5669 - val_loss: -541.8614 - val_mse: 1548.1698\n",
            "Epoch 198/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -542.2780 - mse: 1528.1952 - val_loss: -541.9499 - val_mse: 1538.5828\n",
            "Epoch 199/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -542.4012 - mse: 1506.8037 - val_loss: -542.1032 - val_mse: 1504.4922\n",
            "Epoch 200/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -542.4977 - mse: 1486.1658 - val_loss: -542.2148 - val_mse: 1494.8000\n",
            "Epoch 201/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -542.6228 - mse: 1467.6523 - val_loss: -542.1938 - val_mse: 1497.3979\n",
            "Epoch 202/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -542.7251 - mse: 1448.8022 - val_loss: -542.2547 - val_mse: 1491.7913\n",
            "Epoch 203/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -542.8547 - mse: 1429.7433 - val_loss: -542.5443 - val_mse: 1430.2023\n",
            "Epoch 204/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -542.9514 - mse: 1411.3615 - val_loss: -542.5857 - val_mse: 1441.5000\n",
            "Epoch 205/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.0342 - mse: 1398.0438 - val_loss: -542.7753 - val_mse: 1399.6613\n",
            "Epoch 206/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -543.1534 - mse: 1377.7001 - val_loss: -542.8253 - val_mse: 1400.6317\n",
            "Epoch 207/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -543.2278 - mse: 1365.1718 - val_loss: -542.9758 - val_mse: 1369.2020\n",
            "Epoch 208/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -543.3387 - mse: 1347.2280 - val_loss: -542.6453 - val_mse: 1422.4371\n",
            "Epoch 209/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -543.4353 - mse: 1331.9006 - val_loss: -543.1352 - val_mse: 1335.7147\n",
            "Epoch 210/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.4968 - mse: 1319.4823 - val_loss: -543.2510 - val_mse: 1328.4862\n",
            "Epoch 211/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -543.5978 - mse: 1302.5212 - val_loss: -543.3036 - val_mse: 1321.7814\n",
            "Epoch 212/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.6624 - mse: 1290.2087 - val_loss: -543.4149 - val_mse: 1301.9839\n",
            "Epoch 213/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.7714 - mse: 1271.6091 - val_loss: -543.4754 - val_mse: 1292.7369\n",
            "Epoch 214/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.8460 - mse: 1258.9948 - val_loss: -543.5941 - val_mse: 1267.4276\n",
            "Epoch 215/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.9309 - mse: 1243.2550 - val_loss: -543.6015 - val_mse: 1270.6975\n",
            "Epoch 216/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.9746 - mse: 1232.8711 - val_loss: -543.7669 - val_mse: 1234.4810\n",
            "Epoch 217/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -544.0648 - mse: 1215.0264 - val_loss: -543.8322 - val_mse: 1226.7888\n",
            "Epoch 218/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.1659 - mse: 1197.1591 - val_loss: -543.8664 - val_mse: 1219.5039\n",
            "Epoch 219/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -544.2515 - mse: 1181.6757 - val_loss: -544.0167 - val_mse: 1187.5431\n",
            "Epoch 220/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.3262 - mse: 1165.7325 - val_loss: -544.0921 - val_mse: 1176.6123\n",
            "Epoch 221/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.4123 - mse: 1149.8470 - val_loss: -544.1651 - val_mse: 1163.5750\n",
            "Epoch 222/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -544.4946 - mse: 1134.6072 - val_loss: -544.2467 - val_mse: 1146.4208\n",
            "Epoch 223/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -544.5605 - mse: 1122.0238 - val_loss: -544.2721 - val_mse: 1145.3282\n",
            "Epoch 224/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.6102 - mse: 1110.7043 - val_loss: -544.3894 - val_mse: 1116.8918\n",
            "Epoch 225/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.6932 - mse: 1096.5162 - val_loss: -544.4193 - val_mse: 1107.8416\n",
            "Epoch 226/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.7751 - mse: 1083.6442 - val_loss: -544.5223 - val_mse: 1097.0625\n",
            "Epoch 227/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -544.8169 - mse: 1075.4681 - val_loss: -544.4981 - val_mse: 1104.9290\n",
            "Epoch 228/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.8803 - mse: 1062.1505 - val_loss: -544.6202 - val_mse: 1084.8527\n",
            "Epoch 229/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -544.9494 - mse: 1053.2518 - val_loss: -544.7005 - val_mse: 1071.7395\n",
            "Epoch 230/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.0105 - mse: 1043.9968 - val_loss: -544.7587 - val_mse: 1060.7823\n",
            "Epoch 231/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.0587 - mse: 1035.9690 - val_loss: -544.7354 - val_mse: 1065.4601\n",
            "Epoch 232/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -545.1240 - mse: 1025.0303 - val_loss: -544.8712 - val_mse: 1045.1188\n",
            "Epoch 233/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.1793 - mse: 1015.3683 - val_loss: -544.9254 - val_mse: 1032.4393\n",
            "Epoch 234/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.2163 - mse: 1007.3663 - val_loss: -544.9807 - val_mse: 1028.2490\n",
            "Epoch 235/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.2816 - mse: 998.5680 - val_loss: -545.0198 - val_mse: 1018.0568\n",
            "Epoch 236/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.3212 - mse: 990.7922 - val_loss: -545.0805 - val_mse: 1007.4557\n",
            "Epoch 237/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -545.3666 - mse: 981.5616 - val_loss: -545.0943 - val_mse: 999.0771\n",
            "Epoch 238/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.4003 - mse: 976.0729 - val_loss: -545.1115 - val_mse: 1003.8535\n",
            "Epoch 239/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -545.4576 - mse: 966.9656 - val_loss: -545.1524 - val_mse: 996.2999\n",
            "Epoch 240/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.4796 - mse: 961.8901 - val_loss: -545.0555 - val_mse: 1003.7598\n",
            "Epoch 241/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.5118 - mse: 956.9289 - val_loss: -545.2847 - val_mse: 976.7519\n",
            "Epoch 242/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.5604 - mse: 949.7102 - val_loss: -545.2895 - val_mse: 971.7119\n",
            "Epoch 243/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.5939 - mse: 944.5817 - val_loss: -545.3129 - val_mse: 964.9603\n",
            "Epoch 244/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.6035 - mse: 941.1603 - val_loss: -545.3725 - val_mse: 963.9302\n",
            "Epoch 245/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.6397 - mse: 935.6670 - val_loss: -545.4013 - val_mse: 956.2588\n",
            "Epoch 246/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.6728 - mse: 930.5805 - val_loss: -545.3778 - val_mse: 954.5621\n",
            "Epoch 247/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -545.6793 - mse: 929.3454 - val_loss: -545.4265 - val_mse: 947.5350\n",
            "Epoch 248/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.7295 - mse: 921.9413 - val_loss: -545.5030 - val_mse: 943.4684\n",
            "Epoch 249/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -545.7603 - mse: 917.3167 - val_loss: -545.5134 - val_mse: 942.6503\n",
            "Epoch 250/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.7805 - mse: 914.3464 - val_loss: -545.5554 - val_mse: 936.6529\n",
            "Epoch 251/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.7846 - mse: 912.4128 - val_loss: -545.5418 - val_mse: 936.5082\n",
            "Epoch 252/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -545.8150 - mse: 907.8115 - val_loss: -545.5824 - val_mse: 931.8346\n",
            "Epoch 253/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.8468 - mse: 902.8296 - val_loss: -545.5856 - val_mse: 929.4027\n",
            "Epoch 254/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -545.8579 - mse: 900.9017 - val_loss: -545.5936 - val_mse: 927.7467\n",
            "Epoch 255/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -545.8793 - mse: 897.5205 - val_loss: -545.6579 - val_mse: 922.3305\n",
            "Epoch 256/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -545.8891 - mse: 895.6507 - val_loss: -545.6690 - val_mse: 919.0463\n",
            "Epoch 257/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -545.9121 - mse: 891.4763 - val_loss: -545.6970 - val_mse: 915.1773\n",
            "Epoch 258/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -545.9355 - mse: 888.1673 - val_loss: -545.6701 - val_mse: 912.6563\n",
            "Epoch 259/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -545.9518 - mse: 885.9181 - val_loss: -545.4438 - val_mse: 932.1084\n",
            "Epoch 260/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -545.9689 - mse: 883.5754 - val_loss: -545.7476 - val_mse: 905.1143\n",
            "Epoch 261/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.9890 - mse: 880.1391 - val_loss: -545.7652 - val_mse: 906.9513\n",
            "Epoch 262/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.0100 - mse: 877.9370 - val_loss: -545.7758 - val_mse: 902.9858\n",
            "Epoch 263/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.0133 - mse: 875.8227 - val_loss: -545.7906 - val_mse: 901.0132\n",
            "Epoch 264/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.0353 - mse: 873.2317 - val_loss: -545.8123 - val_mse: 895.4256\n",
            "Epoch 265/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.0470 - mse: 871.3906 - val_loss: -545.8247 - val_mse: 895.1859\n",
            "Epoch 266/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.0285 - mse: 871.3332 - val_loss: -545.8403 - val_mse: 893.7379\n",
            "Epoch 267/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.0677 - mse: 866.8489 - val_loss: -545.8499 - val_mse: 891.3405\n",
            "Epoch 268/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.0916 - mse: 863.4701 - val_loss: -545.8628 - val_mse: 889.9896\n",
            "Epoch 269/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.1105 - mse: 862.1246 - val_loss: -545.8656 - val_mse: 886.9014\n",
            "Epoch 270/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.0957 - mse: 861.2060 - val_loss: -545.8924 - val_mse: 886.6034\n",
            "Epoch 271/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.1221 - mse: 859.3942 - val_loss: -545.9051 - val_mse: 884.2085\n",
            "Epoch 272/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.1454 - mse: 855.7620 - val_loss: -545.8107 - val_mse: 891.0821\n",
            "Epoch 273/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.1498 - mse: 854.9643 - val_loss: -545.8439 - val_mse: 885.4757\n",
            "Epoch 274/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.1718 - mse: 852.0948 - val_loss: -545.8888 - val_mse: 882.0563\n",
            "Epoch 275/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.1776 - mse: 850.6425 - val_loss: -545.9446 - val_mse: 875.0188\n",
            "Epoch 276/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.1766 - mse: 849.6971 - val_loss: -545.7987 - val_mse: 886.5347\n",
            "Epoch 277/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.1834 - mse: 847.5968 - val_loss: -545.9713 - val_mse: 872.3703\n",
            "Epoch 278/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.2111 - mse: 845.8934 - val_loss: -545.9705 - val_mse: 869.7940\n",
            "Epoch 279/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2302 - mse: 843.3282 - val_loss: -545.9812 - val_mse: 868.8397\n",
            "Epoch 280/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.2314 - mse: 841.2642 - val_loss: -545.9300 - val_mse: 873.9476\n",
            "Epoch 281/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.2421 - mse: 840.4678 - val_loss: -545.9470 - val_mse: 871.7661\n",
            "Epoch 282/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.2526 - mse: 838.8838 - val_loss: -546.0255 - val_mse: 864.9250\n",
            "Epoch 283/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2630 - mse: 837.0970 - val_loss: -546.0343 - val_mse: 864.6338\n",
            "Epoch 284/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.2787 - mse: 835.6884 - val_loss: -546.0433 - val_mse: 863.4449\n",
            "Epoch 285/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.2890 - mse: 834.2406 - val_loss: -546.0516 - val_mse: 861.0511\n",
            "Epoch 286/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.2959 - mse: 832.8091 - val_loss: -546.0651 - val_mse: 860.3762\n",
            "Epoch 287/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2982 - mse: 831.8869 - val_loss: -546.0711 - val_mse: 857.3596\n",
            "Epoch 288/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -546.3102 - mse: 829.9677 - val_loss: -545.9745 - val_mse: 863.5506\n",
            "Epoch 289/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.3192 - mse: 828.5231 - val_loss: -546.0832 - val_mse: 855.5002\n",
            "Epoch 290/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3401 - mse: 826.4131 - val_loss: -546.0965 - val_mse: 852.5983\n",
            "Epoch 291/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3446 - mse: 825.5449 - val_loss: -546.0975 - val_mse: 851.7660\n",
            "Epoch 292/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.3469 - mse: 824.0287 - val_loss: -546.1200 - val_mse: 851.7664\n",
            "Epoch 293/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.3576 - mse: 823.1069 - val_loss: -546.1077 - val_mse: 848.2471\n",
            "Epoch 294/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3722 - mse: 820.4915 - val_loss: -546.0960 - val_mse: 850.0748\n",
            "Epoch 295/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3785 - mse: 820.2737 - val_loss: -546.1445 - val_mse: 847.3370\n",
            "Epoch 296/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.3858 - mse: 818.3752 - val_loss: -546.1451 - val_mse: 844.6384\n",
            "Epoch 297/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.3960 - mse: 817.2835 - val_loss: -546.1439 - val_mse: 845.9469\n",
            "Epoch 298/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3780 - mse: 817.2902 - val_loss: -546.1672 - val_mse: 842.5903\n",
            "Epoch 299/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4230 - mse: 813.9114 - val_loss: -546.1762 - val_mse: 842.8851\n",
            "Epoch 300/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4205 - mse: 813.8563 - val_loss: -546.1715 - val_mse: 842.8854\n",
            "Epoch 301/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4349 - mse: 812.4087 - val_loss: -546.1893 - val_mse: 839.6165\n",
            "Epoch 302/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4399 - mse: 811.1903 - val_loss: -546.1047 - val_mse: 845.5506\n",
            "Epoch 303/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.4535 - mse: 809.3283 - val_loss: -546.1948 - val_mse: 838.9512\n",
            "Epoch 304/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.4504 - mse: 808.8965 - val_loss: -546.1938 - val_mse: 837.3759\n",
            "Epoch 305/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.4598 - mse: 807.6544 - val_loss: -546.1728 - val_mse: 838.1332\n",
            "Epoch 306/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4721 - mse: 806.4863 - val_loss: -546.2176 - val_mse: 835.2775\n",
            "Epoch 307/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.4677 - mse: 806.0458 - val_loss: -546.1984 - val_mse: 836.6492\n",
            "Epoch 308/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.4577 - mse: 805.3961 - val_loss: -546.0773 - val_mse: 845.0088\n",
            "Epoch 309/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4872 - mse: 803.4119 - val_loss: -546.2296 - val_mse: 831.0094\n",
            "Epoch 310/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4918 - mse: 801.5591 - val_loss: -546.2542 - val_mse: 828.6542\n",
            "Epoch 311/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5152 - mse: 800.5848 - val_loss: -546.2421 - val_mse: 829.6464\n",
            "Epoch 312/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.5155 - mse: 799.4106 - val_loss: -546.2509 - val_mse: 828.0375\n",
            "Epoch 313/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5208 - mse: 798.8512 - val_loss: -546.2468 - val_mse: 829.8716\n",
            "Epoch 314/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5193 - mse: 798.4689 - val_loss: -546.2649 - val_mse: 827.4681\n",
            "Epoch 315/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5219 - mse: 797.8835 - val_loss: -546.2819 - val_mse: 825.5193\n",
            "Epoch 316/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5428 - mse: 795.2491 - val_loss: -546.2946 - val_mse: 824.3905\n",
            "Epoch 317/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.5450 - mse: 795.6321 - val_loss: -546.2492 - val_mse: 827.5986\n",
            "Epoch 318/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5482 - mse: 794.1627 - val_loss: -546.2957 - val_mse: 822.1166\n",
            "Epoch 319/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5650 - mse: 793.0104 - val_loss: -546.2963 - val_mse: 822.3215\n",
            "Epoch 320/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5645 - mse: 791.8339 - val_loss: -546.3138 - val_mse: 820.3389\n",
            "Epoch 321/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.5765 - mse: 791.2493 - val_loss: -546.2803 - val_mse: 818.9235\n",
            "Epoch 322/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5816 - mse: 790.4225 - val_loss: -546.2918 - val_mse: 821.3415\n",
            "Epoch 323/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.5696 - mse: 790.1747 - val_loss: -546.3361 - val_mse: 817.7396\n",
            "Epoch 324/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.5942 - mse: 787.9241 - val_loss: -546.3280 - val_mse: 818.7020\n",
            "Epoch 325/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5923 - mse: 787.8011 - val_loss: -546.3489 - val_mse: 814.8886\n",
            "Epoch 326/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6052 - mse: 786.0574 - val_loss: -546.3553 - val_mse: 814.2678\n",
            "Epoch 327/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.6111 - mse: 785.3529 - val_loss: -546.3562 - val_mse: 813.5116\n",
            "Epoch 328/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.6131 - mse: 784.9473 - val_loss: -546.3604 - val_mse: 813.4148\n",
            "Epoch 329/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6187 - mse: 784.6763 - val_loss: -546.3656 - val_mse: 811.4340\n",
            "Epoch 330/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6086 - mse: 784.3135 - val_loss: -546.3574 - val_mse: 813.6572\n",
            "Epoch 331/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6340 - mse: 782.4204 - val_loss: -546.3705 - val_mse: 814.4365\n",
            "Epoch 332/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6385 - mse: 781.7922 - val_loss: -546.3645 - val_mse: 812.3932\n",
            "Epoch 333/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6388 - mse: 781.4447 - val_loss: -546.3671 - val_mse: 810.2607\n",
            "Epoch 334/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.6455 - mse: 780.2629 - val_loss: -546.3774 - val_mse: 810.2740\n",
            "Epoch 335/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6506 - mse: 779.4299 - val_loss: -546.3944 - val_mse: 808.4465\n",
            "Epoch 336/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.6584 - mse: 779.7344 - val_loss: -546.4039 - val_mse: 806.6492\n",
            "Epoch 337/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6611 - mse: 778.3470 - val_loss: -546.3875 - val_mse: 807.5391\n",
            "Epoch 338/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6704 - mse: 777.1018 - val_loss: -546.4169 - val_mse: 806.5867\n",
            "Epoch 339/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.6711 - mse: 777.0497 - val_loss: -546.4190 - val_mse: 805.8785\n",
            "Epoch 340/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.6626 - mse: 777.1453 - val_loss: -546.4175 - val_mse: 803.8837\n",
            "Epoch 341/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.6862 - mse: 774.8176 - val_loss: -546.4225 - val_mse: 805.3867\n",
            "Epoch 342/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.6889 - mse: 775.1541 - val_loss: -546.4230 - val_mse: 802.5895\n",
            "Epoch 343/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6833 - mse: 775.0845 - val_loss: -546.4361 - val_mse: 803.4466\n",
            "Epoch 344/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.6922 - mse: 774.4579 - val_loss: -546.4413 - val_mse: 801.4521\n",
            "Epoch 345/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6848 - mse: 773.5348 - val_loss: -546.4471 - val_mse: 801.1890\n",
            "Epoch 346/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6991 - mse: 772.8221 - val_loss: -546.4463 - val_mse: 801.5318\n",
            "Epoch 347/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7029 - mse: 771.9379 - val_loss: -546.4045 - val_mse: 806.7460\n",
            "Epoch 348/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7155 - mse: 771.2217 - val_loss: -546.3316 - val_mse: 806.4066\n",
            "Epoch 349/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.7178 - mse: 771.2587 - val_loss: -546.4600 - val_mse: 799.4177\n",
            "Epoch 350/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7208 - mse: 770.4246 - val_loss: -546.4625 - val_mse: 799.9640\n",
            "Epoch 351/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7277 - mse: 769.8958 - val_loss: -546.4599 - val_mse: 798.4528\n",
            "Epoch 352/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7249 - mse: 769.5482 - val_loss: -546.4634 - val_mse: 800.1116\n",
            "Epoch 353/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7364 - mse: 768.6514 - val_loss: -546.4327 - val_mse: 800.4164\n",
            "Epoch 354/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7354 - mse: 768.2761 - val_loss: -546.4675 - val_mse: 797.1560\n",
            "Epoch 355/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.7394 - mse: 767.8308 - val_loss: -546.4592 - val_mse: 797.4552\n",
            "Epoch 356/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7442 - mse: 766.9072 - val_loss: -546.4688 - val_mse: 798.2062\n",
            "Epoch 357/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7484 - mse: 767.2999 - val_loss: -546.4656 - val_mse: 799.1621\n",
            "Epoch 358/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.7500 - mse: 766.4526 - val_loss: -546.4942 - val_mse: 795.5994\n",
            "Epoch 359/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7576 - mse: 766.2346 - val_loss: -546.4927 - val_mse: 793.9813\n",
            "Epoch 360/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.7649 - mse: 764.6934 - val_loss: -546.5012 - val_mse: 793.5029\n",
            "Epoch 361/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7556 - mse: 765.3782 - val_loss: -546.4994 - val_mse: 794.0283\n",
            "Epoch 362/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.7689 - mse: 764.1116 - val_loss: -546.4963 - val_mse: 795.0008\n",
            "Epoch 363/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.7672 - mse: 764.8631 - val_loss: -546.4636 - val_mse: 794.7727\n",
            "Epoch 364/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7759 - mse: 763.5065 - val_loss: -546.5039 - val_mse: 792.8368\n",
            "Epoch 365/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.7803 - mse: 762.9401 - val_loss: -546.5127 - val_mse: 793.1287\n",
            "Epoch 366/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.7870 - mse: 762.6481 - val_loss: -546.5048 - val_mse: 792.9092\n",
            "Epoch 367/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.7834 - mse: 761.9935 - val_loss: -546.5125 - val_mse: 793.3234\n",
            "Epoch 368/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.7909 - mse: 761.6992 - val_loss: -546.5070 - val_mse: 794.3900\n",
            "Epoch 369/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.7886 - mse: 761.6094 - val_loss: -546.5254 - val_mse: 790.2183\n",
            "Epoch 370/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7985 - mse: 760.6656 - val_loss: -546.5076 - val_mse: 790.3361\n",
            "Epoch 371/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7939 - mse: 760.8556 - val_loss: -546.5238 - val_mse: 789.1669\n",
            "Epoch 372/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7899 - mse: 761.1102 - val_loss: -546.5281 - val_mse: 789.5796\n",
            "Epoch 373/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8030 - mse: 759.5944 - val_loss: -546.5292 - val_mse: 791.2897\n",
            "Epoch 374/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8023 - mse: 760.2526 - val_loss: -546.5414 - val_mse: 788.6244\n",
            "Epoch 375/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8077 - mse: 759.6450 - val_loss: -546.5401 - val_mse: 788.2081\n",
            "Epoch 376/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8154 - mse: 758.6142 - val_loss: -546.5446 - val_mse: 788.4642\n",
            "Epoch 377/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8049 - mse: 759.1199 - val_loss: -546.5379 - val_mse: 790.4446\n",
            "Epoch 378/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8193 - mse: 758.6255 - val_loss: -546.4975 - val_mse: 788.7361\n",
            "Epoch 379/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8028 - mse: 758.4823 - val_loss: -546.4731 - val_mse: 791.8789\n",
            "Epoch 380/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8174 - mse: 757.3305 - val_loss: -546.5571 - val_mse: 788.2449\n",
            "Epoch 381/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8290 - mse: 756.9368 - val_loss: -546.5567 - val_mse: 786.8893\n",
            "Epoch 382/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8336 - mse: 756.1188 - val_loss: -546.5602 - val_mse: 787.4391\n",
            "Epoch 383/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8253 - mse: 757.2371 - val_loss: -546.5312 - val_mse: 787.9132\n",
            "Epoch 384/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8353 - mse: 756.2528 - val_loss: -546.5464 - val_mse: 786.7994\n",
            "Epoch 385/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8366 - mse: 756.4122 - val_loss: -546.5668 - val_mse: 785.6813\n",
            "Epoch 386/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8281 - mse: 756.0541 - val_loss: -546.5668 - val_mse: 784.9528\n",
            "Epoch 387/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8460 - mse: 754.6189 - val_loss: -546.5624 - val_mse: 786.8610\n",
            "Epoch 388/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8323 - mse: 755.4064 - val_loss: -546.4765 - val_mse: 788.8351\n",
            "Epoch 389/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8486 - mse: 754.7291 - val_loss: -546.1904 - val_mse: 800.4290\n",
            "Epoch 390/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8459 - mse: 753.9012 - val_loss: -546.5559 - val_mse: 787.5436\n",
            "Epoch 391/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8480 - mse: 754.3710 - val_loss: -546.5804 - val_mse: 783.5621\n",
            "Epoch 392/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8584 - mse: 753.5725 - val_loss: -546.5655 - val_mse: 785.6807\n",
            "Epoch 393/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8588 - mse: 753.6134 - val_loss: -546.5689 - val_mse: 785.5303\n",
            "Epoch 394/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8589 - mse: 753.2261 - val_loss: -546.5540 - val_mse: 786.9517\n",
            "Epoch 395/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8426 - mse: 752.8193 - val_loss: -546.5390 - val_mse: 786.0070\n",
            "Epoch 396/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8718 - mse: 752.3590 - val_loss: -546.5844 - val_mse: 784.5328\n",
            "Epoch 397/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8692 - mse: 752.0740 - val_loss: -546.5889 - val_mse: 785.5388\n",
            "Epoch 398/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8654 - mse: 752.4331 - val_loss: -546.5906 - val_mse: 784.2614\n",
            "Epoch 399/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8711 - mse: 752.0161 - val_loss: -546.5693 - val_mse: 784.1446\n",
            "Epoch 400/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8723 - mse: 751.7946 - val_loss: -546.5955 - val_mse: 783.1966\n",
            "Epoch 401/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8758 - mse: 751.1816 - val_loss: -546.5896 - val_mse: 783.1823\n",
            "Epoch 402/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8778 - mse: 751.2620 - val_loss: -546.5678 - val_mse: 785.4026\n",
            "Epoch 403/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8593 - mse: 751.5126 - val_loss: -546.5917 - val_mse: 783.1351\n",
            "Epoch 404/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8705 - mse: 750.9153 - val_loss: -546.5919 - val_mse: 783.7120\n",
            "Epoch 405/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8742 - mse: 750.7468 - val_loss: -546.5302 - val_mse: 788.9250\n",
            "Epoch 406/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8847 - mse: 750.1190 - val_loss: -546.5812 - val_mse: 782.6882\n",
            "Epoch 407/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8939 - mse: 749.9610 - val_loss: -546.5857 - val_mse: 781.6973\n",
            "Epoch 408/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8853 - mse: 749.3683 - val_loss: -546.5892 - val_mse: 783.7295\n",
            "Epoch 409/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8880 - mse: 750.0112 - val_loss: -546.5947 - val_mse: 780.0793\n",
            "Epoch 410/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8939 - mse: 749.2310 - val_loss: -546.6084 - val_mse: 781.3093\n",
            "Epoch 411/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8941 - mse: 749.4484 - val_loss: -546.5942 - val_mse: 782.0187\n",
            "Epoch 412/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8917 - mse: 749.3838 - val_loss: -546.6039 - val_mse: 779.4436\n",
            "Epoch 413/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9000 - mse: 748.5504 - val_loss: -546.6092 - val_mse: 781.0808\n",
            "Epoch 414/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.9055 - mse: 748.0262 - val_loss: -546.6004 - val_mse: 781.0784\n",
            "Epoch 415/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9102 - mse: 747.7705 - val_loss: -546.6148 - val_mse: 779.0278\n",
            "Epoch 416/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8884 - mse: 749.1056 - val_loss: -546.5209 - val_mse: 784.7838\n",
            "Epoch 417/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -546.9046 - mse: 747.2031 - val_loss: -546.5725 - val_mse: 781.6735\n",
            "Epoch 418/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8954 - mse: 748.7551 - val_loss: -546.6164 - val_mse: 780.3043\n",
            "Epoch 419/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9014 - mse: 747.6550 - val_loss: -546.4493 - val_mse: 788.9734\n",
            "Epoch 420/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9060 - mse: 747.3123 - val_loss: -546.5842 - val_mse: 784.5568\n",
            "Epoch 421/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9033 - mse: 747.9907 - val_loss: -546.6132 - val_mse: 778.7864\n",
            "Epoch 422/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9057 - mse: 747.0866 - val_loss: -546.6217 - val_mse: 779.2028\n",
            "Epoch 423/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9109 - mse: 746.4393 - val_loss: -546.4918 - val_mse: 784.9006\n",
            "Epoch 424/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8931 - mse: 747.9513 - val_loss: -546.5488 - val_mse: 782.2800\n",
            "Epoch 425/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9234 - mse: 746.0140 - val_loss: -546.6005 - val_mse: 780.9421\n",
            "Epoch 426/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9200 - mse: 746.0191 - val_loss: -546.6182 - val_mse: 778.3751\n",
            "Epoch 427/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9235 - mse: 745.6551 - val_loss: -546.6212 - val_mse: 780.5496\n",
            "Epoch 428/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9213 - mse: 746.6066 - val_loss: -546.6272 - val_mse: 777.7137\n",
            "Epoch 429/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9131 - mse: 746.1586 - val_loss: -546.5974 - val_mse: 779.8428\n",
            "Epoch 430/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -546.9224 - mse: 745.0378 - val_loss: -546.6259 - val_mse: 779.3894\n",
            "Epoch 431/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9298 - mse: 745.2167 - val_loss: -546.6211 - val_mse: 778.5468\n",
            "Epoch 432/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9272 - mse: 745.0848 - val_loss: -546.6118 - val_mse: 779.1975\n",
            "Epoch 433/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9312 - mse: 744.7845 - val_loss: -546.6313 - val_mse: 777.4017\n",
            "Epoch 434/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9298 - mse: 744.9604 - val_loss: -546.6308 - val_mse: 777.4812\n",
            "Epoch 435/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9355 - mse: 744.7294 - val_loss: -546.6277 - val_mse: 779.8776\n",
            "Epoch 436/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9378 - mse: 744.4562 - val_loss: -546.4823 - val_mse: 786.3174\n",
            "Epoch 437/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9192 - mse: 745.0148 - val_loss: -546.6240 - val_mse: 778.7838\n",
            "Epoch 438/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9369 - mse: 744.2413 - val_loss: -546.6356 - val_mse: 777.6365\n",
            "Epoch 439/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9359 - mse: 744.1413 - val_loss: -546.6327 - val_mse: 778.9440\n",
            "Epoch 440/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9275 - mse: 744.5308 - val_loss: -546.5002 - val_mse: 784.6807\n",
            "Epoch 441/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9347 - mse: 743.2608 - val_loss: -546.5877 - val_mse: 779.3501\n",
            "Epoch 442/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9444 - mse: 743.3054 - val_loss: -546.6389 - val_mse: 778.9982\n",
            "Epoch 443/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9447 - mse: 743.0338 - val_loss: -546.6383 - val_mse: 779.2244\n",
            "Epoch 444/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9530 - mse: 742.5350 - val_loss: -546.6358 - val_mse: 779.4086\n",
            "Epoch 445/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9455 - mse: 743.3533 - val_loss: -546.5764 - val_mse: 778.2770\n",
            "Epoch 446/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9431 - mse: 743.3017 - val_loss: -546.6347 - val_mse: 778.8741\n",
            "Epoch 447/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9418 - mse: 743.2445 - val_loss: -546.6384 - val_mse: 776.0925\n",
            "Epoch 448/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9557 - mse: 741.7437 - val_loss: -546.6411 - val_mse: 777.8743\n",
            "Epoch 449/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9408 - mse: 743.2397 - val_loss: -546.6074 - val_mse: 779.6050\n",
            "Epoch 450/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9435 - mse: 742.7391 - val_loss: -546.6321 - val_mse: 778.0895\n",
            "Epoch 451/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9511 - mse: 742.5619 - val_loss: -546.6422 - val_mse: 776.4010\n",
            "Epoch 452/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9603 - mse: 742.1943 - val_loss: -546.6360 - val_mse: 777.0381\n",
            "Epoch 453/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9601 - mse: 741.6071 - val_loss: -546.6449 - val_mse: 776.9185\n",
            "Epoch 454/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9577 - mse: 741.6652 - val_loss: -546.6378 - val_mse: 778.1100\n",
            "Epoch 455/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9577 - mse: 741.0668 - val_loss: -546.5590 - val_mse: 781.7565\n",
            "Epoch 456/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9585 - mse: 741.6636 - val_loss: -546.6415 - val_mse: 779.4689\n",
            "Epoch 457/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9626 - mse: 741.1388 - val_loss: -546.6485 - val_mse: 778.0964\n",
            "Epoch 458/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9691 - mse: 740.4374 - val_loss: -546.6339 - val_mse: 779.6249\n",
            "Epoch 459/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9666 - mse: 740.8248 - val_loss: -546.4392 - val_mse: 787.1409\n",
            "Epoch 460/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9590 - mse: 741.3881 - val_loss: -546.6466 - val_mse: 776.2220\n",
            "Epoch 461/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -546.9616 - mse: 740.6519 - val_loss: -546.6508 - val_mse: 777.6852\n",
            "Epoch 462/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9629 - mse: 740.8881 - val_loss: -546.6296 - val_mse: 776.0724\n",
            "Epoch 463/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -546.9626 - mse: 740.7434 - val_loss: -546.6063 - val_mse: 776.6459\n",
            "Epoch 464/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9524 - mse: 740.8209 - val_loss: -546.6465 - val_mse: 775.5275\n",
            "Epoch 465/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9736 - mse: 739.6911 - val_loss: -546.6490 - val_mse: 777.9759\n",
            "Epoch 466/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9699 - mse: 739.7673 - val_loss: -546.6449 - val_mse: 778.0947\n",
            "Epoch 467/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -546.9656 - mse: 740.6622 - val_loss: -546.6237 - val_mse: 775.5568\n",
            "Epoch 468/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9758 - mse: 739.4318 - val_loss: -546.6379 - val_mse: 777.8696\n",
            "Epoch 469/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -546.9758 - mse: 739.4112 - val_loss: -546.6431 - val_mse: 777.4806\n",
            "Epoch 470/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -546.9776 - mse: 739.3193 - val_loss: -546.6258 - val_mse: 774.8578\n",
            "Epoch 471/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -546.9757 - mse: 739.2775 - val_loss: -546.6438 - val_mse: 776.7360\n",
            "Epoch 472/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -546.9666 - mse: 739.3909 - val_loss: -546.6396 - val_mse: 777.5284\n",
            "Epoch 473/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9769 - mse: 738.7783 - val_loss: -546.6529 - val_mse: 777.1228\n",
            "Epoch 474/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9737 - mse: 738.6456 - val_loss: -546.5761 - val_mse: 777.6849\n",
            "Epoch 475/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9667 - mse: 738.9218 - val_loss: -546.6465 - val_mse: 778.1235\n",
            "Epoch 476/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9869 - mse: 738.2285 - val_loss: -546.6423 - val_mse: 777.9869\n",
            "Epoch 477/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9813 - mse: 738.1522 - val_loss: -546.6350 - val_mse: 778.2703\n",
            "Epoch 478/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9818 - mse: 738.0706 - val_loss: -546.6437 - val_mse: 780.4630\n",
            "Epoch 479/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -546.9851 - mse: 738.0905 - val_loss: -546.6532 - val_mse: 776.2649\n",
            "Epoch 480/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9866 - mse: 738.0688 - val_loss: -546.6472 - val_mse: 775.6086\n",
            "Epoch 481/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9805 - mse: 738.0032 - val_loss: -546.6547 - val_mse: 775.6770\n",
            "Epoch 482/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9852 - mse: 737.7716 - val_loss: -546.6421 - val_mse: 777.4609\n",
            "Epoch 483/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9819 - mse: 738.0548 - val_loss: -546.6379 - val_mse: 778.3207\n",
            "Epoch 484/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9844 - mse: 737.7623 - val_loss: -546.5228 - val_mse: 783.9706\n",
            "Epoch 485/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -546.9847 - mse: 737.9558 - val_loss: -546.6266 - val_mse: 778.2371\n",
            "Epoch 486/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9855 - mse: 737.6757 - val_loss: -546.6102 - val_mse: 779.6685\n",
            "Epoch 487/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9802 - mse: 737.5178 - val_loss: -546.6537 - val_mse: 776.1870\n",
            "Epoch 488/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9954 - mse: 736.7570 - val_loss: -546.5836 - val_mse: 779.1183\n",
            "Epoch 489/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9963 - mse: 736.6853 - val_loss: -546.6571 - val_mse: 776.2904\n",
            "Epoch 490/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9904 - mse: 736.7263 - val_loss: -546.6541 - val_mse: 777.0063\n",
            "Epoch 491/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -547.0002 - mse: 736.2869 - val_loss: -546.6565 - val_mse: 775.7571\n",
            "Epoch 492/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -547.0003 - mse: 736.3704 - val_loss: -546.6046 - val_mse: 779.8752\n",
            "Epoch 493/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9944 - mse: 736.0638 - val_loss: -546.5628 - val_mse: 781.5013\n",
            "Epoch 494/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9926 - mse: 736.1300 - val_loss: -546.5604 - val_mse: 778.3981\n",
            "Epoch 495/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9952 - mse: 736.5790 - val_loss: -546.6108 - val_mse: 779.1385\n",
            "Epoch 496/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9975 - mse: 736.1453 - val_loss: -546.6559 - val_mse: 775.4290\n",
            "Epoch 497/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9924 - mse: 736.6781 - val_loss: -546.6561 - val_mse: 774.3532\n",
            "Epoch 498/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9992 - mse: 735.6520 - val_loss: -546.6512 - val_mse: 775.1521\n",
            "Epoch 499/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -547.0007 - mse: 735.5848 - val_loss: -546.6295 - val_mse: 776.0658\n",
            "Epoch 500/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -547.0017 - mse: 735.0827 - val_loss: -546.6227 - val_mse: 778.4664\n",
            "Epoch 501/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -547.0011 - mse: 735.4943 - val_loss: -546.6429 - val_mse: 774.9548\n",
            "Epoch 502/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.9974 - mse: 735.0922 - val_loss: -546.6465 - val_mse: 776.2156\n",
            "Epoch 503/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -547.0029 - mse: 734.5613 - val_loss: -546.6542 - val_mse: 777.0074\n",
            "Epoch 504/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -547.0008 - mse: 735.4083 - val_loss: -546.6005 - val_mse: 777.6561\n",
            "Save file name colab_notebook_data/feature_interactions/trained_models/poissonloss/negcontrol_model-skipconn_l1reg-0.0_seed100_sgkcd.h5\n",
            "Training model colab_notebook_data/feature_interactions/trained_models/poissonloss/poscontrol_model-onelayer_l1reg-0.0_seed100_bsdzv.h5\n",
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_16 (InputLayer)        (None, 100, 4)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_16 (Conv1D)           (None, 76, 64)            6464      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_16  (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 10,689\n",
            "Trainable params: 10,689\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "40000/40000 [==============================] - 1s 27us/step - loss: -246.7133 - mse: 15702.8291 - val_loss: -345.3741 - val_mse: 12452.7451\n",
            "Epoch 2/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -370.1706 - mse: 10082.5303 - val_loss: -384.4268 - val_mse: 8426.5469\n",
            "Epoch 3/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -387.1735 - mse: 7901.7778 - val_loss: -389.0890 - val_mse: 7631.3154\n",
            "Epoch 4/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -388.8247 - mse: 7600.8511 - val_loss: -389.3805 - val_mse: 7572.3887\n",
            "Epoch 5/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -388.9167 - mse: 7581.9385 - val_loss: -389.4016 - val_mse: 7567.9170\n",
            "Epoch 6/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -388.9304 - mse: 7579.0137 - val_loss: -389.4126 - val_mse: 7565.5591\n",
            "Epoch 7/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -388.9431 - mse: 7576.3296 - val_loss: -389.4235 - val_mse: 7563.1934\n",
            "Epoch 8/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -388.9548 - mse: 7573.8022 - val_loss: -389.4402 - val_mse: 7559.7246\n",
            "Epoch 9/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -388.9715 - mse: 7570.2886 - val_loss: -389.4587 - val_mse: 7555.8086\n",
            "Epoch 10/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -388.9945 - mse: 7565.4658 - val_loss: -389.4831 - val_mse: 7550.6001\n",
            "Epoch 11/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -389.0220 - mse: 7559.5791 - val_loss: -389.5148 - val_mse: 7543.9624\n",
            "Epoch 12/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -389.0617 - mse: 7551.2329 - val_loss: -389.5595 - val_mse: 7534.4561\n",
            "Epoch 13/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -389.1171 - mse: 7539.4785 - val_loss: -389.6260 - val_mse: 7520.2754\n",
            "Epoch 14/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -389.2066 - mse: 7520.7002 - val_loss: -389.7383 - val_mse: 7496.9590\n",
            "Epoch 15/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -389.3550 - mse: 7489.6279 - val_loss: -389.9157 - val_mse: 7459.1089\n",
            "Epoch 16/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -389.5720 - mse: 7443.8633 - val_loss: -390.1651 - val_mse: 7408.8242\n",
            "Epoch 17/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -389.8769 - mse: 7380.6543 - val_loss: -390.4660 - val_mse: 7350.1558\n",
            "Epoch 18/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -390.2704 - mse: 7300.3384 - val_loss: -390.9298 - val_mse: 7247.7329\n",
            "Epoch 19/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -390.7417 - mse: 7203.0752 - val_loss: -391.3842 - val_mse: 7159.6006\n",
            "Epoch 20/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.1535 - mse: 7120.7383 - val_loss: -391.6778 - val_mse: 7095.1904\n",
            "Epoch 21/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -391.4201 - mse: 7067.3750 - val_loss: -391.8705 - val_mse: 7066.0825\n",
            "Epoch 22/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.5612 - mse: 7038.5928 - val_loss: -391.9617 - val_mse: 7046.5142\n",
            "Epoch 23/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6238 - mse: 7026.8320 - val_loss: -391.9812 - val_mse: 7042.2065\n",
            "Epoch 24/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6442 - mse: 7023.5503 - val_loss: -392.0065 - val_mse: 7038.8042\n",
            "Epoch 25/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -391.6596 - mse: 7020.4351 - val_loss: -391.9104 - val_mse: 7059.4585\n",
            "Epoch 26/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6468 - mse: 7022.6592 - val_loss: -391.9851 - val_mse: 7044.4976\n",
            "Epoch 27/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6573 - mse: 7021.4238 - val_loss: -392.0039 - val_mse: 7040.8608\n",
            "Epoch 28/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -391.6690 - mse: 7019.2280 - val_loss: -392.0161 - val_mse: 7038.6089\n",
            "Epoch 29/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -391.6650 - mse: 7019.8672 - val_loss: -392.0269 - val_mse: 7036.7144\n",
            "Epoch 30/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -391.6698 - mse: 7018.8042 - val_loss: -392.0258 - val_mse: 7037.0942\n",
            "Epoch 31/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6704 - mse: 7019.2930 - val_loss: -392.0296 - val_mse: 7036.2710\n",
            "Epoch 32/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -391.6730 - mse: 7018.3857 - val_loss: -392.0223 - val_mse: 7038.1030\n",
            "Epoch 33/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6839 - mse: 7016.4976 - val_loss: -392.0242 - val_mse: 7037.4810\n",
            "Epoch 34/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6924 - mse: 7014.8486 - val_loss: -392.0365 - val_mse: 7035.3096\n",
            "Epoch 35/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6877 - mse: 7015.9146 - val_loss: -392.0460 - val_mse: 7033.3623\n",
            "Epoch 36/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6886 - mse: 7016.1006 - val_loss: -392.0409 - val_mse: 7034.7207\n",
            "Epoch 37/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6970 - mse: 7014.5234 - val_loss: -392.0368 - val_mse: 7035.2559\n",
            "Epoch 38/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -391.6949 - mse: 7014.1455 - val_loss: -392.0537 - val_mse: 7032.1440\n",
            "Epoch 39/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -391.6910 - mse: 7014.8257 - val_loss: -392.0506 - val_mse: 7033.0273\n",
            "Epoch 40/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6920 - mse: 7014.3398 - val_loss: -392.0653 - val_mse: 7030.0938\n",
            "Epoch 41/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.7109 - mse: 7011.8262 - val_loss: -392.0679 - val_mse: 7029.4346\n",
            "Epoch 42/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.6987 - mse: 7014.3271 - val_loss: -392.0169 - val_mse: 7039.7080\n",
            "Epoch 43/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -391.7231 - mse: 7008.9810 - val_loss: -391.9781 - val_mse: 7049.0898\n",
            "Epoch 44/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.7186 - mse: 7009.9033 - val_loss: -392.0841 - val_mse: 7026.3271\n",
            "Epoch 45/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.7327 - mse: 7007.2134 - val_loss: -392.0965 - val_mse: 7024.2744\n",
            "Epoch 46/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.7383 - mse: 7004.6006 - val_loss: -392.0968 - val_mse: 7024.1030\n",
            "Epoch 47/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -391.7468 - mse: 7003.2031 - val_loss: -392.0849 - val_mse: 7025.7183\n",
            "Epoch 48/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.7492 - mse: 7003.5410 - val_loss: -392.1085 - val_mse: 7021.9258\n",
            "Epoch 49/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.7706 - mse: 7000.2710 - val_loss: -392.1491 - val_mse: 7013.3623\n",
            "Epoch 50/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.7996 - mse: 6994.2559 - val_loss: -392.1776 - val_mse: 7007.9414\n",
            "Epoch 51/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.8397 - mse: 6985.5903 - val_loss: -392.2075 - val_mse: 7002.0352\n",
            "Epoch 52/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -391.8818 - mse: 6976.4502 - val_loss: -392.2264 - val_mse: 6997.8208\n",
            "Epoch 53/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.9116 - mse: 6970.6489 - val_loss: -392.2994 - val_mse: 6983.7192\n",
            "Epoch 54/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -391.9996 - mse: 6952.6328 - val_loss: -392.3882 - val_mse: 6965.3545\n",
            "Epoch 55/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -392.0704 - mse: 6939.1064 - val_loss: -392.4753 - val_mse: 6947.9375\n",
            "Epoch 56/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -392.1796 - mse: 6915.8135 - val_loss: -392.5587 - val_mse: 6931.9751\n",
            "Epoch 57/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -392.3321 - mse: 6884.8887 - val_loss: -392.6784 - val_mse: 6903.2422\n",
            "Epoch 58/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -392.4684 - mse: 6856.4946 - val_loss: -392.9046 - val_mse: 6859.5776\n",
            "Epoch 59/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -392.6923 - mse: 6810.9058 - val_loss: -392.8779 - val_mse: 6872.7607\n",
            "Epoch 60/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -392.9162 - mse: 6764.2520 - val_loss: -393.3609 - val_mse: 6761.9722\n",
            "Epoch 61/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -393.2097 - mse: 6704.4990 - val_loss: -393.6379 - val_mse: 6712.8984\n",
            "Epoch 62/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -393.5266 - mse: 6639.4409 - val_loss: -393.9699 - val_mse: 6645.9331\n",
            "Epoch 63/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -393.8652 - mse: 6571.9678 - val_loss: -394.2752 - val_mse: 6561.0190\n",
            "Epoch 64/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -394.2526 - mse: 6493.2998 - val_loss: -394.7159 - val_mse: 6475.3760\n",
            "Epoch 65/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -394.6902 - mse: 6403.5771 - val_loss: -395.1701 - val_mse: 6400.7827\n",
            "Epoch 66/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -395.1166 - mse: 6315.7578 - val_loss: -395.5281 - val_mse: 6340.8013\n",
            "Epoch 67/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -395.5961 - mse: 6222.1685 - val_loss: -396.0744 - val_mse: 6197.8945\n",
            "Epoch 68/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -396.0482 - mse: 6128.8071 - val_loss: -396.4393 - val_mse: 6156.3101\n",
            "Epoch 69/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -396.5078 - mse: 6037.1758 - val_loss: -396.9261 - val_mse: 6049.5933\n",
            "Epoch 70/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -396.9522 - mse: 5945.7100 - val_loss: -397.3450 - val_mse: 5957.7529\n",
            "Epoch 71/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -397.3467 - mse: 5866.9082 - val_loss: -397.6409 - val_mse: 5893.4502\n",
            "Epoch 72/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -397.7065 - mse: 5790.0952 - val_loss: -397.9127 - val_mse: 5835.9966\n",
            "Epoch 73/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -398.0456 - mse: 5720.6255 - val_loss: -398.2294 - val_mse: 5718.8872\n",
            "Epoch 74/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -398.3063 - mse: 5664.4053 - val_loss: -398.5737 - val_mse: 5681.1719\n",
            "Epoch 75/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -398.5670 - mse: 5606.3428 - val_loss: -398.8795 - val_mse: 5621.3838\n",
            "Epoch 76/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -398.7660 - mse: 5567.6455 - val_loss: -399.1361 - val_mse: 5549.1353\n",
            "Epoch 77/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -399.0371 - mse: 5510.3218 - val_loss: -399.3033 - val_mse: 5499.0605\n",
            "Epoch 78/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -399.2471 - mse: 5465.8892 - val_loss: -399.5347 - val_mse: 5477.0835\n",
            "Epoch 79/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -399.4879 - mse: 5423.6660 - val_loss: -399.7432 - val_mse: 5422.5215\n",
            "Epoch 80/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -399.6981 - mse: 5379.7695 - val_loss: -399.9839 - val_mse: 5366.2114\n",
            "Epoch 81/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -399.7940 - mse: 5351.6362 - val_loss: -399.9800 - val_mse: 5398.5303\n",
            "Epoch 82/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -400.0819 - mse: 5300.7666 - val_loss: -400.4110 - val_mse: 5284.5405\n",
            "Epoch 83/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -400.3320 - mse: 5250.2915 - val_loss: -400.4639 - val_mse: 5301.1938\n",
            "Epoch 84/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -400.4879 - mse: 5226.2559 - val_loss: -400.8091 - val_mse: 5192.5586\n",
            "Epoch 85/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -400.6596 - mse: 5184.5327 - val_loss: -400.9178 - val_mse: 5159.2598\n",
            "Epoch 86/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -400.9154 - mse: 5137.8745 - val_loss: -401.2851 - val_mse: 5118.3193\n",
            "Epoch 87/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -401.1576 - mse: 5091.4819 - val_loss: -401.3705 - val_mse: 5122.9653\n",
            "Epoch 88/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -401.3039 - mse: 5061.1426 - val_loss: -401.6570 - val_mse: 5024.8794\n",
            "Epoch 89/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -401.5475 - mse: 5017.4824 - val_loss: -401.9340 - val_mse: 5000.8574\n",
            "Epoch 90/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -401.7719 - mse: 4976.6577 - val_loss: -401.9292 - val_mse: 4948.3882\n",
            "Epoch 91/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -401.9015 - mse: 4944.6992 - val_loss: -402.3094 - val_mse: 4925.3682\n",
            "Epoch 92/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -402.1501 - mse: 4893.5874 - val_loss: -402.3006 - val_mse: 4871.3892\n",
            "Epoch 93/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -402.3474 - mse: 4862.1953 - val_loss: -402.3392 - val_mse: 4850.2910\n",
            "Epoch 94/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -402.5494 - mse: 4818.2559 - val_loss: -402.9490 - val_mse: 4788.8936\n",
            "Epoch 95/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -402.7896 - mse: 4772.6094 - val_loss: -403.1667 - val_mse: 4740.4453\n",
            "Epoch 96/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -402.9388 - mse: 4742.1738 - val_loss: -403.3783 - val_mse: 4701.9595\n",
            "Epoch 97/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -403.1096 - mse: 4699.9741 - val_loss: -403.5676 - val_mse: 4667.3638\n",
            "Epoch 98/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -403.3635 - mse: 4657.2451 - val_loss: -403.7481 - val_mse: 4653.3066\n",
            "Epoch 99/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -403.4849 - mse: 4635.2148 - val_loss: -403.9439 - val_mse: 4607.9058\n",
            "Epoch 100/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -403.7198 - mse: 4588.4502 - val_loss: -403.9074 - val_mse: 4631.6118\n",
            "Epoch 101/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -403.9306 - mse: 4548.8613 - val_loss: -404.3012 - val_mse: 4514.3857\n",
            "Epoch 102/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -404.0377 - mse: 4524.3809 - val_loss: -404.5000 - val_mse: 4497.7227\n",
            "Epoch 103/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -404.2767 - mse: 4483.9033 - val_loss: -404.5496 - val_mse: 4491.1187\n",
            "Epoch 104/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -404.4326 - mse: 4448.2959 - val_loss: -404.7080 - val_mse: 4406.3076\n",
            "Epoch 105/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -404.6395 - mse: 4407.0449 - val_loss: -404.8980 - val_mse: 4416.4639\n",
            "Epoch 106/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -404.7739 - mse: 4377.5449 - val_loss: -405.1467 - val_mse: 4336.6011\n",
            "Epoch 107/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -404.9915 - mse: 4341.4336 - val_loss: -405.3416 - val_mse: 4337.8350\n",
            "Epoch 108/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -405.1767 - mse: 4306.8843 - val_loss: -405.4895 - val_mse: 4282.7969\n",
            "Epoch 109/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -405.3424 - mse: 4268.4976 - val_loss: -405.6260 - val_mse: 4238.6313\n",
            "Epoch 110/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -405.4915 - mse: 4244.0151 - val_loss: -405.8712 - val_mse: 4211.0278\n",
            "Epoch 111/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -405.6862 - mse: 4204.8320 - val_loss: -405.9124 - val_mse: 4223.4731\n",
            "Epoch 112/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -405.8004 - mse: 4186.9028 - val_loss: -405.7436 - val_mse: 4177.2534\n",
            "Epoch 113/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -406.0634 - mse: 4141.9932 - val_loss: -406.3308 - val_mse: 4103.0830\n",
            "Epoch 114/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -406.1560 - mse: 4109.9531 - val_loss: -406.3054 - val_mse: 4155.0200\n",
            "Epoch 115/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -406.3506 - mse: 4082.2612 - val_loss: -406.3423 - val_mse: 4130.9951\n",
            "Epoch 116/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -406.5043 - mse: 4048.5713 - val_loss: -406.7676 - val_mse: 4069.5659\n",
            "Epoch 117/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -406.6769 - mse: 4024.1973 - val_loss: -406.4744 - val_mse: 4074.5557\n",
            "Epoch 118/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -406.7296 - mse: 3997.5537 - val_loss: -406.7994 - val_mse: 4055.7300\n",
            "Epoch 119/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -407.0265 - mse: 3959.6108 - val_loss: -407.3316 - val_mse: 3934.8823\n",
            "Epoch 120/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -407.1829 - mse: 3925.9731 - val_loss: -407.4976 - val_mse: 3901.2896\n",
            "Epoch 121/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -407.3557 - mse: 3893.8120 - val_loss: -407.6627 - val_mse: 3868.8201\n",
            "Epoch 122/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -407.4872 - mse: 3867.4272 - val_loss: -407.8332 - val_mse: 3856.3391\n",
            "Epoch 123/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -407.7153 - mse: 3833.8828 - val_loss: -407.9298 - val_mse: 3806.2163\n",
            "Epoch 124/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -407.8588 - mse: 3804.8977 - val_loss: -408.1638 - val_mse: 3774.3303\n",
            "Epoch 125/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -408.0370 - mse: 3772.3867 - val_loss: -408.3277 - val_mse: 3745.0813\n",
            "Epoch 126/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -408.2252 - mse: 3739.9109 - val_loss: -408.4559 - val_mse: 3726.1511\n",
            "Epoch 127/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -408.3393 - mse: 3714.1428 - val_loss: -408.6591 - val_mse: 3706.1924\n",
            "Epoch 128/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -408.5130 - mse: 3686.9211 - val_loss: -408.7488 - val_mse: 3693.4917\n",
            "Epoch 129/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -408.7221 - mse: 3652.3972 - val_loss: -408.9532 - val_mse: 3615.2893\n",
            "Epoch 130/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -408.8795 - mse: 3619.9893 - val_loss: -409.0459 - val_mse: 3635.2129\n",
            "Epoch 131/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -409.0322 - mse: 3597.1897 - val_loss: -409.3433 - val_mse: 3566.9480\n",
            "Epoch 132/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -409.1972 - mse: 3560.7339 - val_loss: -409.4748 - val_mse: 3560.3340\n",
            "Epoch 133/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -409.4197 - mse: 3529.9648 - val_loss: -409.6034 - val_mse: 3524.3616\n",
            "Epoch 134/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -409.5731 - mse: 3499.6799 - val_loss: -409.6796 - val_mse: 3470.2175\n",
            "Epoch 135/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -409.6750 - mse: 3478.9541 - val_loss: -409.5914 - val_mse: 3513.1289\n",
            "Epoch 136/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -409.8268 - mse: 3450.7493 - val_loss: -410.1655 - val_mse: 3418.2888\n",
            "Epoch 137/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -410.0337 - mse: 3423.1279 - val_loss: -410.2508 - val_mse: 3377.5012\n",
            "Epoch 138/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -410.1974 - mse: 3388.9080 - val_loss: -410.4500 - val_mse: 3351.6013\n",
            "Epoch 139/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -410.3246 - mse: 3360.9724 - val_loss: -410.6077 - val_mse: 3324.1396\n",
            "Epoch 140/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -410.5096 - mse: 3338.4568 - val_loss: -410.7005 - val_mse: 3308.1230\n",
            "Epoch 141/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -410.6542 - mse: 3308.9329 - val_loss: -410.6284 - val_mse: 3315.1941\n",
            "Epoch 142/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -410.7686 - mse: 3281.5991 - val_loss: -410.8587 - val_mse: 3250.7976\n",
            "Epoch 143/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -410.9670 - mse: 3255.6636 - val_loss: -411.2137 - val_mse: 3213.5681\n",
            "Epoch 144/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -411.1412 - mse: 3226.4551 - val_loss: -411.2659 - val_mse: 3214.3003\n",
            "Epoch 145/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -411.2329 - mse: 3206.2051 - val_loss: -411.4563 - val_mse: 3158.0820\n",
            "Epoch 146/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -411.4118 - mse: 3175.1592 - val_loss: -411.4169 - val_mse: 3170.7056\n",
            "Epoch 147/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -411.4920 - mse: 3156.4534 - val_loss: -411.8377 - val_mse: 3108.8809\n",
            "Epoch 148/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -411.6761 - mse: 3129.3113 - val_loss: -411.9639 - val_mse: 3076.7788\n",
            "Epoch 149/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -411.7938 - mse: 3103.9929 - val_loss: -412.0104 - val_mse: 3054.0383\n",
            "Epoch 150/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -411.9730 - mse: 3077.8408 - val_loss: -412.1214 - val_mse: 3029.8672\n",
            "Epoch 151/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -412.0793 - mse: 3054.3967 - val_loss: -412.3484 - val_mse: 3014.6389\n",
            "Epoch 152/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -412.1563 - mse: 3040.3325 - val_loss: -412.0648 - val_mse: 3049.9473\n",
            "Epoch 153/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -412.2850 - mse: 3014.7827 - val_loss: -412.5304 - val_mse: 2958.2400\n",
            "Epoch 154/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -412.4587 - mse: 2990.8567 - val_loss: -412.7671 - val_mse: 2944.2588\n",
            "Epoch 155/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -412.6079 - mse: 2960.5215 - val_loss: -412.8490 - val_mse: 2909.8022\n",
            "Epoch 156/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -412.7021 - mse: 2943.4517 - val_loss: -412.9088 - val_mse: 2897.1704\n",
            "Epoch 157/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -412.8248 - mse: 2924.3689 - val_loss: -413.0247 - val_mse: 2871.8057\n",
            "Epoch 158/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -412.9766 - mse: 2899.0166 - val_loss: -412.9857 - val_mse: 2891.6699\n",
            "Epoch 159/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -413.0852 - mse: 2878.4473 - val_loss: -413.4289 - val_mse: 2823.8315\n",
            "Epoch 160/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -413.1363 - mse: 2859.9778 - val_loss: -413.4856 - val_mse: 2808.6201\n",
            "Epoch 161/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -413.2882 - mse: 2835.8003 - val_loss: -413.5400 - val_mse: 2793.2705\n",
            "Epoch 162/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -413.4272 - mse: 2820.5461 - val_loss: -413.7007 - val_mse: 2759.6123\n",
            "Epoch 163/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -413.5377 - mse: 2794.6775 - val_loss: -413.9220 - val_mse: 2749.0120\n",
            "Epoch 164/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -413.6717 - mse: 2772.7834 - val_loss: -413.9525 - val_mse: 2721.2681\n",
            "Epoch 165/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -413.7126 - mse: 2760.2563 - val_loss: -414.1306 - val_mse: 2700.8809\n",
            "Epoch 166/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -413.9072 - mse: 2731.6702 - val_loss: -414.1826 - val_mse: 2678.7854\n",
            "Epoch 167/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -413.9925 - mse: 2711.1455 - val_loss: -414.3941 - val_mse: 2659.0737\n",
            "Epoch 168/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -414.1406 - mse: 2685.2375 - val_loss: -414.4405 - val_mse: 2664.0793\n",
            "Epoch 169/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -414.2388 - mse: 2664.7185 - val_loss: -414.5853 - val_mse: 2628.1211\n",
            "Epoch 170/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -414.3051 - mse: 2651.9524 - val_loss: -414.6807 - val_mse: 2600.2007\n",
            "Epoch 171/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -414.4960 - mse: 2622.7280 - val_loss: -414.8726 - val_mse: 2583.2532\n",
            "Epoch 172/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -414.5735 - mse: 2606.2405 - val_loss: -414.9062 - val_mse: 2554.7402\n",
            "Epoch 173/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -414.6967 - mse: 2583.7690 - val_loss: -415.0663 - val_mse: 2533.1768\n",
            "Epoch 174/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -414.7704 - mse: 2565.9443 - val_loss: -415.1857 - val_mse: 2529.3074\n",
            "Epoch 175/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -414.8955 - mse: 2547.6318 - val_loss: -414.9646 - val_mse: 2575.1895\n",
            "Epoch 176/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -415.0599 - mse: 2523.1760 - val_loss: -415.4146 - val_mse: 2480.4402\n",
            "Epoch 177/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -415.1252 - mse: 2505.1516 - val_loss: -415.3657 - val_mse: 2509.2456\n",
            "Epoch 178/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -415.2114 - mse: 2487.4514 - val_loss: -415.6116 - val_mse: 2459.9360\n",
            "Epoch 179/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -415.3336 - mse: 2471.8691 - val_loss: -415.6943 - val_mse: 2441.1260\n",
            "Epoch 180/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -415.4569 - mse: 2450.3606 - val_loss: -415.6063 - val_mse: 2442.6758\n",
            "Epoch 181/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -415.4538 - mse: 2441.3384 - val_loss: -415.9104 - val_mse: 2391.0176\n",
            "Epoch 182/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -415.5986 - mse: 2416.2920 - val_loss: -415.9367 - val_mse: 2378.4412\n",
            "Epoch 183/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -415.7444 - mse: 2398.4822 - val_loss: -416.0785 - val_mse: 2365.8032\n",
            "Epoch 184/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -415.8278 - mse: 2383.3313 - val_loss: -416.1922 - val_mse: 2342.5737\n",
            "Epoch 185/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -415.9477 - mse: 2359.7766 - val_loss: -416.2189 - val_mse: 2353.0068\n",
            "Epoch 186/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -416.0320 - mse: 2347.1545 - val_loss: -416.3547 - val_mse: 2318.1106\n",
            "Epoch 187/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -416.0481 - mse: 2336.5342 - val_loss: -416.1753 - val_mse: 2332.8186\n",
            "Epoch 188/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -416.1725 - mse: 2318.7317 - val_loss: -416.3273 - val_mse: 2291.8213\n",
            "Epoch 189/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -416.2960 - mse: 2298.1355 - val_loss: -416.4280 - val_mse: 2296.9656\n",
            "Epoch 190/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -416.3047 - mse: 2288.5879 - val_loss: -416.7264 - val_mse: 2258.4695\n",
            "Epoch 191/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -416.4844 - mse: 2264.6345 - val_loss: -416.8140 - val_mse: 2238.7134\n",
            "Epoch 192/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -416.5771 - mse: 2249.9124 - val_loss: -416.8682 - val_mse: 2223.1792\n",
            "Epoch 193/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -416.6543 - mse: 2230.1223 - val_loss: -417.0097 - val_mse: 2209.3103\n",
            "Epoch 194/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -416.7791 - mse: 2214.4578 - val_loss: -417.0611 - val_mse: 2198.2512\n",
            "Epoch 195/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -416.8179 - mse: 2200.2998 - val_loss: -417.0978 - val_mse: 2174.2805\n",
            "Epoch 196/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -416.9386 - mse: 2181.6990 - val_loss: -417.0987 - val_mse: 2190.0483\n",
            "Epoch 197/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -417.0415 - mse: 2162.9106 - val_loss: -417.3693 - val_mse: 2146.4458\n",
            "Epoch 198/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -417.1521 - mse: 2142.1555 - val_loss: -417.5064 - val_mse: 2113.1853\n",
            "Epoch 199/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -417.2650 - mse: 2123.4885 - val_loss: -417.6000 - val_mse: 2096.3059\n",
            "Epoch 200/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -417.3235 - mse: 2106.7485 - val_loss: -417.5841 - val_mse: 2099.7200\n",
            "Epoch 201/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -417.4874 - mse: 2083.3091 - val_loss: -417.6980 - val_mse: 2055.2859\n",
            "Epoch 202/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -417.5386 - mse: 2064.4397 - val_loss: -417.9337 - val_mse: 2030.7646\n",
            "Epoch 203/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -417.7011 - mse: 2038.5558 - val_loss: -418.0576 - val_mse: 2010.9636\n",
            "Epoch 204/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -417.7845 - mse: 2019.8997 - val_loss: -418.1374 - val_mse: 1988.0258\n",
            "Epoch 205/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -417.9357 - mse: 1995.2260 - val_loss: -418.2742 - val_mse: 1975.8966\n",
            "Epoch 206/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -418.0117 - mse: 1973.9706 - val_loss: -418.2294 - val_mse: 1970.8522\n",
            "Epoch 207/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -418.1591 - mse: 1948.2252 - val_loss: -418.4599 - val_mse: 1946.2822\n",
            "Epoch 208/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -418.2351 - mse: 1933.3850 - val_loss: -418.6148 - val_mse: 1908.9832\n",
            "Epoch 209/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -418.3308 - mse: 1907.7484 - val_loss: -418.5935 - val_mse: 1911.1250\n",
            "Epoch 210/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -418.4596 - mse: 1886.9565 - val_loss: -418.7629 - val_mse: 1886.6484\n",
            "Epoch 211/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -418.5692 - mse: 1864.5714 - val_loss: -418.9268 - val_mse: 1856.8446\n",
            "Epoch 212/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -418.6251 - mse: 1849.9158 - val_loss: -418.9053 - val_mse: 1851.1121\n",
            "Epoch 213/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -418.7574 - mse: 1824.8964 - val_loss: -419.0887 - val_mse: 1821.8000\n",
            "Epoch 214/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -418.8611 - mse: 1809.3116 - val_loss: -419.2209 - val_mse: 1792.8724\n",
            "Epoch 215/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -418.9088 - mse: 1792.8173 - val_loss: -419.3118 - val_mse: 1780.3988\n",
            "Epoch 216/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -418.9981 - mse: 1776.6075 - val_loss: -419.3702 - val_mse: 1761.2072\n",
            "Epoch 217/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -419.1012 - mse: 1758.7158 - val_loss: -419.3266 - val_mse: 1748.5992\n",
            "Epoch 218/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -419.1338 - mse: 1747.2290 - val_loss: -419.3658 - val_mse: 1743.5780\n",
            "Epoch 219/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -419.2869 - mse: 1725.0724 - val_loss: -419.5161 - val_mse: 1726.5308\n",
            "Epoch 220/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -419.3604 - mse: 1711.2729 - val_loss: -419.7065 - val_mse: 1695.5200\n",
            "Epoch 221/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -419.4207 - mse: 1696.8022 - val_loss: -419.8192 - val_mse: 1673.7542\n",
            "Epoch 222/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -419.5034 - mse: 1676.4353 - val_loss: -419.9123 - val_mse: 1661.1827\n",
            "Epoch 223/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -419.5595 - mse: 1662.8575 - val_loss: -419.9472 - val_mse: 1643.3871\n",
            "Epoch 224/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -419.6241 - mse: 1650.0724 - val_loss: -420.0448 - val_mse: 1629.7434\n",
            "Epoch 225/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -419.7127 - mse: 1632.0260 - val_loss: -420.0962 - val_mse: 1610.2961\n",
            "Epoch 226/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -419.8027 - mse: 1616.4803 - val_loss: -420.1828 - val_mse: 1599.5190\n",
            "Epoch 227/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -419.8313 - mse: 1603.8221 - val_loss: -420.1959 - val_mse: 1601.3245\n",
            "Epoch 228/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -419.8812 - mse: 1594.7614 - val_loss: -420.0556 - val_mse: 1597.7936\n",
            "Epoch 229/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -419.8960 - mse: 1585.5195 - val_loss: -420.2862 - val_mse: 1571.2198\n",
            "Epoch 230/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -419.9855 - mse: 1571.6743 - val_loss: -420.1342 - val_mse: 1578.5959\n",
            "Epoch 231/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.0298 - mse: 1562.0334 - val_loss: -420.3392 - val_mse: 1556.6847\n",
            "Epoch 232/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -420.0904 - mse: 1548.2308 - val_loss: -420.3753 - val_mse: 1547.1686\n",
            "Epoch 233/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -420.1339 - mse: 1542.6504 - val_loss: -420.4080 - val_mse: 1538.3597\n",
            "Epoch 234/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -420.1635 - mse: 1529.2366 - val_loss: -420.4202 - val_mse: 1543.5753\n",
            "Epoch 235/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -420.1786 - mse: 1524.8105 - val_loss: -420.4700 - val_mse: 1538.3792\n",
            "Epoch 236/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.2472 - mse: 1515.7826 - val_loss: -420.4063 - val_mse: 1530.9188\n",
            "Epoch 237/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.2936 - mse: 1504.6187 - val_loss: -420.6160 - val_mse: 1505.3378\n",
            "Epoch 238/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -420.3248 - mse: 1499.9471 - val_loss: -420.6469 - val_mse: 1491.2679\n",
            "Epoch 239/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.3546 - mse: 1488.3809 - val_loss: -420.6855 - val_mse: 1491.3921\n",
            "Epoch 240/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -420.3761 - mse: 1484.7379 - val_loss: -420.6563 - val_mse: 1487.1317\n",
            "Epoch 241/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.3776 - mse: 1481.1038 - val_loss: -420.6867 - val_mse: 1478.7169\n",
            "Epoch 242/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.4484 - mse: 1469.7104 - val_loss: -420.7847 - val_mse: 1464.6589\n",
            "Epoch 243/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.4678 - mse: 1463.8636 - val_loss: -420.7737 - val_mse: 1454.4856\n",
            "Epoch 244/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.4912 - mse: 1455.4353 - val_loss: -420.8057 - val_mse: 1455.3188\n",
            "Epoch 245/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -420.5157 - mse: 1451.4806 - val_loss: -420.7320 - val_mse: 1453.8177\n",
            "Epoch 246/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -420.5563 - mse: 1444.1859 - val_loss: -420.7604 - val_mse: 1455.5452\n",
            "Epoch 247/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -420.5958 - mse: 1436.0804 - val_loss: -420.9140 - val_mse: 1441.0618\n",
            "Epoch 248/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -420.6157 - mse: 1430.8311 - val_loss: -420.6254 - val_mse: 1450.3173\n",
            "Epoch 249/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -420.6448 - mse: 1425.8837 - val_loss: -420.7946 - val_mse: 1436.5354\n",
            "Epoch 250/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.6341 - mse: 1423.0206 - val_loss: -420.9631 - val_mse: 1428.8110\n",
            "Epoch 251/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -420.6918 - mse: 1417.8773 - val_loss: -421.0187 - val_mse: 1414.1105\n",
            "Epoch 252/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -420.7203 - mse: 1409.1376 - val_loss: -420.9891 - val_mse: 1415.1998\n",
            "Epoch 253/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -420.7345 - mse: 1406.7032 - val_loss: -420.9829 - val_mse: 1412.2565\n",
            "Epoch 254/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.7629 - mse: 1401.0197 - val_loss: -421.0566 - val_mse: 1405.4167\n",
            "Epoch 255/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.7633 - mse: 1398.8726 - val_loss: -421.0567 - val_mse: 1405.9431\n",
            "Epoch 256/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -420.7874 - mse: 1395.2740 - val_loss: -421.0425 - val_mse: 1407.5870\n",
            "Epoch 257/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -420.8218 - mse: 1390.9646 - val_loss: -421.1380 - val_mse: 1385.8196\n",
            "Epoch 258/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -420.8360 - mse: 1384.5895 - val_loss: -421.1043 - val_mse: 1399.9816\n",
            "Epoch 259/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.8589 - mse: 1383.5875 - val_loss: -421.1476 - val_mse: 1383.0953\n",
            "Epoch 260/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.8895 - mse: 1376.6885 - val_loss: -421.1003 - val_mse: 1377.1412\n",
            "Epoch 261/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.8972 - mse: 1373.9738 - val_loss: -421.2135 - val_mse: 1378.3324\n",
            "Epoch 262/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.9191 - mse: 1369.0618 - val_loss: -421.2206 - val_mse: 1384.3022\n",
            "Epoch 263/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.9380 - mse: 1368.5176 - val_loss: -421.2082 - val_mse: 1372.5996\n",
            "Epoch 264/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.9504 - mse: 1364.6954 - val_loss: -421.2235 - val_mse: 1364.5789\n",
            "Epoch 265/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -420.9525 - mse: 1361.6909 - val_loss: -421.2723 - val_mse: 1358.4945\n",
            "Epoch 266/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -420.9746 - mse: 1358.3217 - val_loss: -421.2853 - val_mse: 1354.5532\n",
            "Epoch 267/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.0169 - mse: 1353.3783 - val_loss: -421.2152 - val_mse: 1356.5426\n",
            "Epoch 268/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.0112 - mse: 1351.2096 - val_loss: -421.2502 - val_mse: 1358.2122\n",
            "Epoch 269/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.0500 - mse: 1346.6045 - val_loss: -421.3423 - val_mse: 1347.5214\n",
            "Epoch 270/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.0388 - mse: 1344.9657 - val_loss: -421.1280 - val_mse: 1367.8921\n",
            "Epoch 271/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.0697 - mse: 1340.6686 - val_loss: -421.3248 - val_mse: 1349.3958\n",
            "Epoch 272/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.0757 - mse: 1338.7115 - val_loss: -421.3844 - val_mse: 1341.6990\n",
            "Epoch 273/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.0689 - mse: 1338.5125 - val_loss: -421.4120 - val_mse: 1334.4648\n",
            "Epoch 274/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.1153 - mse: 1332.1379 - val_loss: -421.4325 - val_mse: 1335.6576\n",
            "Epoch 275/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.1137 - mse: 1329.8962 - val_loss: -421.4432 - val_mse: 1339.9637\n",
            "Epoch 276/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.1567 - mse: 1327.3348 - val_loss: -421.3457 - val_mse: 1334.1868\n",
            "Epoch 277/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.1449 - mse: 1325.2025 - val_loss: -421.3204 - val_mse: 1337.3090\n",
            "Epoch 278/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.1765 - mse: 1319.7034 - val_loss: -421.4658 - val_mse: 1329.3848\n",
            "Epoch 279/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.1905 - mse: 1318.5201 - val_loss: -421.5041 - val_mse: 1320.7343\n",
            "Epoch 280/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.2137 - mse: 1314.2438 - val_loss: -421.5162 - val_mse: 1322.7885\n",
            "Epoch 281/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.1836 - mse: 1313.4771 - val_loss: -421.5125 - val_mse: 1324.1630\n",
            "Epoch 282/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.2065 - mse: 1312.3215 - val_loss: -421.5257 - val_mse: 1322.9053\n",
            "Epoch 283/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.2410 - mse: 1310.2177 - val_loss: -421.4883 - val_mse: 1316.0415\n",
            "Epoch 284/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.2378 - mse: 1307.4926 - val_loss: -421.5253 - val_mse: 1312.6548\n",
            "Epoch 285/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.2450 - mse: 1303.4583 - val_loss: -421.5298 - val_mse: 1314.2775\n",
            "Epoch 286/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.2724 - mse: 1302.2437 - val_loss: -421.5796 - val_mse: 1315.5472\n",
            "Epoch 287/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.2776 - mse: 1300.3630 - val_loss: -421.5159 - val_mse: 1315.2864\n",
            "Epoch 288/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.3039 - mse: 1296.5734 - val_loss: -421.4561 - val_mse: 1319.4550\n",
            "Epoch 289/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.3181 - mse: 1294.1409 - val_loss: -421.5769 - val_mse: 1302.4821\n",
            "Epoch 290/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.3316 - mse: 1291.2959 - val_loss: -421.6313 - val_mse: 1301.4191\n",
            "Epoch 291/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.3304 - mse: 1290.7540 - val_loss: -421.6275 - val_mse: 1302.9739\n",
            "Epoch 292/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.3509 - mse: 1287.8618 - val_loss: -421.5637 - val_mse: 1298.7286\n",
            "Epoch 293/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.3510 - mse: 1286.5754 - val_loss: -421.6395 - val_mse: 1297.7234\n",
            "Epoch 294/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.3597 - mse: 1284.3303 - val_loss: -421.6417 - val_mse: 1297.0337\n",
            "Epoch 295/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.3669 - mse: 1283.2010 - val_loss: -421.6282 - val_mse: 1291.5454\n",
            "Epoch 296/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.3856 - mse: 1278.5177 - val_loss: -421.6845 - val_mse: 1292.1726\n",
            "Epoch 297/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.3957 - mse: 1279.8417 - val_loss: -421.7085 - val_mse: 1285.5867\n",
            "Epoch 298/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.4008 - mse: 1275.8569 - val_loss: -421.7126 - val_mse: 1287.4524\n",
            "Epoch 299/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.4123 - mse: 1275.4536 - val_loss: -421.7245 - val_mse: 1283.0016\n",
            "Epoch 300/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -421.4030 - mse: 1274.4232 - val_loss: -421.7125 - val_mse: 1279.2772\n",
            "Epoch 301/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.4321 - mse: 1271.5746 - val_loss: -421.7339 - val_mse: 1283.0460\n",
            "Epoch 302/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.4408 - mse: 1269.8010 - val_loss: -421.7337 - val_mse: 1278.4141\n",
            "Epoch 303/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.4537 - mse: 1268.3892 - val_loss: -421.7534 - val_mse: 1274.1389\n",
            "Epoch 304/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.4648 - mse: 1264.6023 - val_loss: -421.7357 - val_mse: 1286.5835\n",
            "Epoch 305/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.4772 - mse: 1267.2433 - val_loss: -421.7561 - val_mse: 1268.5048\n",
            "Epoch 306/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.4951 - mse: 1261.2124 - val_loss: -421.7414 - val_mse: 1283.8289\n",
            "Epoch 307/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.4666 - mse: 1262.6040 - val_loss: -421.7522 - val_mse: 1274.2417\n",
            "Epoch 308/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.4955 - mse: 1260.4191 - val_loss: -421.7719 - val_mse: 1269.5817\n",
            "Epoch 309/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.5003 - mse: 1259.7284 - val_loss: -421.7988 - val_mse: 1266.7932\n",
            "Epoch 310/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.5139 - mse: 1255.5494 - val_loss: -421.8054 - val_mse: 1267.6611\n",
            "Epoch 311/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.5221 - mse: 1255.6556 - val_loss: -421.7558 - val_mse: 1270.8785\n",
            "Epoch 312/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.5068 - mse: 1256.2219 - val_loss: -421.7802 - val_mse: 1270.5039\n",
            "Epoch 313/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.5252 - mse: 1253.4845 - val_loss: -421.8406 - val_mse: 1261.9180\n",
            "Epoch 314/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.5326 - mse: 1251.7690 - val_loss: -421.8445 - val_mse: 1262.8605\n",
            "Epoch 315/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.5610 - mse: 1250.3964 - val_loss: -421.8533 - val_mse: 1262.7638\n",
            "Epoch 316/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.5614 - mse: 1247.8064 - val_loss: -421.7069 - val_mse: 1271.3162\n",
            "Epoch 317/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.5661 - mse: 1247.0320 - val_loss: -421.8607 - val_mse: 1258.0116\n",
            "Epoch 318/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.5665 - mse: 1247.8795 - val_loss: -421.6697 - val_mse: 1268.2539\n",
            "Epoch 319/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.5702 - mse: 1245.0410 - val_loss: -421.6092 - val_mse: 1277.0710\n",
            "Epoch 320/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.5774 - mse: 1243.8717 - val_loss: -421.8131 - val_mse: 1263.2615\n",
            "Epoch 321/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.5903 - mse: 1243.7744 - val_loss: -421.8903 - val_mse: 1252.0525\n",
            "Epoch 322/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6030 - mse: 1241.0635 - val_loss: -421.8690 - val_mse: 1249.0459\n",
            "Epoch 323/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.6089 - mse: 1238.2281 - val_loss: -421.7676 - val_mse: 1263.6842\n",
            "Epoch 324/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.6073 - mse: 1239.0815 - val_loss: -421.5634 - val_mse: 1276.8190\n",
            "Epoch 325/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6233 - mse: 1237.0446 - val_loss: -421.8694 - val_mse: 1253.8362\n",
            "Epoch 326/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.6327 - mse: 1235.9008 - val_loss: -421.9198 - val_mse: 1245.0824\n",
            "Epoch 327/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6153 - mse: 1235.5463 - val_loss: -421.9204 - val_mse: 1250.8813\n",
            "Epoch 328/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.6272 - mse: 1235.3231 - val_loss: -421.9251 - val_mse: 1249.4943\n",
            "Epoch 329/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6441 - mse: 1234.2386 - val_loss: -421.8871 - val_mse: 1250.5923\n",
            "Epoch 330/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6607 - mse: 1230.9813 - val_loss: -421.9097 - val_mse: 1247.1490\n",
            "Epoch 331/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6617 - mse: 1229.1128 - val_loss: -421.8008 - val_mse: 1254.5538\n",
            "Epoch 332/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.6465 - mse: 1230.7429 - val_loss: -421.9477 - val_mse: 1242.7688\n",
            "Epoch 333/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.6665 - mse: 1228.2313 - val_loss: -421.8827 - val_mse: 1247.1934\n",
            "Epoch 334/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6659 - mse: 1228.5376 - val_loss: -421.9501 - val_mse: 1244.6639\n",
            "Epoch 335/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6843 - mse: 1224.4722 - val_loss: -421.9558 - val_mse: 1248.7834\n",
            "Epoch 336/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.6885 - mse: 1225.0887 - val_loss: -421.9202 - val_mse: 1252.6689\n",
            "Epoch 337/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.6760 - mse: 1226.9955 - val_loss: -421.7933 - val_mse: 1259.1895\n",
            "Epoch 338/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.6890 - mse: 1224.2924 - val_loss: -421.9582 - val_mse: 1238.4286\n",
            "Epoch 339/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.7004 - mse: 1222.4510 - val_loss: -421.9447 - val_mse: 1239.3594\n",
            "Epoch 340/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7117 - mse: 1222.5171 - val_loss: -421.9926 - val_mse: 1236.7568\n",
            "Epoch 341/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7260 - mse: 1219.7950 - val_loss: -421.9929 - val_mse: 1238.5980\n",
            "Epoch 342/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.7060 - mse: 1219.5697 - val_loss: -421.9575 - val_mse: 1240.2697\n",
            "Epoch 343/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.7306 - mse: 1216.8267 - val_loss: -421.9839 - val_mse: 1239.7877\n",
            "Epoch 344/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.7218 - mse: 1219.6703 - val_loss: -421.9969 - val_mse: 1229.9102\n",
            "Epoch 345/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -421.7320 - mse: 1217.3853 - val_loss: -422.0145 - val_mse: 1229.0518\n",
            "Epoch 346/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.7472 - mse: 1214.6748 - val_loss: -422.0135 - val_mse: 1233.6384\n",
            "Epoch 347/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7486 - mse: 1213.2584 - val_loss: -421.9453 - val_mse: 1236.9775\n",
            "Epoch 348/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.7497 - mse: 1214.4408 - val_loss: -421.8512 - val_mse: 1247.8546\n",
            "Epoch 349/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.7598 - mse: 1213.3837 - val_loss: -422.0244 - val_mse: 1230.2578\n",
            "Epoch 350/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.7421 - mse: 1211.5970 - val_loss: -421.8777 - val_mse: 1244.2800\n",
            "Epoch 351/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.7662 - mse: 1212.5483 - val_loss: -422.0290 - val_mse: 1233.2046\n",
            "Epoch 352/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.7725 - mse: 1209.3149 - val_loss: -422.0154 - val_mse: 1232.8401\n",
            "Epoch 353/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7753 - mse: 1209.9156 - val_loss: -422.0250 - val_mse: 1227.5469\n",
            "Epoch 354/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.7599 - mse: 1209.5970 - val_loss: -421.9551 - val_mse: 1235.5450\n",
            "Epoch 355/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.7891 - mse: 1207.9517 - val_loss: -422.0398 - val_mse: 1232.7393\n",
            "Epoch 356/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7940 - mse: 1206.9434 - val_loss: -422.0524 - val_mse: 1228.7607\n",
            "Epoch 357/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.7735 - mse: 1206.6143 - val_loss: -422.0604 - val_mse: 1235.0581\n",
            "Epoch 358/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.8032 - mse: 1204.8966 - val_loss: -422.0524 - val_mse: 1230.1364\n",
            "Epoch 359/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8047 - mse: 1204.6104 - val_loss: -422.0601 - val_mse: 1223.3822\n",
            "Epoch 360/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8101 - mse: 1203.2322 - val_loss: -422.0019 - val_mse: 1228.6827\n",
            "Epoch 361/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8151 - mse: 1201.6379 - val_loss: -422.0532 - val_mse: 1227.5223\n",
            "Epoch 362/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.8182 - mse: 1199.5574 - val_loss: -422.0681 - val_mse: 1228.6980\n",
            "Epoch 363/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8047 - mse: 1202.9904 - val_loss: -422.0336 - val_mse: 1222.4813\n",
            "Epoch 364/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8199 - mse: 1199.3815 - val_loss: -422.0771 - val_mse: 1227.2039\n",
            "Epoch 365/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8247 - mse: 1198.9656 - val_loss: -422.0466 - val_mse: 1230.6666\n",
            "Epoch 366/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8325 - mse: 1198.4093 - val_loss: -422.0540 - val_mse: 1227.5566\n",
            "Epoch 367/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.8281 - mse: 1198.2153 - val_loss: -421.9489 - val_mse: 1234.5902\n",
            "Epoch 368/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8486 - mse: 1196.3407 - val_loss: -421.7751 - val_mse: 1235.6469\n",
            "Epoch 369/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8462 - mse: 1195.6910 - val_loss: -422.0847 - val_mse: 1220.1406\n",
            "Epoch 370/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8553 - mse: 1194.9261 - val_loss: -422.0927 - val_mse: 1217.4100\n",
            "Epoch 371/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8481 - mse: 1194.2728 - val_loss: -422.0947 - val_mse: 1222.4011\n",
            "Epoch 372/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8463 - mse: 1193.8646 - val_loss: -422.0975 - val_mse: 1224.3824\n",
            "Epoch 373/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8636 - mse: 1193.6978 - val_loss: -422.0946 - val_mse: 1217.4185\n",
            "Epoch 374/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8703 - mse: 1193.2559 - val_loss: -422.0474 - val_mse: 1214.9840\n",
            "Epoch 375/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.8604 - mse: 1191.8540 - val_loss: -422.0849 - val_mse: 1218.8741\n",
            "Epoch 376/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -421.8676 - mse: 1191.7251 - val_loss: -422.0768 - val_mse: 1221.7291\n",
            "Epoch 377/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8723 - mse: 1191.4711 - val_loss: -422.0628 - val_mse: 1223.1115\n",
            "Epoch 378/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8818 - mse: 1189.7059 - val_loss: -422.1146 - val_mse: 1216.9674\n",
            "Epoch 379/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8806 - mse: 1189.7939 - val_loss: -422.0610 - val_mse: 1212.4333\n",
            "Epoch 380/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8854 - mse: 1186.5167 - val_loss: -422.1019 - val_mse: 1214.8107\n",
            "Epoch 381/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8874 - mse: 1186.3064 - val_loss: -422.1113 - val_mse: 1216.5643\n",
            "Epoch 382/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.8937 - mse: 1186.4987 - val_loss: -422.0493 - val_mse: 1217.8875\n",
            "Epoch 383/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9042 - mse: 1185.3849 - val_loss: -422.0903 - val_mse: 1221.4781\n",
            "Epoch 384/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8967 - mse: 1186.9597 - val_loss: -422.0908 - val_mse: 1209.1388\n",
            "Epoch 385/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9057 - mse: 1184.2957 - val_loss: -422.0630 - val_mse: 1215.5691\n",
            "Epoch 386/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9013 - mse: 1184.0249 - val_loss: -422.1265 - val_mse: 1217.9535\n",
            "Epoch 387/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.8943 - mse: 1184.9935 - val_loss: -422.1071 - val_mse: 1211.4784\n",
            "Epoch 388/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9154 - mse: 1180.7168 - val_loss: -422.1291 - val_mse: 1219.1346\n",
            "Epoch 389/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9218 - mse: 1183.0212 - val_loss: -422.1225 - val_mse: 1211.1425\n",
            "Epoch 390/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9225 - mse: 1181.9595 - val_loss: -422.1345 - val_mse: 1213.3954\n",
            "Epoch 391/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.8997 - mse: 1180.5334 - val_loss: -422.1233 - val_mse: 1215.9358\n",
            "Epoch 392/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9188 - mse: 1180.4229 - val_loss: -421.8784 - val_mse: 1229.5422\n",
            "Epoch 393/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9107 - mse: 1182.2561 - val_loss: -422.1109 - val_mse: 1212.2017\n",
            "Epoch 394/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9413 - mse: 1178.1831 - val_loss: -422.0868 - val_mse: 1215.6460\n",
            "Epoch 395/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9390 - mse: 1177.9493 - val_loss: -422.1323 - val_mse: 1211.6278\n",
            "Epoch 396/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9180 - mse: 1178.7399 - val_loss: -422.1412 - val_mse: 1207.7018\n",
            "Epoch 397/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9434 - mse: 1176.7056 - val_loss: -422.1507 - val_mse: 1211.2509\n",
            "Epoch 398/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9504 - mse: 1177.1227 - val_loss: -422.1274 - val_mse: 1210.7980\n",
            "Epoch 399/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9378 - mse: 1177.7273 - val_loss: -422.1415 - val_mse: 1208.2463\n",
            "Epoch 400/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9239 - mse: 1177.1971 - val_loss: -421.9355 - val_mse: 1217.6523\n",
            "Epoch 401/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9422 - mse: 1174.4111 - val_loss: -422.1486 - val_mse: 1208.8759\n",
            "Epoch 402/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9653 - mse: 1174.2393 - val_loss: -422.0240 - val_mse: 1211.9355\n",
            "Epoch 403/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9675 - mse: 1173.4325 - val_loss: -422.1527 - val_mse: 1204.2299\n",
            "Epoch 404/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9739 - mse: 1172.3107 - val_loss: -422.1549 - val_mse: 1211.1460\n",
            "Epoch 405/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9549 - mse: 1172.6650 - val_loss: -422.1479 - val_mse: 1207.4274\n",
            "Epoch 406/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9690 - mse: 1171.2242 - val_loss: -422.0737 - val_mse: 1210.7451\n",
            "Epoch 407/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9841 - mse: 1170.0837 - val_loss: -422.1558 - val_mse: 1202.1255\n",
            "Epoch 408/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9765 - mse: 1170.0891 - val_loss: -421.9790 - val_mse: 1218.1414\n",
            "Epoch 409/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9628 - mse: 1170.5330 - val_loss: -421.8054 - val_mse: 1233.2632\n",
            "Epoch 410/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9756 - mse: 1172.3164 - val_loss: -421.9998 - val_mse: 1205.4280\n",
            "Epoch 411/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9769 - mse: 1166.4923 - val_loss: -422.1214 - val_mse: 1215.6119\n",
            "Epoch 412/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9890 - mse: 1169.0449 - val_loss: -422.0181 - val_mse: 1221.3660\n",
            "Epoch 413/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9988 - mse: 1168.8992 - val_loss: -422.1634 - val_mse: 1202.1094\n",
            "Epoch 414/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9822 - mse: 1167.0125 - val_loss: -422.1707 - val_mse: 1210.1884\n",
            "Epoch 415/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9904 - mse: 1167.6787 - val_loss: -422.1315 - val_mse: 1207.4514\n",
            "Epoch 416/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -421.9926 - mse: 1165.8365 - val_loss: -422.1697 - val_mse: 1201.4116\n",
            "Epoch 417/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -421.9915 - mse: 1166.8472 - val_loss: -422.1735 - val_mse: 1201.9857\n",
            "Epoch 418/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0040 - mse: 1164.4865 - val_loss: -422.0895 - val_mse: 1210.3499\n",
            "Epoch 419/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0183 - mse: 1163.3774 - val_loss: -422.1700 - val_mse: 1203.7313\n",
            "Epoch 420/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0055 - mse: 1163.7040 - val_loss: -422.1807 - val_mse: 1206.0590\n",
            "Epoch 421/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0065 - mse: 1163.6781 - val_loss: -422.1258 - val_mse: 1208.4498\n",
            "Epoch 422/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0058 - mse: 1163.8518 - val_loss: -422.1524 - val_mse: 1210.4534\n",
            "Epoch 423/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0202 - mse: 1162.0105 - val_loss: -422.1351 - val_mse: 1203.7625\n",
            "Epoch 424/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0239 - mse: 1162.6136 - val_loss: -422.0843 - val_mse: 1203.8414\n",
            "Epoch 425/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0095 - mse: 1161.1163 - val_loss: -422.1409 - val_mse: 1202.4749\n",
            "Epoch 426/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.0331 - mse: 1159.6829 - val_loss: -422.1216 - val_mse: 1205.3889\n",
            "Epoch 427/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0288 - mse: 1158.0508 - val_loss: -422.1311 - val_mse: 1206.4607\n",
            "Epoch 428/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0193 - mse: 1161.1385 - val_loss: -422.1141 - val_mse: 1207.7893\n",
            "Epoch 429/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0350 - mse: 1159.1807 - val_loss: -422.1223 - val_mse: 1205.3586\n",
            "Epoch 430/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0387 - mse: 1158.6035 - val_loss: -422.1794 - val_mse: 1196.8488\n",
            "Epoch 431/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0411 - mse: 1156.3008 - val_loss: -422.1854 - val_mse: 1207.7279\n",
            "Epoch 432/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -422.0377 - mse: 1157.8184 - val_loss: -422.1780 - val_mse: 1199.6809\n",
            "Epoch 433/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0355 - mse: 1157.5330 - val_loss: -422.1743 - val_mse: 1201.7919\n",
            "Epoch 434/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0389 - mse: 1156.9412 - val_loss: -422.1521 - val_mse: 1200.1661\n",
            "Epoch 435/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0483 - mse: 1155.9642 - val_loss: -422.0851 - val_mse: 1205.7083\n",
            "Epoch 436/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0423 - mse: 1156.9038 - val_loss: -422.1365 - val_mse: 1198.4812\n",
            "Epoch 437/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0402 - mse: 1155.5615 - val_loss: -422.1706 - val_mse: 1195.7155\n",
            "Epoch 438/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0516 - mse: 1153.8365 - val_loss: -422.1474 - val_mse: 1207.8376\n",
            "Epoch 439/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0495 - mse: 1155.5955 - val_loss: -422.1257 - val_mse: 1207.1720\n",
            "Epoch 440/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0463 - mse: 1154.6526 - val_loss: -422.1764 - val_mse: 1200.6720\n",
            "Epoch 441/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0502 - mse: 1153.5510 - val_loss: -422.1953 - val_mse: 1201.6927\n",
            "Epoch 442/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0673 - mse: 1153.6232 - val_loss: -422.0634 - val_mse: 1201.7769\n",
            "Epoch 443/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0580 - mse: 1152.1981 - val_loss: -422.1992 - val_mse: 1198.9323\n",
            "Epoch 444/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0720 - mse: 1151.8204 - val_loss: -422.1817 - val_mse: 1198.7178\n",
            "Epoch 445/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0747 - mse: 1151.3580 - val_loss: -422.1110 - val_mse: 1206.5245\n",
            "Epoch 446/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0527 - mse: 1152.2054 - val_loss: -422.1928 - val_mse: 1195.2511\n",
            "Epoch 447/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0750 - mse: 1150.6492 - val_loss: -422.1788 - val_mse: 1201.6250\n",
            "Epoch 448/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0584 - mse: 1150.5315 - val_loss: -422.1942 - val_mse: 1198.4666\n",
            "Epoch 449/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0507 - mse: 1151.3507 - val_loss: -422.1978 - val_mse: 1198.5305\n",
            "Epoch 450/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0848 - mse: 1149.4690 - val_loss: -422.1804 - val_mse: 1195.9264\n",
            "Epoch 451/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0732 - mse: 1148.7712 - val_loss: -422.1348 - val_mse: 1195.0573\n",
            "Epoch 452/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0782 - mse: 1148.2660 - val_loss: -422.2032 - val_mse: 1197.6102\n",
            "Epoch 453/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0876 - mse: 1148.2208 - val_loss: -422.1437 - val_mse: 1196.0537\n",
            "Epoch 454/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0772 - mse: 1147.0850 - val_loss: -422.1752 - val_mse: 1206.5994\n",
            "Epoch 455/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0884 - mse: 1148.4644 - val_loss: -422.2038 - val_mse: 1195.4406\n",
            "Epoch 456/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0932 - mse: 1145.4617 - val_loss: -422.1954 - val_mse: 1199.6478\n",
            "Epoch 457/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0750 - mse: 1148.5431 - val_loss: -422.0406 - val_mse: 1203.2177\n",
            "Epoch 458/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0997 - mse: 1145.2021 - val_loss: -422.1751 - val_mse: 1194.5443\n",
            "Epoch 459/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0982 - mse: 1146.1318 - val_loss: -422.0964 - val_mse: 1196.7058\n",
            "Epoch 460/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0974 - mse: 1144.0035 - val_loss: -422.1451 - val_mse: 1199.9841\n",
            "Epoch 461/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0964 - mse: 1146.2347 - val_loss: -422.1976 - val_mse: 1194.3184\n",
            "Epoch 462/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0970 - mse: 1142.9417 - val_loss: -422.2114 - val_mse: 1194.9723\n",
            "Epoch 463/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.1018 - mse: 1144.5505 - val_loss: -421.9894 - val_mse: 1206.1011\n",
            "Epoch 464/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.1039 - mse: 1143.7931 - val_loss: -422.1132 - val_mse: 1198.5389\n",
            "Epoch 465/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1084 - mse: 1143.4272 - val_loss: -422.0302 - val_mse: 1202.8102\n",
            "Epoch 466/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1113 - mse: 1141.6935 - val_loss: -422.1704 - val_mse: 1199.4727\n",
            "Epoch 467/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1148 - mse: 1140.6979 - val_loss: -422.2110 - val_mse: 1199.1958\n",
            "Epoch 468/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.0968 - mse: 1142.7054 - val_loss: -422.2050 - val_mse: 1194.5715\n",
            "Epoch 469/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.0931 - mse: 1143.0625 - val_loss: -422.1538 - val_mse: 1198.5985\n",
            "Epoch 470/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1128 - mse: 1141.8645 - val_loss: -422.0802 - val_mse: 1199.8583\n",
            "Epoch 471/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.1110 - mse: 1140.7794 - val_loss: -422.1808 - val_mse: 1189.1877\n",
            "Epoch 472/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1229 - mse: 1140.3071 - val_loss: -421.7662 - val_mse: 1221.1021\n",
            "Epoch 473/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1140 - mse: 1139.4310 - val_loss: -422.0942 - val_mse: 1199.7748\n",
            "Epoch 474/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1215 - mse: 1141.0428 - val_loss: -422.2098 - val_mse: 1192.0566\n",
            "Epoch 475/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -422.1183 - mse: 1138.4198 - val_loss: -422.1920 - val_mse: 1199.6893\n",
            "Epoch 476/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1319 - mse: 1139.2885 - val_loss: -422.1002 - val_mse: 1194.0742\n",
            "Epoch 477/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -422.1261 - mse: 1138.3676 - val_loss: -422.2078 - val_mse: 1192.8488\n",
            "Save file name colab_notebook_data/feature_interactions/trained_models/poissonloss/poscontrol_model-onelayer_l1reg-0.0_seed100_bsdzv.h5\n",
            "Training model colab_notebook_data/feature_interactions/trained_models/poissonloss/negcontrol_model-onelayer_l1reg-0.0_seed100_axanf.h5\n",
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_17 (InputLayer)        (None, 100, 4)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_17 (Conv1D)           (None, 76, 64)            6464      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_17  (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 10,689\n",
            "Trainable params: 10,689\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "40000/40000 [==============================] - 1s 28us/step - loss: -314.3680 - mse: 20559.4941 - val_loss: -444.3100 - val_mse: 16103.8867\n",
            "Epoch 2/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -482.7597 - mse: 12302.1035 - val_loss: -505.6774 - val_mse: 9332.5508\n",
            "Epoch 3/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -512.8719 - mse: 8017.1450 - val_loss: -516.4813 - val_mse: 7247.3423\n",
            "Epoch 4/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -517.4750 - mse: 7042.4561 - val_loss: -517.7038 - val_mse: 6952.7095\n",
            "Epoch 5/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -517.9220 - mse: 6931.4082 - val_loss: -517.7919 - val_mse: 6929.7534\n",
            "Epoch 6/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -517.9551 - mse: 6922.7178 - val_loss: -517.8016 - val_mse: 6927.1719\n",
            "Epoch 7/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -517.9635 - mse: 6920.4727 - val_loss: -517.8072 - val_mse: 6925.6431\n",
            "Epoch 8/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -517.9696 - mse: 6918.8218 - val_loss: -517.8168 - val_mse: 6923.1143\n",
            "Epoch 9/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -517.9783 - mse: 6916.5166 - val_loss: -517.8268 - val_mse: 6920.4634\n",
            "Epoch 10/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -517.9903 - mse: 6913.3408 - val_loss: -517.8386 - val_mse: 6917.3369\n",
            "Epoch 11/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -518.0035 - mse: 6909.8174 - val_loss: -517.8530 - val_mse: 6913.5400\n",
            "Epoch 12/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -518.0205 - mse: 6905.3296 - val_loss: -517.8716 - val_mse: 6908.5825\n",
            "Epoch 13/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -518.0417 - mse: 6899.6616 - val_loss: -517.8944 - val_mse: 6902.4434\n",
            "Epoch 14/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -518.0690 - mse: 6892.4062 - val_loss: -517.9237 - val_mse: 6894.8306\n",
            "Epoch 15/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -518.1028 - mse: 6883.4849 - val_loss: -517.9636 - val_mse: 6884.1226\n",
            "Epoch 16/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -518.1498 - mse: 6870.9160 - val_loss: -518.0170 - val_mse: 6870.1479\n",
            "Epoch 17/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -518.2182 - mse: 6852.8486 - val_loss: -518.0878 - val_mse: 6852.1714\n",
            "Epoch 18/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -518.3163 - mse: 6827.2358 - val_loss: -518.2217 - val_mse: 6816.4727\n",
            "Epoch 19/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -518.4848 - mse: 6782.8398 - val_loss: -518.4062 - val_mse: 6766.6929\n",
            "Epoch 20/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -518.6976 - mse: 6727.1582 - val_loss: -518.6378 - val_mse: 6705.5767\n",
            "Epoch 21/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -518.9676 - mse: 6656.7666 - val_loss: -518.9151 - val_mse: 6639.5918\n",
            "Epoch 22/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -519.2970 - mse: 6572.1641 - val_loss: -519.2556 - val_mse: 6551.5083\n",
            "Epoch 23/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -519.6154 - mse: 6491.3262 - val_loss: -519.5072 - val_mse: 6483.0571\n",
            "Epoch 24/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -519.8410 - mse: 6434.6094 - val_loss: -519.6857 - val_mse: 6441.8301\n",
            "Epoch 25/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -519.9770 - mse: 6400.7124 - val_loss: -519.7150 - val_mse: 6442.3433\n",
            "Epoch 26/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.0310 - mse: 6387.9756 - val_loss: -519.7962 - val_mse: 6420.9180\n",
            "Epoch 27/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.0623 - mse: 6381.2925 - val_loss: -519.8242 - val_mse: 6414.1851\n",
            "Epoch 28/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -520.0787 - mse: 6377.7290 - val_loss: -519.8319 - val_mse: 6412.8950\n",
            "Epoch 29/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.0827 - mse: 6377.1538 - val_loss: -519.8383 - val_mse: 6411.6953\n",
            "Epoch 30/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.0899 - mse: 6375.5151 - val_loss: -519.8352 - val_mse: 6412.8838\n",
            "Epoch 31/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.0912 - mse: 6375.6494 - val_loss: -519.8456 - val_mse: 6410.2056\n",
            "Epoch 32/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.0908 - mse: 6375.3994 - val_loss: -519.8468 - val_mse: 6410.5542\n",
            "Epoch 33/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1001 - mse: 6373.4863 - val_loss: -519.8491 - val_mse: 6409.9878\n",
            "Epoch 34/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1080 - mse: 6371.5195 - val_loss: -519.8545 - val_mse: 6408.9272\n",
            "Epoch 35/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1021 - mse: 6373.6343 - val_loss: -519.8553 - val_mse: 6408.5513\n",
            "Epoch 36/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -520.1028 - mse: 6373.3242 - val_loss: -519.8594 - val_mse: 6407.7896\n",
            "Epoch 37/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1107 - mse: 6371.1670 - val_loss: -519.8588 - val_mse: 6407.8374\n",
            "Epoch 38/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1088 - mse: 6371.3599 - val_loss: -519.8647 - val_mse: 6406.3564\n",
            "Epoch 39/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1057 - mse: 6372.2065 - val_loss: -519.8661 - val_mse: 6406.2002\n",
            "Epoch 40/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -520.1113 - mse: 6370.3516 - val_loss: -519.8665 - val_mse: 6406.3345\n",
            "Epoch 41/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1230 - mse: 6368.4146 - val_loss: -519.8754 - val_mse: 6403.8018\n",
            "Epoch 42/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -520.1133 - mse: 6370.7598 - val_loss: -519.8511 - val_mse: 6409.8726\n",
            "Epoch 43/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1336 - mse: 6365.2495 - val_loss: -519.8470 - val_mse: 6411.8501\n",
            "Epoch 44/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1299 - mse: 6366.2964 - val_loss: -519.8796 - val_mse: 6402.9390\n",
            "Epoch 45/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1374 - mse: 6364.5698 - val_loss: -519.8969 - val_mse: 6398.7842\n",
            "Epoch 46/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1455 - mse: 6361.4878 - val_loss: -519.9011 - val_mse: 6397.5171\n",
            "Epoch 47/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -520.1530 - mse: 6360.0283 - val_loss: -519.9080 - val_mse: 6395.5122\n",
            "Epoch 48/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.1528 - mse: 6360.1846 - val_loss: -519.9087 - val_mse: 6395.7793\n",
            "Epoch 49/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -520.1657 - mse: 6358.0874 - val_loss: -519.9267 - val_mse: 6391.0283\n",
            "Epoch 50/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -520.1877 - mse: 6352.3521 - val_loss: -519.9495 - val_mse: 6385.4580\n",
            "Epoch 51/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.2097 - mse: 6346.2842 - val_loss: -519.9680 - val_mse: 6380.5459\n",
            "Epoch 52/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.2311 - mse: 6340.6548 - val_loss: -519.9535 - val_mse: 6384.4346\n",
            "Epoch 53/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.2365 - mse: 6339.0547 - val_loss: -520.0065 - val_mse: 6371.0742\n",
            "Epoch 54/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -520.2786 - mse: 6328.2798 - val_loss: -520.0389 - val_mse: 6362.7881\n",
            "Epoch 55/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.2936 - mse: 6325.1797 - val_loss: -520.0691 - val_mse: 6355.0156\n",
            "Epoch 56/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.3319 - mse: 6314.7158 - val_loss: -520.0889 - val_mse: 6350.1934\n",
            "Epoch 57/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.3854 - mse: 6301.2471 - val_loss: -520.1132 - val_mse: 6343.1118\n",
            "Epoch 58/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.4163 - mse: 6292.9863 - val_loss: -520.1913 - val_mse: 6323.5547\n",
            "Epoch 59/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.4842 - mse: 6275.5889 - val_loss: -520.1465 - val_mse: 6336.9194\n",
            "Epoch 60/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.5346 - mse: 6261.8711 - val_loss: -520.3202 - val_mse: 6288.3179\n",
            "Epoch 61/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.6402 - mse: 6235.1035 - val_loss: -520.4066 - val_mse: 6268.5654\n",
            "Epoch 62/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.7438 - mse: 6208.5786 - val_loss: -520.5191 - val_mse: 6239.8442\n",
            "Epoch 63/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -520.8594 - mse: 6179.6587 - val_loss: -520.6497 - val_mse: 6200.2402\n",
            "Epoch 64/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -521.0313 - mse: 6134.4346 - val_loss: -520.7706 - val_mse: 6167.2285\n",
            "Epoch 65/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -521.2287 - mse: 6082.8809 - val_loss: -521.0181 - val_mse: 6112.4810\n",
            "Epoch 66/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -521.4486 - mse: 6026.3564 - val_loss: -521.1713 - val_mse: 6079.7852\n",
            "Epoch 67/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -521.6980 - mse: 5963.9160 - val_loss: -521.4872 - val_mse: 5980.4546\n",
            "Epoch 68/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -521.9702 - mse: 5893.5801 - val_loss: -521.7361 - val_mse: 5934.8081\n",
            "Epoch 69/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -522.2783 - mse: 5816.4346 - val_loss: -522.0386 - val_mse: 5857.8257\n",
            "Epoch 70/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -522.5879 - mse: 5737.0952 - val_loss: -522.3782 - val_mse: 5767.4531\n",
            "Epoch 71/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -522.8991 - mse: 5660.4658 - val_loss: -522.7095 - val_mse: 5677.7090\n",
            "Epoch 72/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -523.2594 - mse: 5570.2402 - val_loss: -523.0109 - val_mse: 5612.5410\n",
            "Epoch 73/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -523.6043 - mse: 5484.3901 - val_loss: -523.3068 - val_mse: 5509.8887\n",
            "Epoch 74/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -523.9587 - mse: 5396.6714 - val_loss: -523.6999 - val_mse: 5431.9863\n",
            "Epoch 75/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -524.2454 - mse: 5326.4014 - val_loss: -524.0162 - val_mse: 5348.6318\n",
            "Epoch 76/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -524.5558 - mse: 5250.5425 - val_loss: -524.2971 - val_mse: 5272.9146\n",
            "Epoch 77/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -524.8810 - mse: 5170.2666 - val_loss: -524.5507 - val_mse: 5202.1484\n",
            "Epoch 78/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -525.1604 - mse: 5102.0498 - val_loss: -524.8129 - val_mse: 5137.7437\n",
            "Epoch 79/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -525.4387 - mse: 5033.9194 - val_loss: -525.0804 - val_mse: 5089.5044\n",
            "Epoch 80/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -525.6763 - mse: 4976.4263 - val_loss: -525.3331 - val_mse: 5023.9849\n",
            "Epoch 81/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -525.8613 - mse: 4927.6567 - val_loss: -525.4722 - val_mse: 5002.6006\n",
            "Epoch 82/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -526.0819 - mse: 4876.8999 - val_loss: -525.7691 - val_mse: 4911.2666\n",
            "Epoch 83/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -526.3340 - mse: 4813.7441 - val_loss: -525.9647 - val_mse: 4866.6826\n",
            "Epoch 84/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -526.4979 - mse: 4780.7378 - val_loss: -526.1308 - val_mse: 4810.2725\n",
            "Epoch 85/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -526.6779 - mse: 4733.0454 - val_loss: -526.2948 - val_mse: 4765.3662\n",
            "Epoch 86/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -526.8920 - mse: 4682.3887 - val_loss: -526.5198 - val_mse: 4716.1558\n",
            "Epoch 87/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -527.0927 - mse: 4637.1514 - val_loss: -526.5832 - val_mse: 4723.6348\n",
            "Epoch 88/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -527.2722 - mse: 4596.3716 - val_loss: -526.7717 - val_mse: 4638.8599\n",
            "Epoch 89/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -527.4404 - mse: 4556.1553 - val_loss: -527.0862 - val_mse: 4578.5562\n",
            "Epoch 90/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -527.6421 - mse: 4512.4473 - val_loss: -527.2264 - val_mse: 4536.3018\n",
            "Epoch 91/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -527.7609 - mse: 4479.5679 - val_loss: -527.3425 - val_mse: 4521.0361\n",
            "Epoch 92/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -528.0013 - mse: 4424.0186 - val_loss: -526.7310 - val_mse: 4627.8286\n",
            "Epoch 93/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -528.1069 - mse: 4401.9307 - val_loss: -527.6013 - val_mse: 4437.9673\n",
            "Epoch 94/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -528.3346 - mse: 4347.8662 - val_loss: -527.9192 - val_mse: 4384.1880\n",
            "Epoch 95/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -528.4925 - mse: 4311.0122 - val_loss: -528.0987 - val_mse: 4331.5962\n",
            "Epoch 96/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -528.6159 - mse: 4279.9512 - val_loss: -528.2802 - val_mse: 4296.2700\n",
            "Epoch 97/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -528.7717 - mse: 4243.7534 - val_loss: -528.4266 - val_mse: 4264.7378\n",
            "Epoch 98/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -528.9752 - mse: 4198.5142 - val_loss: -528.6194 - val_mse: 4227.7134\n",
            "Epoch 99/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -529.0932 - mse: 4172.0049 - val_loss: -528.7460 - val_mse: 4196.2998\n",
            "Epoch 100/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -529.2673 - mse: 4132.1602 - val_loss: -528.8291 - val_mse: 4184.8149\n",
            "Epoch 101/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -529.3803 - mse: 4104.9731 - val_loss: -529.0654 - val_mse: 4115.6597\n",
            "Epoch 102/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -529.4714 - mse: 4081.9021 - val_loss: -529.1992 - val_mse: 4087.8789\n",
            "Epoch 103/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -529.6724 - mse: 4036.7876 - val_loss: -529.2967 - val_mse: 4077.4836\n",
            "Epoch 104/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -529.8281 - mse: 4002.5625 - val_loss: -529.4362 - val_mse: 4027.6167\n",
            "Epoch 105/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -529.9626 - mse: 3970.5879 - val_loss: -529.5311 - val_mse: 4013.7444\n",
            "Epoch 106/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -530.0260 - mse: 3948.5181 - val_loss: -529.7129 - val_mse: 3961.4167\n",
            "Epoch 107/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -530.2261 - mse: 3912.5493 - val_loss: -529.7753 - val_mse: 3973.0125\n",
            "Epoch 108/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -530.3379 - mse: 3887.5901 - val_loss: -529.9463 - val_mse: 3909.5627\n",
            "Epoch 109/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -530.4311 - mse: 3863.7307 - val_loss: -530.0519 - val_mse: 3875.9500\n",
            "Epoch 110/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -530.5722 - mse: 3828.1245 - val_loss: -529.9145 - val_mse: 3883.5376\n",
            "Epoch 111/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -530.6844 - mse: 3803.2192 - val_loss: -530.3384 - val_mse: 3822.2949\n",
            "Epoch 112/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -530.7431 - mse: 3792.4341 - val_loss: -530.2331 - val_mse: 3815.8257\n",
            "Epoch 113/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -530.9425 - mse: 3747.9248 - val_loss: -530.4921 - val_mse: 3771.6611\n",
            "Epoch 114/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -531.0312 - mse: 3726.6736 - val_loss: -530.5196 - val_mse: 3794.4343\n",
            "Epoch 115/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -531.2020 - mse: 3691.0044 - val_loss: -530.4919 - val_mse: 3799.9487\n",
            "Epoch 116/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -531.2324 - mse: 3676.0947 - val_loss: -530.8006 - val_mse: 3728.4824\n",
            "Epoch 117/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -531.3922 - mse: 3651.4431 - val_loss: -530.6120 - val_mse: 3754.0403\n",
            "Epoch 118/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -531.4012 - mse: 3637.3459 - val_loss: -530.8380 - val_mse: 3730.7651\n",
            "Epoch 119/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -531.5840 - mse: 3604.1323 - val_loss: -531.1769 - val_mse: 3632.8464\n",
            "Epoch 120/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -531.7099 - mse: 3577.2505 - val_loss: -531.2796 - val_mse: 3602.4851\n",
            "Epoch 121/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -531.8046 - mse: 3557.2671 - val_loss: -531.3765 - val_mse: 3574.3828\n",
            "Epoch 122/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -531.9173 - mse: 3529.3765 - val_loss: -531.5021 - val_mse: 3552.8933\n",
            "Epoch 123/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -532.0302 - mse: 3505.9839 - val_loss: -531.5783 - val_mse: 3546.0996\n",
            "Epoch 124/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -532.0902 - mse: 3492.5525 - val_loss: -531.6896 - val_mse: 3506.8037\n",
            "Epoch 125/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -532.2303 - mse: 3463.3564 - val_loss: -531.8029 - val_mse: 3482.9236\n",
            "Epoch 126/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -532.2983 - mse: 3445.7217 - val_loss: -531.8277 - val_mse: 3481.4304\n",
            "Epoch 127/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -532.4317 - mse: 3416.8711 - val_loss: -531.8845 - val_mse: 3470.2249\n",
            "Epoch 128/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -532.4924 - mse: 3404.7639 - val_loss: -532.1127 - val_mse: 3416.0967\n",
            "Epoch 129/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -532.6134 - mse: 3381.3979 - val_loss: -532.1899 - val_mse: 3400.4863\n",
            "Epoch 130/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -532.7349 - mse: 3353.4048 - val_loss: -532.1173 - val_mse: 3416.9363\n",
            "Epoch 131/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -532.7646 - mse: 3348.6025 - val_loss: -532.4101 - val_mse: 3348.8669\n",
            "Epoch 132/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -532.9099 - mse: 3315.0505 - val_loss: -532.1412 - val_mse: 3424.5615\n",
            "Epoch 133/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -533.0200 - mse: 3289.5789 - val_loss: -532.5806 - val_mse: 3313.4368\n",
            "Epoch 134/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -533.1506 - mse: 3267.8613 - val_loss: -532.6838 - val_mse: 3282.4514\n",
            "Epoch 135/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -533.2427 - mse: 3247.4331 - val_loss: -532.7468 - val_mse: 3279.0339\n",
            "Epoch 136/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -533.3589 - mse: 3220.0825 - val_loss: -532.9156 - val_mse: 3245.9509\n",
            "Epoch 137/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -533.4787 - mse: 3200.1362 - val_loss: -533.0576 - val_mse: 3208.3218\n",
            "Epoch 138/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -533.5629 - mse: 3175.1584 - val_loss: -533.1427 - val_mse: 3192.7251\n",
            "Epoch 139/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -533.7230 - mse: 3144.1357 - val_loss: -533.2947 - val_mse: 3159.0823\n",
            "Epoch 140/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -533.8015 - mse: 3127.4751 - val_loss: -533.3870 - val_mse: 3134.8589\n",
            "Epoch 141/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -533.9496 - mse: 3096.7915 - val_loss: -533.3030 - val_mse: 3154.1665\n",
            "Epoch 142/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -534.0460 - mse: 3075.7126 - val_loss: -533.5253 - val_mse: 3115.7668\n",
            "Epoch 143/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -534.1830 - mse: 3046.0657 - val_loss: -533.7406 - val_mse: 3053.7097\n",
            "Epoch 144/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -534.3066 - mse: 3024.8616 - val_loss: -533.8949 - val_mse: 3025.7087\n",
            "Epoch 145/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -534.4408 - mse: 2995.2290 - val_loss: -533.9117 - val_mse: 3010.0144\n",
            "Epoch 146/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -534.5651 - mse: 2973.1670 - val_loss: -534.1608 - val_mse: 2975.6919\n",
            "Epoch 147/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -534.6286 - mse: 2951.5139 - val_loss: -534.3183 - val_mse: 2942.6487\n",
            "Epoch 148/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -534.8471 - mse: 2915.6133 - val_loss: -534.4339 - val_mse: 2913.4180\n",
            "Epoch 149/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -534.8985 - mse: 2900.1072 - val_loss: -534.5411 - val_mse: 2888.3738\n",
            "Epoch 150/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -535.0613 - mse: 2868.9778 - val_loss: -534.5638 - val_mse: 2884.1091\n",
            "Epoch 151/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -535.2050 - mse: 2840.6677 - val_loss: -534.8016 - val_mse: 2846.3242\n",
            "Epoch 152/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -535.3114 - mse: 2815.8347 - val_loss: -534.7042 - val_mse: 2863.8357\n",
            "Epoch 153/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -535.4094 - mse: 2797.2517 - val_loss: -534.9394 - val_mse: 2797.6831\n",
            "Epoch 154/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -535.5290 - mse: 2773.5146 - val_loss: -535.0237 - val_mse: 2799.9341\n",
            "Epoch 155/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -535.7052 - mse: 2738.6721 - val_loss: -535.3611 - val_mse: 2729.8789\n",
            "Epoch 156/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -535.8277 - mse: 2716.5332 - val_loss: -535.4620 - val_mse: 2716.7544\n",
            "Epoch 157/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -535.9012 - mse: 2699.1104 - val_loss: -535.5002 - val_mse: 2700.2300\n",
            "Epoch 158/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -536.0654 - mse: 2668.7812 - val_loss: -535.4954 - val_mse: 2704.2571\n",
            "Epoch 159/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -536.1479 - mse: 2652.2600 - val_loss: -535.7939 - val_mse: 2635.4509\n",
            "Epoch 160/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -536.2561 - mse: 2631.1067 - val_loss: -535.9649 - val_mse: 2615.8745\n",
            "Epoch 161/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -536.3665 - mse: 2607.8669 - val_loss: -536.0872 - val_mse: 2589.2903\n",
            "Epoch 162/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -536.5106 - mse: 2581.0049 - val_loss: -536.1119 - val_mse: 2579.4065\n",
            "Epoch 163/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -536.6126 - mse: 2562.5693 - val_loss: -536.1881 - val_mse: 2555.8462\n",
            "Epoch 164/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -536.7315 - mse: 2541.3328 - val_loss: -536.4087 - val_mse: 2528.1494\n",
            "Epoch 165/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -536.7705 - mse: 2532.9763 - val_loss: -536.5242 - val_mse: 2505.4087\n",
            "Epoch 166/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -536.9520 - mse: 2499.5879 - val_loss: -536.6462 - val_mse: 2483.2996\n",
            "Epoch 167/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -537.0422 - mse: 2480.7234 - val_loss: -536.7344 - val_mse: 2467.0168\n",
            "Epoch 168/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -537.1447 - mse: 2460.5146 - val_loss: -536.8491 - val_mse: 2448.9331\n",
            "Epoch 169/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -537.1721 - mse: 2453.3442 - val_loss: -536.9504 - val_mse: 2433.8647\n",
            "Epoch 170/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -537.3648 - mse: 2423.4387 - val_loss: -536.8805 - val_mse: 2428.5557\n",
            "Epoch 171/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -537.4443 - mse: 2405.0430 - val_loss: -537.1489 - val_mse: 2392.0083\n",
            "Epoch 172/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -537.5764 - mse: 2381.8047 - val_loss: -537.2881 - val_mse: 2362.9568\n",
            "Epoch 173/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -537.6496 - mse: 2364.1304 - val_loss: -537.3599 - val_mse: 2344.0466\n",
            "Epoch 174/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -537.7889 - mse: 2343.3496 - val_loss: -537.3172 - val_mse: 2346.1990\n",
            "Epoch 175/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -537.8869 - mse: 2322.5310 - val_loss: -537.4594 - val_mse: 2339.9314\n",
            "Epoch 176/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -538.0142 - mse: 2300.1960 - val_loss: -537.7123 - val_mse: 2286.1665\n",
            "Epoch 177/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -538.0843 - mse: 2286.1958 - val_loss: -537.7738 - val_mse: 2282.5559\n",
            "Epoch 178/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -538.2056 - mse: 2261.8074 - val_loss: -537.8031 - val_mse: 2281.6516\n",
            "Epoch 179/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -538.2944 - mse: 2246.5869 - val_loss: -537.9571 - val_mse: 2226.1455\n",
            "Epoch 180/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -538.4385 - mse: 2221.4043 - val_loss: -538.0827 - val_mse: 2224.3447\n",
            "Epoch 181/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -538.5327 - mse: 2202.7329 - val_loss: -538.2569 - val_mse: 2188.5481\n",
            "Epoch 182/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -538.6358 - mse: 2181.7900 - val_loss: -538.2806 - val_mse: 2192.1548\n",
            "Epoch 183/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -538.7234 - mse: 2163.0315 - val_loss: -538.4619 - val_mse: 2153.0754\n",
            "Epoch 184/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -538.8821 - mse: 2141.2346 - val_loss: -538.5841 - val_mse: 2130.6111\n",
            "Epoch 185/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -538.9811 - mse: 2118.8027 - val_loss: -538.6808 - val_mse: 2120.2754\n",
            "Epoch 186/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -539.0833 - mse: 2099.4136 - val_loss: -538.7379 - val_mse: 2088.4778\n",
            "Epoch 187/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -539.0790 - mse: 2095.0178 - val_loss: -538.7592 - val_mse: 2113.0967\n",
            "Epoch 188/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -539.2528 - mse: 2065.4014 - val_loss: -539.0080 - val_mse: 2046.3274\n",
            "Epoch 189/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -539.4075 - mse: 2036.7168 - val_loss: -539.0987 - val_mse: 2039.5142\n",
            "Epoch 190/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -539.5238 - mse: 2013.2474 - val_loss: -539.2122 - val_mse: 2021.0300\n",
            "Epoch 191/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -539.6271 - mse: 1992.6344 - val_loss: -539.3434 - val_mse: 1990.4468\n",
            "Epoch 192/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -539.7802 - mse: 1966.7206 - val_loss: -539.4392 - val_mse: 1969.4292\n",
            "Epoch 193/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -539.8539 - mse: 1951.6240 - val_loss: -539.5446 - val_mse: 1944.9526\n",
            "Epoch 194/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -540.0058 - mse: 1924.1058 - val_loss: -539.6002 - val_mse: 1926.1484\n",
            "Epoch 195/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -540.1087 - mse: 1904.3580 - val_loss: -539.6124 - val_mse: 1918.1052\n",
            "Epoch 196/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -540.2256 - mse: 1881.9261 - val_loss: -539.8602 - val_mse: 1900.9012\n",
            "Epoch 197/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -540.2699 - mse: 1870.8234 - val_loss: -539.9764 - val_mse: 1871.2382\n",
            "Epoch 198/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -540.4499 - mse: 1840.2416 - val_loss: -540.0235 - val_mse: 1872.8400\n",
            "Epoch 199/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -540.5356 - mse: 1825.3206 - val_loss: -540.1021 - val_mse: 1837.8932\n",
            "Epoch 200/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -540.6162 - mse: 1810.7690 - val_loss: -540.2121 - val_mse: 1833.1826\n",
            "Epoch 201/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -540.7399 - mse: 1784.8812 - val_loss: -540.3249 - val_mse: 1798.1572\n",
            "Epoch 202/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -540.8422 - mse: 1767.7046 - val_loss: -540.4447 - val_mse: 1783.3944\n",
            "Epoch 203/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -540.9908 - mse: 1740.5558 - val_loss: -540.5125 - val_mse: 1773.4182\n",
            "Epoch 204/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -541.0664 - mse: 1725.7065 - val_loss: -540.6627 - val_mse: 1742.7230\n",
            "Epoch 205/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -541.1983 - mse: 1704.5380 - val_loss: -540.7184 - val_mse: 1732.6536\n",
            "Epoch 206/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -541.2566 - mse: 1687.2664 - val_loss: -540.6615 - val_mse: 1738.6876\n",
            "Epoch 207/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -541.4197 - mse: 1665.3632 - val_loss: -540.9443 - val_mse: 1692.2048\n",
            "Epoch 208/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -541.5071 - mse: 1647.6935 - val_loss: -541.0634 - val_mse: 1670.4751\n",
            "Epoch 209/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -541.5977 - mse: 1629.7216 - val_loss: -540.9241 - val_mse: 1690.5573\n",
            "Epoch 210/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -541.7275 - mse: 1610.5958 - val_loss: -541.2158 - val_mse: 1641.3156\n",
            "Epoch 211/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -541.8139 - mse: 1593.7893 - val_loss: -541.3433 - val_mse: 1622.3928\n",
            "Epoch 212/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -541.9351 - mse: 1575.2047 - val_loss: -541.4818 - val_mse: 1595.5527\n",
            "Epoch 213/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -542.0394 - mse: 1555.0032 - val_loss: -541.5661 - val_mse: 1581.0382\n",
            "Epoch 214/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -542.1668 - mse: 1535.8318 - val_loss: -541.6949 - val_mse: 1556.2987\n",
            "Epoch 215/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -542.2149 - mse: 1523.9163 - val_loss: -541.5999 - val_mse: 1558.5129\n",
            "Epoch 216/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -542.3455 - mse: 1503.8588 - val_loss: -541.7660 - val_mse: 1543.3878\n",
            "Epoch 217/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -542.4370 - mse: 1486.9116 - val_loss: -542.0002 - val_mse: 1504.2480\n",
            "Epoch 218/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -542.5370 - mse: 1468.8185 - val_loss: -541.7738 - val_mse: 1527.9354\n",
            "Epoch 219/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -542.6224 - mse: 1454.0824 - val_loss: -542.1612 - val_mse: 1475.9771\n",
            "Epoch 220/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -542.7424 - mse: 1435.7787 - val_loss: -542.2861 - val_mse: 1455.6105\n",
            "Epoch 221/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -542.8283 - mse: 1417.6779 - val_loss: -542.3950 - val_mse: 1432.3134\n",
            "Epoch 222/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -542.9250 - mse: 1400.7374 - val_loss: -542.4904 - val_mse: 1416.3816\n",
            "Epoch 223/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -542.9813 - mse: 1388.2853 - val_loss: -542.5888 - val_mse: 1399.9847\n",
            "Epoch 224/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.0846 - mse: 1369.2612 - val_loss: -542.6564 - val_mse: 1384.2343\n",
            "Epoch 225/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.1886 - mse: 1352.3788 - val_loss: -542.7391 - val_mse: 1374.9849\n",
            "Epoch 226/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.2763 - mse: 1338.3293 - val_loss: -542.8464 - val_mse: 1353.8398\n",
            "Epoch 227/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.3441 - mse: 1324.7010 - val_loss: -542.9279 - val_mse: 1341.0588\n",
            "Epoch 228/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.4067 - mse: 1312.8779 - val_loss: -542.9590 - val_mse: 1335.6808\n",
            "Epoch 229/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.5114 - mse: 1295.8954 - val_loss: -543.0481 - val_mse: 1321.9323\n",
            "Epoch 230/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.5647 - mse: 1287.0428 - val_loss: -542.7523 - val_mse: 1349.9851\n",
            "Epoch 231/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.6494 - mse: 1272.7139 - val_loss: -543.2479 - val_mse: 1287.5352\n",
            "Epoch 232/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.7165 - mse: 1259.4993 - val_loss: -543.3035 - val_mse: 1276.8640\n",
            "Epoch 233/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.7734 - mse: 1249.0310 - val_loss: -543.3889 - val_mse: 1258.5270\n",
            "Epoch 234/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.8423 - mse: 1235.1049 - val_loss: -543.4406 - val_mse: 1254.7166\n",
            "Epoch 235/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.9195 - mse: 1221.7653 - val_loss: -543.4417 - val_mse: 1246.7694\n",
            "Epoch 236/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -543.9778 - mse: 1211.6298 - val_loss: -543.3296 - val_mse: 1261.2365\n",
            "Epoch 237/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.0440 - mse: 1200.0688 - val_loss: -543.5910 - val_mse: 1220.3864\n",
            "Epoch 238/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -544.0920 - mse: 1189.7434 - val_loss: -543.6687 - val_mse: 1207.0049\n",
            "Epoch 239/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -544.1389 - mse: 1180.4868 - val_loss: -543.8071 - val_mse: 1185.2942\n",
            "Epoch 240/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.2219 - mse: 1168.6355 - val_loss: -543.8638 - val_mse: 1181.7050\n",
            "Epoch 241/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.2657 - mse: 1161.4030 - val_loss: -543.9171 - val_mse: 1172.9766\n",
            "Epoch 242/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -544.3171 - mse: 1151.6039 - val_loss: -543.9727 - val_mse: 1162.0704\n",
            "Epoch 243/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.3666 - mse: 1143.4365 - val_loss: -544.0239 - val_mse: 1153.4196\n",
            "Epoch 244/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.4266 - mse: 1134.4939 - val_loss: -543.9586 - val_mse: 1159.2618\n",
            "Epoch 245/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.4564 - mse: 1128.0452 - val_loss: -544.0964 - val_mse: 1142.1299\n",
            "Epoch 246/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.4903 - mse: 1120.9208 - val_loss: -544.1725 - val_mse: 1132.3357\n",
            "Epoch 247/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.5455 - mse: 1113.2566 - val_loss: -544.2154 - val_mse: 1124.7743\n",
            "Epoch 248/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.5766 - mse: 1106.0330 - val_loss: -544.1518 - val_mse: 1130.9277\n",
            "Epoch 249/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.6266 - mse: 1100.4240 - val_loss: -544.2806 - val_mse: 1116.5999\n",
            "Epoch 250/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -544.6571 - mse: 1094.5161 - val_loss: -544.3282 - val_mse: 1109.7136\n",
            "Epoch 251/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -544.7061 - mse: 1088.1101 - val_loss: -544.3623 - val_mse: 1101.7371\n",
            "Epoch 252/1000\n",
            "40000/40000 [==============================] - 1s 23us/step - loss: -544.7491 - mse: 1079.7965 - val_loss: -544.4157 - val_mse: 1097.9655\n",
            "Epoch 253/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -544.7802 - mse: 1075.2257 - val_loss: -544.4286 - val_mse: 1095.6958\n",
            "Epoch 254/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -544.8104 - mse: 1070.9708 - val_loss: -544.3103 - val_mse: 1101.0986\n",
            "Epoch 255/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -544.8377 - mse: 1065.4576 - val_loss: -544.5120 - val_mse: 1079.9905\n",
            "Epoch 256/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -544.8616 - mse: 1060.6523 - val_loss: -544.4222 - val_mse: 1086.1644\n",
            "Epoch 257/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -544.8975 - mse: 1053.9336 - val_loss: -544.5621 - val_mse: 1072.9875\n",
            "Epoch 258/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -544.9186 - mse: 1050.7533 - val_loss: -544.6063 - val_mse: 1066.0773\n",
            "Epoch 259/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -544.9729 - mse: 1042.0634 - val_loss: -544.6047 - val_mse: 1065.4551\n",
            "Epoch 260/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -544.9725 - mse: 1039.7627 - val_loss: -544.5094 - val_mse: 1070.3258\n",
            "Epoch 261/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -545.0373 - mse: 1032.8623 - val_loss: -544.6911 - val_mse: 1053.2217\n",
            "Epoch 262/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -545.0587 - mse: 1028.4257 - val_loss: -544.7153 - val_mse: 1049.1101\n",
            "Epoch 263/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.0889 - mse: 1023.8387 - val_loss: -544.6749 - val_mse: 1052.5743\n",
            "Epoch 264/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.1168 - mse: 1018.7108 - val_loss: -544.7466 - val_mse: 1042.0132\n",
            "Epoch 265/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -545.1225 - mse: 1015.8176 - val_loss: -544.7777 - val_mse: 1035.9490\n",
            "Epoch 266/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.1646 - mse: 1009.5693 - val_loss: -544.7915 - val_mse: 1032.1714\n",
            "Epoch 267/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.2039 - mse: 1005.4547 - val_loss: -544.7745 - val_mse: 1030.6201\n",
            "Epoch 268/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.2009 - mse: 1002.9251 - val_loss: -544.8262 - val_mse: 1024.0636\n",
            "Epoch 269/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.2518 - mse: 994.7840 - val_loss: -544.8419 - val_mse: 1020.4224\n",
            "Epoch 270/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.2600 - mse: 992.3707 - val_loss: -544.8600 - val_mse: 1018.0234\n",
            "Epoch 271/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.2987 - mse: 985.8052 - val_loss: -544.9404 - val_mse: 1006.2868\n",
            "Epoch 272/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.2896 - mse: 982.2062 - val_loss: -544.9697 - val_mse: 1002.6071\n",
            "Epoch 273/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.2984 - mse: 978.5937 - val_loss: -544.9904 - val_mse: 996.3351\n",
            "Epoch 274/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.3683 - mse: 970.9076 - val_loss: -545.0189 - val_mse: 994.4161\n",
            "Epoch 275/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.3951 - mse: 966.2073 - val_loss: -544.9344 - val_mse: 998.0009\n",
            "Epoch 276/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.4326 - mse: 959.6467 - val_loss: -545.0412 - val_mse: 985.1140\n",
            "Epoch 277/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.4470 - mse: 955.4027 - val_loss: -544.8943 - val_mse: 997.9575\n",
            "Epoch 278/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.4636 - mse: 952.3426 - val_loss: -545.1151 - val_mse: 974.6589\n",
            "Epoch 279/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.5026 - mse: 947.1417 - val_loss: -545.1215 - val_mse: 972.7224\n",
            "Epoch 280/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.5228 - mse: 945.0284 - val_loss: -545.1551 - val_mse: 966.3995\n",
            "Epoch 281/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.5198 - mse: 941.2910 - val_loss: -545.1659 - val_mse: 968.0074\n",
            "Epoch 282/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.5439 - mse: 938.2301 - val_loss: -545.1581 - val_mse: 966.9719\n",
            "Epoch 283/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.5710 - mse: 936.5606 - val_loss: -545.1962 - val_mse: 962.9754\n",
            "Epoch 284/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.5977 - mse: 932.7684 - val_loss: -545.1121 - val_mse: 967.2323\n",
            "Epoch 285/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.5865 - mse: 932.5180 - val_loss: -545.0990 - val_mse: 967.0235\n",
            "Epoch 286/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.6344 - mse: 927.4461 - val_loss: -545.2413 - val_mse: 955.9074\n",
            "Epoch 287/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.6401 - mse: 925.7885 - val_loss: -545.2551 - val_mse: 953.2701\n",
            "Epoch 288/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.6642 - mse: 922.9573 - val_loss: -545.2585 - val_mse: 954.8880\n",
            "Epoch 289/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.6766 - mse: 920.8151 - val_loss: -545.2994 - val_mse: 946.7183\n",
            "Epoch 290/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.6832 - mse: 919.8122 - val_loss: -545.2797 - val_mse: 948.7975\n",
            "Epoch 291/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.7111 - mse: 914.8430 - val_loss: -545.3341 - val_mse: 942.3523\n",
            "Epoch 292/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.7162 - mse: 913.8940 - val_loss: -545.3115 - val_mse: 944.3095\n",
            "Epoch 293/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.7402 - mse: 910.4695 - val_loss: -545.3613 - val_mse: 938.4051\n",
            "Epoch 294/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -545.7287 - mse: 911.4580 - val_loss: -545.3731 - val_mse: 936.8826\n",
            "Epoch 295/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.7631 - mse: 908.3162 - val_loss: -545.3759 - val_mse: 935.3250\n",
            "Epoch 296/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.7447 - mse: 905.7611 - val_loss: -545.4023 - val_mse: 933.5124\n",
            "Epoch 297/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.7912 - mse: 903.7001 - val_loss: -545.4099 - val_mse: 930.9009\n",
            "Epoch 298/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.7975 - mse: 899.9172 - val_loss: -545.3790 - val_mse: 933.0736\n",
            "Epoch 299/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.8187 - mse: 898.4544 - val_loss: -545.3912 - val_mse: 929.8150\n",
            "Epoch 300/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.8071 - mse: 898.4651 - val_loss: -545.4243 - val_mse: 927.4608\n",
            "Epoch 301/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.8511 - mse: 893.2162 - val_loss: -545.4632 - val_mse: 922.4821\n",
            "Epoch 302/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.8542 - mse: 891.9322 - val_loss: -545.4757 - val_mse: 922.9284\n",
            "Epoch 303/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.8656 - mse: 890.3160 - val_loss: -545.4906 - val_mse: 919.4147\n",
            "Epoch 304/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.8872 - mse: 887.8458 - val_loss: -545.5022 - val_mse: 917.6818\n",
            "Epoch 305/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.8911 - mse: 886.2339 - val_loss: -545.5118 - val_mse: 917.3980\n",
            "Epoch 306/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.8806 - mse: 885.5313 - val_loss: -545.3823 - val_mse: 925.9368\n",
            "Epoch 307/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.9110 - mse: 882.8859 - val_loss: -545.5168 - val_mse: 913.4343\n",
            "Epoch 308/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -545.9304 - mse: 880.7850 - val_loss: -545.4804 - val_mse: 915.0017\n",
            "Epoch 309/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.9337 - mse: 880.3643 - val_loss: -545.5582 - val_mse: 909.0772\n",
            "Epoch 310/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.9485 - mse: 877.5664 - val_loss: -545.5243 - val_mse: 910.6309\n",
            "Epoch 311/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.9578 - mse: 876.2596 - val_loss: -545.5732 - val_mse: 908.0385\n",
            "Epoch 312/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.9633 - mse: 875.3559 - val_loss: -545.4652 - val_mse: 914.6311\n",
            "Epoch 313/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -545.9763 - mse: 874.4490 - val_loss: -545.5719 - val_mse: 904.8625\n",
            "Epoch 314/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -545.9851 - mse: 872.2467 - val_loss: -545.5900 - val_mse: 903.7122\n",
            "Epoch 315/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.0029 - mse: 870.8414 - val_loss: -545.6153 - val_mse: 902.3016\n",
            "Epoch 316/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.0136 - mse: 868.1537 - val_loss: -545.5901 - val_mse: 902.2128\n",
            "Epoch 317/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.0188 - mse: 867.1706 - val_loss: -545.6235 - val_mse: 900.5105\n",
            "Epoch 318/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.0113 - mse: 867.6117 - val_loss: -545.6353 - val_mse: 901.3408\n",
            "Epoch 319/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.0390 - mse: 865.4477 - val_loss: -545.5511 - val_mse: 906.7705\n",
            "Epoch 320/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.0435 - mse: 864.3210 - val_loss: -545.5302 - val_mse: 904.9188\n",
            "Epoch 321/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.0457 - mse: 862.5815 - val_loss: -545.6610 - val_mse: 897.1084\n",
            "Epoch 322/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.0635 - mse: 861.5281 - val_loss: -545.6629 - val_mse: 892.9712\n",
            "Epoch 323/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.0550 - mse: 860.5444 - val_loss: -545.6760 - val_mse: 893.7232\n",
            "Epoch 324/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.0712 - mse: 859.5821 - val_loss: -545.6498 - val_mse: 895.0171\n",
            "Epoch 325/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.0844 - mse: 858.0182 - val_loss: -545.4885 - val_mse: 902.6757\n",
            "Epoch 326/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.0927 - mse: 857.2053 - val_loss: -545.7081 - val_mse: 890.0220\n",
            "Epoch 327/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.0757 - mse: 857.0759 - val_loss: -545.7134 - val_mse: 889.0395\n",
            "Epoch 328/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.0875 - mse: 855.6340 - val_loss: -545.6281 - val_mse: 893.5859\n",
            "Epoch 329/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.1142 - mse: 854.6797 - val_loss: -545.5171 - val_mse: 900.3326\n",
            "Epoch 330/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.1152 - mse: 853.7744 - val_loss: -545.6274 - val_mse: 900.0937\n",
            "Epoch 331/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.1350 - mse: 852.0018 - val_loss: -545.5917 - val_mse: 892.8397\n",
            "Epoch 332/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.1437 - mse: 850.3972 - val_loss: -545.7320 - val_mse: 884.2612\n",
            "Epoch 333/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.1530 - mse: 849.4250 - val_loss: -545.7598 - val_mse: 882.3897\n",
            "Epoch 334/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.1517 - mse: 849.0774 - val_loss: -545.7568 - val_mse: 883.1995\n",
            "Epoch 335/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.1701 - mse: 847.3869 - val_loss: -545.7669 - val_mse: 884.0714\n",
            "Epoch 336/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.1641 - mse: 847.0466 - val_loss: -545.7763 - val_mse: 880.3846\n",
            "Epoch 337/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.1789 - mse: 845.8400 - val_loss: -545.6930 - val_mse: 885.6593\n",
            "Epoch 338/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.1587 - mse: 846.6122 - val_loss: -545.7580 - val_mse: 880.3374\n",
            "Epoch 339/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.1829 - mse: 844.7990 - val_loss: -545.6490 - val_mse: 887.4938\n",
            "Epoch 340/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.1854 - mse: 844.2981 - val_loss: -545.6858 - val_mse: 888.9813\n",
            "Epoch 341/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2073 - mse: 841.8531 - val_loss: -545.8071 - val_mse: 879.2379\n",
            "Epoch 342/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.2015 - mse: 842.2846 - val_loss: -545.8022 - val_mse: 877.0455\n",
            "Epoch 343/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2096 - mse: 840.3147 - val_loss: -545.8134 - val_mse: 877.9862\n",
            "Epoch 344/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2045 - mse: 841.4642 - val_loss: -545.7193 - val_mse: 879.0131\n",
            "Epoch 345/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2186 - mse: 839.1454 - val_loss: -545.8343 - val_mse: 873.8431\n",
            "Epoch 346/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -546.2423 - mse: 837.6987 - val_loss: -545.8376 - val_mse: 875.2429\n",
            "Epoch 347/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.2306 - mse: 838.5916 - val_loss: -545.8420 - val_mse: 871.6651\n",
            "Epoch 348/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2412 - mse: 836.3376 - val_loss: -545.8450 - val_mse: 873.4304\n",
            "Epoch 349/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2520 - mse: 836.6004 - val_loss: -545.7659 - val_mse: 875.9996\n",
            "Epoch 350/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2450 - mse: 835.0601 - val_loss: -545.8142 - val_mse: 876.8027\n",
            "Epoch 351/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2599 - mse: 835.6501 - val_loss: -545.7824 - val_mse: 875.8556\n",
            "Epoch 352/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2700 - mse: 833.2411 - val_loss: -545.8692 - val_mse: 868.2958\n",
            "Epoch 353/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2849 - mse: 832.3689 - val_loss: -545.8781 - val_mse: 868.7723\n",
            "Epoch 354/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2795 - mse: 831.6530 - val_loss: -545.8705 - val_mse: 868.4076\n",
            "Epoch 355/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2737 - mse: 832.4733 - val_loss: -545.8739 - val_mse: 868.4701\n",
            "Epoch 356/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2922 - mse: 830.3070 - val_loss: -545.8716 - val_mse: 868.7568\n",
            "Epoch 357/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2881 - mse: 829.7997 - val_loss: -545.8898 - val_mse: 867.1640\n",
            "Epoch 358/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3115 - mse: 828.8274 - val_loss: -545.8784 - val_mse: 866.3514\n",
            "Epoch 359/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.2976 - mse: 828.3307 - val_loss: -545.9055 - val_mse: 865.9728\n",
            "Epoch 360/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3153 - mse: 827.6199 - val_loss: -545.9147 - val_mse: 865.0048\n",
            "Epoch 361/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.3269 - mse: 827.3563 - val_loss: -545.9171 - val_mse: 864.1503\n",
            "Epoch 362/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3311 - mse: 825.1884 - val_loss: -545.9103 - val_mse: 864.9333\n",
            "Epoch 363/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3306 - mse: 826.1558 - val_loss: -545.9268 - val_mse: 860.8156\n",
            "Epoch 364/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3433 - mse: 824.2541 - val_loss: -545.9016 - val_mse: 865.0738\n",
            "Epoch 365/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3288 - mse: 824.5432 - val_loss: -545.7910 - val_mse: 869.9722\n",
            "Epoch 366/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.3441 - mse: 824.0464 - val_loss: -545.9116 - val_mse: 864.8917\n",
            "Epoch 367/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3458 - mse: 823.9200 - val_loss: -545.9333 - val_mse: 860.7577\n",
            "Epoch 368/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3498 - mse: 822.8325 - val_loss: -545.8121 - val_mse: 867.4177\n",
            "Epoch 369/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3495 - mse: 822.1694 - val_loss: -545.9556 - val_mse: 860.6292\n",
            "Epoch 370/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3563 - mse: 820.7000 - val_loss: -545.9470 - val_mse: 861.5449\n",
            "Epoch 371/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3792 - mse: 820.3555 - val_loss: -545.9601 - val_mse: 858.6736\n",
            "Epoch 372/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3819 - mse: 819.4269 - val_loss: -545.9680 - val_mse: 858.2123\n",
            "Epoch 373/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3668 - mse: 820.3066 - val_loss: -545.9573 - val_mse: 857.6702\n",
            "Epoch 374/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3927 - mse: 818.4039 - val_loss: -545.8957 - val_mse: 859.0834\n",
            "Epoch 375/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.3896 - mse: 818.6091 - val_loss: -545.9809 - val_mse: 854.8764\n",
            "Epoch 376/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3725 - mse: 819.4357 - val_loss: -545.9838 - val_mse: 855.9889\n",
            "Epoch 377/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.3988 - mse: 816.6801 - val_loss: -545.9273 - val_mse: 858.8277\n",
            "Epoch 378/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.3973 - mse: 816.8832 - val_loss: -545.9936 - val_mse: 852.8008\n",
            "Epoch 379/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4143 - mse: 814.6283 - val_loss: -545.9818 - val_mse: 855.4346\n",
            "Epoch 380/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4016 - mse: 816.1871 - val_loss: -545.9972 - val_mse: 853.4235\n",
            "Epoch 381/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4216 - mse: 814.2846 - val_loss: -546.0021 - val_mse: 854.3682\n",
            "Epoch 382/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.4180 - mse: 814.3124 - val_loss: -545.9667 - val_mse: 857.0315\n",
            "Epoch 383/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4216 - mse: 814.0983 - val_loss: -546.0095 - val_mse: 852.1229\n",
            "Epoch 384/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.4315 - mse: 813.1371 - val_loss: -545.9916 - val_mse: 850.8647\n",
            "Epoch 385/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4388 - mse: 811.6285 - val_loss: -546.0060 - val_mse: 852.0509\n",
            "Epoch 386/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4492 - mse: 811.0704 - val_loss: -545.9932 - val_mse: 853.0430\n",
            "Epoch 387/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4469 - mse: 811.0635 - val_loss: -546.0243 - val_mse: 847.9615\n",
            "Epoch 388/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4334 - mse: 810.4791 - val_loss: -546.0212 - val_mse: 850.5247\n",
            "Epoch 389/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4613 - mse: 808.9733 - val_loss: -546.0314 - val_mse: 847.7790\n",
            "Epoch 390/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.4574 - mse: 809.7853 - val_loss: -545.9426 - val_mse: 852.6942\n",
            "Epoch 391/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4472 - mse: 809.3502 - val_loss: -546.0448 - val_mse: 847.9810\n",
            "Epoch 392/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4744 - mse: 807.7753 - val_loss: -546.0274 - val_mse: 850.9922\n",
            "Epoch 393/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4870 - mse: 806.7590 - val_loss: -546.0502 - val_mse: 846.9249\n",
            "Epoch 394/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4744 - mse: 807.1913 - val_loss: -546.0555 - val_mse: 845.9976\n",
            "Epoch 395/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4802 - mse: 805.6704 - val_loss: -546.0576 - val_mse: 847.1271\n",
            "Epoch 396/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4957 - mse: 804.7229 - val_loss: -546.0626 - val_mse: 844.8390\n",
            "Epoch 397/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4908 - mse: 804.6436 - val_loss: -546.0685 - val_mse: 844.1323\n",
            "Epoch 398/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5010 - mse: 804.0812 - val_loss: -546.0496 - val_mse: 845.7980\n",
            "Epoch 399/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5039 - mse: 803.4551 - val_loss: -546.0222 - val_mse: 845.3794\n",
            "Epoch 400/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.4989 - mse: 802.3549 - val_loss: -546.0660 - val_mse: 843.9564\n",
            "Epoch 401/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.5129 - mse: 802.6453 - val_loss: -546.0766 - val_mse: 844.6588\n",
            "Epoch 402/1000\n",
            "40000/40000 [==============================] - 1s 22us/step - loss: -546.5123 - mse: 802.0199 - val_loss: -546.0640 - val_mse: 841.7343\n",
            "Epoch 403/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5208 - mse: 801.5875 - val_loss: -546.0855 - val_mse: 842.8879\n",
            "Epoch 404/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5203 - mse: 800.7954 - val_loss: -546.0678 - val_mse: 842.6551\n",
            "Epoch 405/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5198 - mse: 799.9881 - val_loss: -546.0762 - val_mse: 843.1621\n",
            "Epoch 406/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5290 - mse: 799.5875 - val_loss: -546.0833 - val_mse: 841.3871\n",
            "Epoch 407/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.5355 - mse: 798.9968 - val_loss: -546.0832 - val_mse: 840.3784\n",
            "Epoch 408/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5463 - mse: 797.5078 - val_loss: -546.1018 - val_mse: 840.7375\n",
            "Epoch 409/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5318 - mse: 799.2307 - val_loss: -546.0950 - val_mse: 839.7697\n",
            "Epoch 410/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5405 - mse: 797.2141 - val_loss: -546.0477 - val_mse: 839.2641\n",
            "Epoch 411/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5529 - mse: 796.5192 - val_loss: -546.0061 - val_mse: 848.4056\n",
            "Epoch 412/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5602 - mse: 796.2066 - val_loss: -546.1129 - val_mse: 838.6243\n",
            "Epoch 413/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5520 - mse: 796.0255 - val_loss: -546.1169 - val_mse: 838.8624\n",
            "Epoch 414/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5677 - mse: 795.1017 - val_loss: -546.0772 - val_mse: 840.2845\n",
            "Epoch 415/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5649 - mse: 794.5377 - val_loss: -546.1133 - val_mse: 837.2175\n",
            "Epoch 416/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5724 - mse: 794.2175 - val_loss: -546.1258 - val_mse: 836.3885\n",
            "Epoch 417/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5695 - mse: 795.1254 - val_loss: -546.1267 - val_mse: 835.5109\n",
            "Epoch 418/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5633 - mse: 793.0040 - val_loss: -545.9484 - val_mse: 853.0472\n",
            "Epoch 419/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5784 - mse: 793.3380 - val_loss: -546.1302 - val_mse: 835.5209\n",
            "Epoch 420/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5678 - mse: 793.0702 - val_loss: -546.0810 - val_mse: 837.9086\n",
            "Epoch 421/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5980 - mse: 791.9585 - val_loss: -546.1368 - val_mse: 835.8970\n",
            "Epoch 422/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5812 - mse: 792.7189 - val_loss: -546.0745 - val_mse: 842.9214\n",
            "Epoch 423/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.5882 - mse: 791.5446 - val_loss: -546.1324 - val_mse: 834.7858\n",
            "Epoch 424/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5923 - mse: 791.8434 - val_loss: -546.1480 - val_mse: 833.7208\n",
            "Epoch 425/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5997 - mse: 789.7306 - val_loss: -546.1422 - val_mse: 833.9941\n",
            "Epoch 426/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.5821 - mse: 792.2350 - val_loss: -546.1500 - val_mse: 833.3723\n",
            "Epoch 427/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6086 - mse: 790.0229 - val_loss: -546.1534 - val_mse: 832.1708\n",
            "Epoch 428/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6212 - mse: 788.7141 - val_loss: -546.0850 - val_mse: 835.3679\n",
            "Epoch 429/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.6092 - mse: 789.0159 - val_loss: -546.0930 - val_mse: 834.6838\n",
            "Epoch 430/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6127 - mse: 789.3268 - val_loss: -546.1449 - val_mse: 833.3361\n",
            "Epoch 431/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.6124 - mse: 788.7800 - val_loss: -546.1634 - val_mse: 833.7113\n",
            "Epoch 432/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6284 - mse: 787.3895 - val_loss: -546.1476 - val_mse: 832.6108\n",
            "Epoch 433/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.6170 - mse: 788.0576 - val_loss: -546.1684 - val_mse: 831.5273\n",
            "Epoch 434/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6217 - mse: 787.4706 - val_loss: -546.1700 - val_mse: 832.0262\n",
            "Epoch 435/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6358 - mse: 786.2922 - val_loss: -546.1066 - val_mse: 834.2552\n",
            "Epoch 436/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6323 - mse: 785.8717 - val_loss: -546.1701 - val_mse: 831.7993\n",
            "Epoch 437/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.6266 - mse: 787.0056 - val_loss: -546.1622 - val_mse: 829.1734\n",
            "Epoch 438/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6443 - mse: 785.2712 - val_loss: -546.0723 - val_mse: 837.3717\n",
            "Epoch 439/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6244 - mse: 786.1586 - val_loss: -546.1660 - val_mse: 829.9099\n",
            "Epoch 440/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6544 - mse: 784.7720 - val_loss: -546.1816 - val_mse: 828.1196\n",
            "Epoch 441/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6526 - mse: 784.3176 - val_loss: -546.1698 - val_mse: 831.1992\n",
            "Epoch 442/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6443 - mse: 783.9310 - val_loss: -546.1546 - val_mse: 830.4177\n",
            "Epoch 443/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6440 - mse: 784.1223 - val_loss: -546.1520 - val_mse: 831.9193\n",
            "Epoch 444/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6611 - mse: 783.5828 - val_loss: -546.1696 - val_mse: 827.7295\n",
            "Epoch 445/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6647 - mse: 782.9013 - val_loss: -546.1681 - val_mse: 830.2689\n",
            "Epoch 446/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6569 - mse: 782.4528 - val_loss: -546.1566 - val_mse: 829.8145\n",
            "Epoch 447/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6651 - mse: 782.9678 - val_loss: -546.1927 - val_mse: 829.4062\n",
            "Epoch 448/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6595 - mse: 782.0471 - val_loss: -546.1782 - val_mse: 829.4141\n",
            "Epoch 449/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6520 - mse: 782.6868 - val_loss: -546.1924 - val_mse: 828.0662\n",
            "Epoch 450/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6787 - mse: 781.1910 - val_loss: -546.1792 - val_mse: 828.3195\n",
            "Epoch 451/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6694 - mse: 781.3830 - val_loss: -546.1805 - val_mse: 827.3679\n",
            "Epoch 452/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6815 - mse: 780.4814 - val_loss: -546.1440 - val_mse: 829.6801\n",
            "Epoch 453/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.6779 - mse: 780.7997 - val_loss: -546.2049 - val_mse: 825.8316\n",
            "Epoch 454/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6869 - mse: 779.7214 - val_loss: -546.2024 - val_mse: 831.3636\n",
            "Epoch 455/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6802 - mse: 780.7123 - val_loss: -546.2094 - val_mse: 826.6974\n",
            "Epoch 456/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6794 - mse: 779.7771 - val_loss: -546.1843 - val_mse: 827.6965\n",
            "Epoch 457/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6822 - mse: 779.6472 - val_loss: -546.1709 - val_mse: 827.8547\n",
            "Epoch 458/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6835 - mse: 779.7305 - val_loss: -546.1879 - val_mse: 827.4883\n",
            "Epoch 459/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6810 - mse: 779.3229 - val_loss: -546.2071 - val_mse: 826.2394\n",
            "Epoch 460/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7073 - mse: 778.3412 - val_loss: -546.2186 - val_mse: 826.2642\n",
            "Epoch 461/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.6886 - mse: 779.4119 - val_loss: -546.1130 - val_mse: 834.2531\n",
            "Epoch 462/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.6993 - mse: 778.4608 - val_loss: -546.2179 - val_mse: 826.6204\n",
            "Epoch 463/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.7084 - mse: 777.0027 - val_loss: -546.0070 - val_mse: 836.0343\n",
            "Epoch 464/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7051 - mse: 777.4840 - val_loss: -546.2202 - val_mse: 824.9697\n",
            "Epoch 465/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7134 - mse: 776.6043 - val_loss: -546.2157 - val_mse: 825.6783\n",
            "Epoch 466/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7010 - mse: 777.5123 - val_loss: -545.9480 - val_mse: 848.0328\n",
            "Epoch 467/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.6929 - mse: 777.2183 - val_loss: -546.2060 - val_mse: 826.0106\n",
            "Epoch 468/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7148 - mse: 776.1250 - val_loss: -546.2249 - val_mse: 825.3528\n",
            "Epoch 469/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7238 - mse: 775.4341 - val_loss: -546.2223 - val_mse: 824.5119\n",
            "Epoch 470/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7148 - mse: 776.8329 - val_loss: -546.2184 - val_mse: 824.7186\n",
            "Epoch 471/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.7156 - mse: 775.0248 - val_loss: -546.2281 - val_mse: 822.2383\n",
            "Epoch 472/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.7310 - mse: 774.8546 - val_loss: -546.0923 - val_mse: 829.0809\n",
            "Epoch 473/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7235 - mse: 775.0344 - val_loss: -546.2286 - val_mse: 825.6701\n",
            "Epoch 474/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7341 - mse: 775.0901 - val_loss: -546.2244 - val_mse: 825.3992\n",
            "Epoch 475/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7383 - mse: 773.4969 - val_loss: -546.2396 - val_mse: 824.1382\n",
            "Epoch 476/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7196 - mse: 775.4284 - val_loss: -546.2377 - val_mse: 823.3070\n",
            "Epoch 477/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7188 - mse: 774.8788 - val_loss: -546.1921 - val_mse: 825.6056\n",
            "Epoch 478/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7344 - mse: 773.4101 - val_loss: -546.2005 - val_mse: 827.7994\n",
            "Epoch 479/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7451 - mse: 773.3036 - val_loss: -546.2153 - val_mse: 823.7291\n",
            "Epoch 480/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7472 - mse: 772.7825 - val_loss: -546.1919 - val_mse: 824.1731\n",
            "Epoch 481/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7263 - mse: 774.0053 - val_loss: -546.2171 - val_mse: 823.0586\n",
            "Epoch 482/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7348 - mse: 773.6102 - val_loss: -546.2426 - val_mse: 823.5617\n",
            "Epoch 483/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7460 - mse: 772.4592 - val_loss: -546.2430 - val_mse: 822.8779\n",
            "Epoch 484/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7511 - mse: 772.2019 - val_loss: -546.2506 - val_mse: 822.3186\n",
            "Epoch 485/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.7489 - mse: 771.7570 - val_loss: -546.2009 - val_mse: 824.8025\n",
            "Epoch 486/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.7506 - mse: 772.0106 - val_loss: -546.2394 - val_mse: 824.1611\n",
            "Epoch 487/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7481 - mse: 771.8441 - val_loss: -546.2115 - val_mse: 823.9603\n",
            "Epoch 488/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7566 - mse: 771.1007 - val_loss: -546.2215 - val_mse: 824.8965\n",
            "Epoch 489/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7504 - mse: 771.4359 - val_loss: -546.2542 - val_mse: 820.6326\n",
            "Epoch 490/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7666 - mse: 770.5231 - val_loss: -546.2146 - val_mse: 822.6163\n",
            "Epoch 491/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7645 - mse: 770.3268 - val_loss: -546.2310 - val_mse: 821.8517\n",
            "Epoch 492/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7583 - mse: 769.4647 - val_loss: -546.2410 - val_mse: 823.6138\n",
            "Epoch 493/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7674 - mse: 770.2594 - val_loss: -546.2454 - val_mse: 823.1958\n",
            "Epoch 494/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7672 - mse: 769.5729 - val_loss: -546.2579 - val_mse: 820.2005\n",
            "Epoch 495/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7653 - mse: 769.1550 - val_loss: -546.1921 - val_mse: 822.1316\n",
            "Epoch 496/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.7696 - mse: 769.3358 - val_loss: -546.2362 - val_mse: 822.9158\n",
            "Epoch 497/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7742 - mse: 769.1224 - val_loss: -546.2328 - val_mse: 822.2180\n",
            "Epoch 498/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7681 - mse: 769.5421 - val_loss: -546.2355 - val_mse: 821.4527\n",
            "Epoch 499/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7753 - mse: 768.0704 - val_loss: -546.1502 - val_mse: 827.9230\n",
            "Epoch 500/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7815 - mse: 768.0455 - val_loss: -546.1633 - val_mse: 822.0771\n",
            "Epoch 501/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7773 - mse: 768.7924 - val_loss: -546.2626 - val_mse: 822.1230\n",
            "Epoch 502/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7816 - mse: 768.0599 - val_loss: -546.2172 - val_mse: 823.1906\n",
            "Epoch 503/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7761 - mse: 768.2858 - val_loss: -546.1642 - val_mse: 824.5819\n",
            "Epoch 504/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7854 - mse: 767.0124 - val_loss: -546.2000 - val_mse: 823.5944\n",
            "Epoch 505/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7913 - mse: 767.6802 - val_loss: -546.2404 - val_mse: 820.8493\n",
            "Epoch 506/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7983 - mse: 766.3113 - val_loss: -546.2646 - val_mse: 819.8868\n",
            "Epoch 507/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7896 - mse: 766.8550 - val_loss: -546.2665 - val_mse: 821.0872\n",
            "Epoch 508/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7905 - mse: 766.5510 - val_loss: -546.2672 - val_mse: 818.5218\n",
            "Epoch 509/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7902 - mse: 766.4821 - val_loss: -546.2702 - val_mse: 821.8748\n",
            "Epoch 510/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.7909 - mse: 766.3820 - val_loss: -546.2645 - val_mse: 817.7714\n",
            "Epoch 511/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8044 - mse: 765.6616 - val_loss: -546.2590 - val_mse: 819.1536\n",
            "Epoch 512/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7985 - mse: 765.7322 - val_loss: -546.2616 - val_mse: 820.4473\n",
            "Epoch 513/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7901 - mse: 766.4797 - val_loss: -546.2419 - val_mse: 821.4233\n",
            "Epoch 514/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8041 - mse: 764.7576 - val_loss: -546.2700 - val_mse: 820.0176\n",
            "Epoch 515/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8029 - mse: 765.1013 - val_loss: -546.2417 - val_mse: 821.6558\n",
            "Epoch 516/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.7834 - mse: 765.8342 - val_loss: -546.2809 - val_mse: 818.7783\n",
            "Epoch 517/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8131 - mse: 764.4124 - val_loss: -546.2018 - val_mse: 820.5139\n",
            "Epoch 518/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8060 - mse: 763.6616 - val_loss: -546.2596 - val_mse: 819.3633\n",
            "Epoch 519/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8113 - mse: 764.2443 - val_loss: -546.2712 - val_mse: 819.0084\n",
            "Epoch 520/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8118 - mse: 763.4999 - val_loss: -546.2165 - val_mse: 820.4694\n",
            "Epoch 521/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8140 - mse: 764.0506 - val_loss: -546.2799 - val_mse: 819.6738\n",
            "Epoch 522/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.8119 - mse: 763.3768 - val_loss: -546.2245 - val_mse: 820.0957\n",
            "Epoch 523/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8154 - mse: 763.4097 - val_loss: -546.2820 - val_mse: 818.9285\n",
            "Epoch 524/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8182 - mse: 763.8149 - val_loss: -546.2862 - val_mse: 817.4072\n",
            "Epoch 525/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8080 - mse: 764.0222 - val_loss: -546.0714 - val_mse: 827.8353\n",
            "Epoch 526/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8173 - mse: 763.1363 - val_loss: -546.2629 - val_mse: 819.4343\n",
            "Epoch 527/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8198 - mse: 762.6878 - val_loss: -546.2804 - val_mse: 817.4054\n",
            "Epoch 528/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8192 - mse: 762.1620 - val_loss: -546.2844 - val_mse: 819.0100\n",
            "Epoch 529/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8323 - mse: 761.7282 - val_loss: -546.2812 - val_mse: 819.0771\n",
            "Epoch 530/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8268 - mse: 762.0798 - val_loss: -546.2814 - val_mse: 817.8542\n",
            "Epoch 531/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8245 - mse: 761.9593 - val_loss: -546.2609 - val_mse: 819.2568\n",
            "Epoch 532/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8258 - mse: 762.0825 - val_loss: -546.2672 - val_mse: 818.1824\n",
            "Epoch 533/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8376 - mse: 760.7345 - val_loss: -546.2863 - val_mse: 819.8480\n",
            "Epoch 534/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8329 - mse: 761.2689 - val_loss: -546.2865 - val_mse: 818.0767\n",
            "Epoch 535/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8332 - mse: 760.6614 - val_loss: -546.2755 - val_mse: 819.2464\n",
            "Epoch 536/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8375 - mse: 761.0505 - val_loss: -546.1902 - val_mse: 817.6650\n",
            "Epoch 537/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8443 - mse: 760.1006 - val_loss: -546.2935 - val_mse: 816.2359\n",
            "Epoch 538/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8444 - mse: 759.4653 - val_loss: -546.2770 - val_mse: 818.2265\n",
            "Epoch 539/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8378 - mse: 760.4172 - val_loss: -546.2475 - val_mse: 818.2864\n",
            "Epoch 540/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.8348 - mse: 760.3157 - val_loss: -546.2954 - val_mse: 818.0160\n",
            "Epoch 541/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8453 - mse: 759.7928 - val_loss: -546.1592 - val_mse: 824.9232\n",
            "Epoch 542/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8495 - mse: 759.9739 - val_loss: -546.2972 - val_mse: 816.8699\n",
            "Epoch 543/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8466 - mse: 759.1208 - val_loss: -546.2885 - val_mse: 815.6890\n",
            "Epoch 544/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8385 - mse: 759.1664 - val_loss: -546.2514 - val_mse: 819.0450\n",
            "Epoch 545/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8470 - mse: 759.1449 - val_loss: -546.2485 - val_mse: 819.1005\n",
            "Epoch 546/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8448 - mse: 759.0773 - val_loss: -546.2927 - val_mse: 815.5111\n",
            "Epoch 547/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8443 - mse: 758.7513 - val_loss: -546.1747 - val_mse: 822.2147\n",
            "Epoch 548/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8421 - mse: 758.9641 - val_loss: -546.2980 - val_mse: 816.9941\n",
            "Epoch 549/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8430 - mse: 758.4774 - val_loss: -546.2540 - val_mse: 815.9051\n",
            "Epoch 550/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.8523 - mse: 758.0123 - val_loss: -546.1969 - val_mse: 822.6675\n",
            "Epoch 551/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8553 - mse: 758.1395 - val_loss: -546.3002 - val_mse: 814.6052\n",
            "Epoch 552/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8592 - mse: 757.3438 - val_loss: -546.2493 - val_mse: 821.6085\n",
            "Epoch 553/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -546.8619 - mse: 757.3737 - val_loss: -546.2997 - val_mse: 815.3728\n",
            "Epoch 554/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8586 - mse: 757.2781 - val_loss: -546.2465 - val_mse: 819.3944\n",
            "Epoch 555/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8623 - mse: 756.7981 - val_loss: -546.2467 - val_mse: 814.7775\n",
            "Epoch 556/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8704 - mse: 756.2984 - val_loss: -546.2972 - val_mse: 815.9998\n",
            "Epoch 557/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.8638 - mse: 756.6604 - val_loss: -546.3079 - val_mse: 816.0784\n",
            "Epoch 558/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.8645 - mse: 756.7143 - val_loss: -546.2560 - val_mse: 816.7215\n",
            "Epoch 559/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8723 - mse: 756.2598 - val_loss: -546.2852 - val_mse: 816.3700\n",
            "Epoch 560/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8731 - mse: 755.7254 - val_loss: -546.2522 - val_mse: 815.5078\n",
            "Epoch 561/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8687 - mse: 755.9181 - val_loss: -546.2446 - val_mse: 816.4200\n",
            "Epoch 562/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8603 - mse: 756.2256 - val_loss: -546.2642 - val_mse: 817.2181\n",
            "Epoch 563/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8700 - mse: 755.0667 - val_loss: -546.2831 - val_mse: 817.1636\n",
            "Epoch 564/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8691 - mse: 755.1125 - val_loss: -546.2809 - val_mse: 816.8323\n",
            "Epoch 565/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.8651 - mse: 756.1160 - val_loss: -546.2880 - val_mse: 814.7911\n",
            "Epoch 566/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.8809 - mse: 754.5792 - val_loss: -546.3096 - val_mse: 816.4713\n",
            "Epoch 567/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8653 - mse: 755.7775 - val_loss: -546.3006 - val_mse: 815.6192\n",
            "Epoch 568/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8713 - mse: 754.4238 - val_loss: -546.1868 - val_mse: 821.1578\n",
            "Epoch 569/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.8801 - mse: 754.0285 - val_loss: -546.2987 - val_mse: 817.7994\n",
            "Epoch 570/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8763 - mse: 754.0914 - val_loss: -546.3116 - val_mse: 814.8416\n",
            "Epoch 571/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8731 - mse: 754.9082 - val_loss: -546.3086 - val_mse: 815.4503\n",
            "Epoch 572/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.8867 - mse: 753.8029 - val_loss: -546.3082 - val_mse: 815.8517\n",
            "Epoch 573/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.8919 - mse: 753.4681 - val_loss: -546.2496 - val_mse: 822.6415\n",
            "Epoch 574/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8832 - mse: 753.5841 - val_loss: -546.3047 - val_mse: 815.8784\n",
            "Epoch 575/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8883 - mse: 753.2438 - val_loss: -546.3163 - val_mse: 816.8109\n",
            "Epoch 576/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.8787 - mse: 754.0629 - val_loss: -546.2236 - val_mse: 819.5933\n",
            "Epoch 577/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8791 - mse: 754.3020 - val_loss: -546.3177 - val_mse: 815.3328\n",
            "Epoch 578/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8934 - mse: 752.7725 - val_loss: -546.2521 - val_mse: 816.3844\n",
            "Epoch 579/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8901 - mse: 752.6075 - val_loss: -546.3077 - val_mse: 815.9993\n",
            "Epoch 580/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8950 - mse: 752.7848 - val_loss: -546.2969 - val_mse: 815.3197\n",
            "Epoch 581/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8884 - mse: 752.9000 - val_loss: -546.2991 - val_mse: 813.7421\n",
            "Epoch 582/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8986 - mse: 751.4073 - val_loss: -546.2725 - val_mse: 813.9927\n",
            "Epoch 583/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8856 - mse: 752.2427 - val_loss: -546.2675 - val_mse: 814.9382\n",
            "Epoch 584/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8904 - mse: 752.1695 - val_loss: -546.3076 - val_mse: 813.4802\n",
            "Epoch 585/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8950 - mse: 752.0439 - val_loss: -546.2824 - val_mse: 819.8231\n",
            "Epoch 586/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8816 - mse: 751.5700 - val_loss: -546.2905 - val_mse: 815.2498\n",
            "Epoch 587/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9066 - mse: 751.6281 - val_loss: -546.3250 - val_mse: 812.9247\n",
            "Epoch 588/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.8953 - mse: 751.1597 - val_loss: -546.2690 - val_mse: 815.4257\n",
            "Epoch 589/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9067 - mse: 751.0475 - val_loss: -546.2991 - val_mse: 814.9820\n",
            "Epoch 590/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.8999 - mse: 751.3318 - val_loss: -546.3179 - val_mse: 813.8491\n",
            "Epoch 591/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9056 - mse: 750.1217 - val_loss: -546.3046 - val_mse: 815.6124\n",
            "Epoch 592/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.8879 - mse: 751.6358 - val_loss: -546.3079 - val_mse: 814.4501\n",
            "Epoch 593/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.8974 - mse: 751.3251 - val_loss: -546.3226 - val_mse: 813.4505\n",
            "Epoch 594/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9038 - mse: 750.8134 - val_loss: -546.2398 - val_mse: 815.9576\n",
            "Epoch 595/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.9082 - mse: 749.8217 - val_loss: -546.3225 - val_mse: 813.2119\n",
            "Epoch 596/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9009 - mse: 750.0627 - val_loss: -546.3124 - val_mse: 811.5782\n",
            "Epoch 597/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.9132 - mse: 749.6353 - val_loss: -546.3174 - val_mse: 814.5592\n",
            "Epoch 598/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.9061 - mse: 749.6434 - val_loss: -546.2944 - val_mse: 814.3491\n",
            "Epoch 599/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9103 - mse: 749.7043 - val_loss: -546.3011 - val_mse: 814.0416\n",
            "Epoch 600/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9029 - mse: 749.7386 - val_loss: -546.3123 - val_mse: 811.7894\n",
            "Epoch 601/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9185 - mse: 748.5524 - val_loss: -546.3203 - val_mse: 812.2744\n",
            "Epoch 602/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9145 - mse: 749.0308 - val_loss: -546.3254 - val_mse: 811.7966\n",
            "Epoch 603/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9164 - mse: 748.5975 - val_loss: -546.2755 - val_mse: 812.9110\n",
            "Epoch 604/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9111 - mse: 748.8893 - val_loss: -546.2848 - val_mse: 813.8754\n",
            "Epoch 605/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9158 - mse: 748.4920 - val_loss: -546.2608 - val_mse: 814.7159\n",
            "Epoch 606/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9184 - mse: 748.0651 - val_loss: -546.3345 - val_mse: 812.0258\n",
            "Epoch 607/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9123 - mse: 748.4395 - val_loss: -546.3018 - val_mse: 812.8436\n",
            "Epoch 608/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9148 - mse: 748.5254 - val_loss: -546.3299 - val_mse: 813.5109\n",
            "Epoch 609/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9232 - mse: 747.5889 - val_loss: -546.3240 - val_mse: 813.2567\n",
            "Epoch 610/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9302 - mse: 747.5056 - val_loss: -546.2995 - val_mse: 812.2915\n",
            "Epoch 611/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9204 - mse: 747.6711 - val_loss: -546.3211 - val_mse: 812.3848\n",
            "Epoch 612/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.9202 - mse: 747.5290 - val_loss: -546.2756 - val_mse: 814.4090\n",
            "Epoch 613/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9271 - mse: 746.6321 - val_loss: -546.3270 - val_mse: 813.7394\n",
            "Epoch 614/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9321 - mse: 746.8144 - val_loss: -546.2575 - val_mse: 816.8677\n",
            "Epoch 615/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -546.9163 - mse: 747.7460 - val_loss: -546.3310 - val_mse: 812.8456\n",
            "Epoch 616/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.9265 - mse: 747.0626 - val_loss: -546.3265 - val_mse: 812.6082\n",
            "Epoch 617/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.9305 - mse: 746.9990 - val_loss: -546.3303 - val_mse: 811.9320\n",
            "Epoch 618/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.9226 - mse: 746.8935 - val_loss: -546.3274 - val_mse: 812.6310\n",
            "Epoch 619/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.9212 - mse: 746.4448 - val_loss: -546.2826 - val_mse: 812.4602\n",
            "Epoch 620/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.9319 - mse: 745.7821 - val_loss: -546.3259 - val_mse: 811.6527\n",
            "Epoch 621/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -546.9298 - mse: 745.5560 - val_loss: -546.3036 - val_mse: 814.8693\n",
            "Save file name colab_notebook_data/feature_interactions/trained_models/poissonloss/negcontrol_model-onelayer_l1reg-0.0_seed100_axanf.h5\n",
            "Training model colab_notebook_data/feature_interactions/trained_models/poissonloss/poscontrol_model-sanitycheck_l1reg-1e-05_seed100_qtexi.h5\n",
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        (None, 100, 4)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 76, 64)            6464      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_18  (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 6,529\n",
            "Trainable params: 6,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "40000/40000 [==============================] - 1s 27us/step - loss: -138.6495 - mse: 17897.3809 - val_loss: -208.6714 - val_mse: 17286.7969\n",
            "Epoch 2/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -233.3628 - mse: 16827.1992 - val_loss: -253.6866 - val_mse: 16409.0352\n",
            "Epoch 3/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -267.6969 - mse: 16015.7852 - val_loss: -280.7220 - val_mse: 15641.6045\n",
            "Epoch 4/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -290.3009 - mse: 15287.2480 - val_loss: -299.5287 - val_mse: 14954.4385\n",
            "Epoch 5/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -306.5482 - mse: 14633.9424 - val_loss: -313.6674 - val_mse: 14329.4668\n",
            "Epoch 6/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -319.0704 - mse: 14036.4990 - val_loss: -324.7488 - val_mse: 13758.8574\n",
            "Epoch 7/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -329.0318 - mse: 13489.8525 - val_loss: -333.7834 - val_mse: 13230.4287\n",
            "Epoch 8/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -337.3052 - mse: 12978.6543 - val_loss: -341.3641 - val_mse: 12735.4141\n",
            "Epoch 9/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -344.3058 - mse: 12498.7305 - val_loss: -347.8490 - val_mse: 12268.5244\n",
            "Epoch 10/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -350.2891 - mse: 12048.8604 - val_loss: -353.3524 - val_mse: 11836.1592\n",
            "Epoch 11/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -355.3799 - mse: 11633.0820 - val_loss: -358.0705 - val_mse: 11435.3936\n",
            "Epoch 12/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -359.7651 - mse: 11247.2568 - val_loss: -362.1574 - val_mse: 11062.8037\n",
            "Epoch 13/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -363.5937 - mse: 10886.7617 - val_loss: -365.7655 - val_mse: 10711.7744\n",
            "Epoch 14/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -367.0017 - mse: 10544.9951 - val_loss: -368.9907 - val_mse: 10378.2773\n",
            "Epoch 15/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -370.0283 - mse: 10223.0469 - val_loss: -371.8241 - val_mse: 10068.0801\n",
            "Epoch 16/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -372.6740 - mse: 9925.6807 - val_loss: -374.3072 - val_mse: 9781.4082\n",
            "Epoch 17/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -374.9913 - mse: 9651.5166 - val_loss: -376.4809 - val_mse: 9517.7188\n",
            "Epoch 18/1000\n",
            "40000/40000 [==============================] - 1s 21us/step - loss: -377.0260 - mse: 9399.0127 - val_loss: -378.3865 - val_mse: 9275.6523\n",
            "Epoch 19/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -378.8184 - mse: 9166.3652 - val_loss: -380.0810 - val_mse: 9050.8105\n",
            "Epoch 20/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -380.4136 - mse: 8950.2998 - val_loss: -381.5890 - val_mse: 8842.2061\n",
            "Epoch 21/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -381.8288 - mse: 8750.6602 - val_loss: -382.9140 - val_mse: 8651.4961\n",
            "Epoch 22/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -383.0578 - mse: 8570.4658 - val_loss: -384.0629 - val_mse: 8479.7959\n",
            "Epoch 23/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -384.1304 - mse: 8407.3301 - val_loss: -385.0629 - val_mse: 8324.9316\n",
            "Epoch 24/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -385.0585 - mse: 8261.1797 - val_loss: -385.9217 - val_mse: 8187.3457\n",
            "Epoch 25/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -385.8389 - mse: 8134.2026 - val_loss: -386.6407 - val_mse: 8068.4600\n",
            "Epoch 26/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -386.4901 - mse: 8024.9746 - val_loss: -387.2350 - val_mse: 7967.2646\n",
            "Epoch 27/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -387.0323 - mse: 7931.4033 - val_loss: -387.7323 - val_mse: 7880.2246\n",
            "Epoch 28/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -387.4830 - mse: 7851.5264 - val_loss: -388.1420 - val_mse: 7806.6450\n",
            "Epoch 29/1000\n",
            "40000/40000 [==============================] - 1s 20us/step - loss: -387.8479 - mse: 7785.2280 - val_loss: -388.4664 - val_mse: 7746.9873\n",
            "Epoch 30/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -388.1357 - mse: 7731.7202 - val_loss: -388.7226 - val_mse: 7698.8047\n",
            "Epoch 31/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -388.3597 - mse: 7689.2017 - val_loss: -388.9182 - val_mse: 7661.2993\n",
            "Epoch 32/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -388.5276 - mse: 7656.7178 - val_loss: -389.0633 - val_mse: 7632.9502\n",
            "Epoch 33/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -388.6488 - mse: 7632.8682 - val_loss: -389.1665 - val_mse: 7612.4858\n",
            "Epoch 34/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -388.7343 - mse: 7615.7920 - val_loss: -389.2395 - val_mse: 7597.8105\n",
            "Epoch 35/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -388.7926 - mse: 7604.0010 - val_loss: -389.2871 - val_mse: 7588.1274\n",
            "Epoch 36/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -388.8315 - mse: 7596.0425 - val_loss: -389.3192 - val_mse: 7581.5410\n",
            "Epoch 37/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -388.8565 - mse: 7590.8994 - val_loss: -389.3394 - val_mse: 7577.3569\n",
            "Epoch 38/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -388.8716 - mse: 7587.7808 - val_loss: -389.3523 - val_mse: 7574.6855\n",
            "Epoch 39/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -388.8822 - mse: 7585.5679 - val_loss: -389.3622 - val_mse: 7572.6113\n",
            "Epoch 40/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -388.8923 - mse: 7583.4609 - val_loss: -389.3728 - val_mse: 7570.4048\n",
            "Epoch 41/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -388.9042 - mse: 7580.9502 - val_loss: -389.3887 - val_mse: 7567.0386\n",
            "Epoch 42/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -388.9225 - mse: 7577.1064 - val_loss: -389.4051 - val_mse: 7563.5825\n",
            "Epoch 43/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -388.9360 - mse: 7574.2578 - val_loss: -389.4165 - val_mse: 7561.1777\n",
            "Epoch 44/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -388.9478 - mse: 7571.7441 - val_loss: -389.4300 - val_mse: 7558.3296\n",
            "Epoch 45/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -388.9773 - mse: 7565.5576 - val_loss: -389.4686 - val_mse: 7550.2144\n",
            "Epoch 46/1000\n",
            "40000/40000 [==============================] - 1s 18us/step - loss: -389.0050 - mse: 7559.7090 - val_loss: -389.4893 - val_mse: 7545.8472\n",
            "Epoch 47/1000\n",
            "40000/40000 [==============================] - 1s 19us/step - loss: -389.0603 - mse: 7548.3198 - val_loss: -389.6279 - val_mse: 7517.5654\n",
            "Epoch 48/1000\n",
            "10000/40000 [======>.......................] - ETA: 0s - loss: -389.1237 - mse: 7560.5601Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKZLtACYS8db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHfeXcR-1vuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdJc9KsI2DVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}