{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainModels.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMuj3QczZNii2hyyz5XTSzd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kundajelab/mfinkels_work/blob/master/av/TrainModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy6uELUUxZpx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fa82cbef-103b-4925-a8cd-f3cced6c8e37"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikdAjY7YxzBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "outputId": "7b5aae7a-a2e9-4eb2-e305-5aaa6a9e0e38"
      },
      "source": [
        "#download raw data\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/371e0dc637ccf85716d208e312c8f7c0ba3174d4/av/simulation.simdata.gz\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/371e0dc637ccf85716d208e312c8f7c0ba3174d4/av/neg_labels.txt.gz\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/371e0dc637ccf85716d208e312c8f7c0ba3174d4/av/pos_labels.txt.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-18 08:26:27--  https://github.com/kundajelab/mfinkels_work/raw/371e0dc637ccf85716d208e312c8f7c0ba3174d4/av/simulation.simdata.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/371e0dc637ccf85716d208e312c8f7c0ba3174d4/av/simulation.simdata.gz [following]\n",
            "--2020-05-18 08:26:28--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/371e0dc637ccf85716d208e312c8f7c0ba3174d4/av/simulation.simdata.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2093048 (2.0M) [application/octet-stream]\n",
            "Saving to: ‘simulation.simdata.gz’\n",
            "\n",
            "\rsimulation.simdata.   0%[                    ]       0  --.-KB/s               \rsimulation.simdata. 100%[===================>]   2.00M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-05-18 08:26:28 (16.8 MB/s) - ‘simulation.simdata.gz’ saved [2093048/2093048]\n",
            "\n",
            "--2020-05-18 08:26:29--  https://github.com/kundajelab/mfinkels_work/raw/371e0dc637ccf85716d208e312c8f7c0ba3174d4/av/neg_labels.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/371e0dc637ccf85716d208e312c8f7c0ba3174d4/av/neg_labels.txt.gz [following]\n",
            "--2020-05-18 08:26:30--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/371e0dc637ccf85716d208e312c8f7c0ba3174d4/av/neg_labels.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 523525 (511K) [application/octet-stream]\n",
            "Saving to: ‘neg_labels.txt.gz’\n",
            "\n",
            "neg_labels.txt.gz   100%[===================>] 511.25K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-05-18 08:26:30 (11.6 MB/s) - ‘neg_labels.txt.gz’ saved [523525/523525]\n",
            "\n",
            "--2020-05-18 08:26:32--  https://github.com/kundajelab/mfinkels_work/raw/371e0dc637ccf85716d208e312c8f7c0ba3174d4/av/pos_labels.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/371e0dc637ccf85716d208e312c8f7c0ba3174d4/av/pos_labels.txt.gz [following]\n",
            "--2020-05-18 08:26:32--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/371e0dc637ccf85716d208e312c8f7c0ba3174d4/av/pos_labels.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 518844 (507K) [application/octet-stream]\n",
            "Saving to: ‘pos_labels.txt.gz’\n",
            "\n",
            "pos_labels.txt.gz   100%[===================>] 506.68K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-05-18 08:26:33 (16.3 MB/s) - ‘pos_labels.txt.gz’ saved [518844/518844]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhBwM80nyOa8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "470acf9e-995b-4c7c-be49-0f5f4491ef7b"
      },
      "source": [
        "!gunzip simulation.simdata.gz\n",
        "!md5sum simulation.simdata"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28490a9cd104baf7de558df0e01e7eef  simulation.simdata\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJRNHLEyymSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "4b7e414e-c837-4897-c8e3-02f506d5235d"
      },
      "source": [
        "!gunzip neg_labels.txt.gz\n",
        "!head neg_labels.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\t3.9556714333663376\n",
            "0\t0.8723493322167508\n",
            "183\t165.86628508719633\n",
            "83\t82.91478903189929\n",
            "109\t102.47376788600042\n",
            "115\t112.80948366668682\n",
            "0\t0.2505610132630518\n",
            "109\t113.12165963419002\n",
            "208\t235.77379484710877\n",
            "142\t120.82657161930747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlmbPjgCyUWq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "38373f4d-8a1f-4d7d-d3d0-061fcaaba9be"
      },
      "source": [
        "!gunzip pos_labels.txt.gz\n",
        "!head pos_labels.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\t0.47204300550326533\n",
            "0\t0.0488862697472111\n",
            "121\t128.17060289394672\n",
            "38\t45.300109361586486\n",
            "60\t62.24010378600618\n",
            "72\t71.89019598160023\n",
            "0\t0.0075252597546593145\n",
            "81\t72.18881330157092\n",
            "210\t217.21736987999986\n",
            "77\t79.68836743977995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBtXarlUynn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "f08f8486-9799-4f91-cbd3-0f441ee04c89"
      },
      "source": [
        "!pip install simdna"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting simdna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/c6/dc6cc2e9ac09c85d5ec6d896c6c43c8dd5ef50bb9c14423e9290131dce27/simdna-0.4.3.2.tar.gz (634kB)\n",
            "\r\u001b[K     |▌                               | 10kB 19.6MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 4.2MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 4.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 4.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81kB 5.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 112kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 143kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 153kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 174kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 184kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 204kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 215kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 225kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 235kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 245kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 256kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 266kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 286kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 307kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 327kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 337kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 348kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 358kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 368kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 389kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 399kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 409kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 419kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 430kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 440kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 450kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 460kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 471kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 481kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 491kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 501kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 512kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 522kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 532kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 542kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 552kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 563kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 573kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 583kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 593kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 604kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 614kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 624kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 634kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.6/dist-packages (from simdna) (1.18.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from simdna) (3.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from simdna) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->simdna) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->simdna) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->simdna) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->simdna) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->simdna) (1.12.0)\n",
            "Building wheels for collected packages: simdna\n",
            "  Building wheel for simdna (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for simdna\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for simdna\n",
            "Failed to build simdna\n",
            "Installing collected packages: simdna\n",
            "    Running setup.py install for simdna ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed simdna-0.4.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a-rv5JUzGhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import simdna\n",
        "from simdna import synthetic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDo9TZkQzKCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = synthetic.read_simdata_file(\"simulation.simdata\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMQPKHf1zL-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#this is set up for 1d convolutions where examples\n",
        "#have dimensions (len, num_channels) \n",
        "#the channel axis is the axis for one-hot encoding.\n",
        "def one_hot_encode_along_channel_axis(sequence):\n",
        "    to_return = np.zeros((len(sequence),4), dtype=np.int8)\n",
        "    seq_to_one_hot_fill_in_array(zeros_array=to_return,\n",
        "                                 sequence=sequence, one_hot_axis=1)\n",
        "    return to_return\n",
        "\n",
        "def seq_to_one_hot_fill_in_array(zeros_array, sequence, one_hot_axis):\n",
        "    assert one_hot_axis==0 or one_hot_axis==1\n",
        "    if (one_hot_axis==0):\n",
        "        assert zeros_array.shape[1] == len(sequence)\n",
        "    elif (one_hot_axis==1): \n",
        "        assert zeros_array.shape[0] == len(sequence)\n",
        "    #will mutate zeros_array\n",
        "    for (i,char) in enumerate(sequence):\n",
        "        if (char==\"A\" or char==\"a\"):\n",
        "            char_idx = 0\n",
        "        elif (char==\"C\" or char==\"c\"):\n",
        "            char_idx = 1\n",
        "        elif (char==\"G\" or char==\"g\"):\n",
        "            char_idx = 2\n",
        "        elif (char==\"T\" or char==\"t\"):\n",
        "            char_idx = 3\n",
        "        elif (char==\"N\" or char==\"n\"):\n",
        "            continue #leave that pos as all 0's\n",
        "        else:\n",
        "            raise RuntimeError(\"Unsupported character: \"+str(char))\n",
        "        if (one_hot_axis==0):\n",
        "            zeros_array[char_idx,i] = 1\n",
        "        elif (one_hot_axis==1):\n",
        "            zeros_array[i,char_idx] = 1\n",
        "\n",
        "def anscombe_transform(vals):\n",
        "  return 2*np.sqrt(vals + 3.0/8)\n",
        "\n",
        "            \n",
        "onehot_data = np.array([one_hot_encode_along_channel_axis(seq) for seq in data.sequences])\n",
        "\n",
        "pos_labels = anscombe_transform(np.array([float(x.split(\"\\t\")[0]) for\n",
        "                                          x in open(\"pos_labels.txt\")]))\n",
        "neg_labels = anscombe_transform(np.array([float(x.split(\"\\t\")[0]) for\n",
        "                                          x in open(\"neg_labels.txt\")]))\n",
        "\n",
        "pos_oracle = anscombe_transform(np.array([float(x.split(\"\\t\")[1]) for\n",
        "                                          x in open(\"pos_labels.txt\")]))\n",
        "neg_oracle = anscombe_transform(np.array([float(x.split(\"\\t\")[1]) for\n",
        "                                          x in open(\"neg_labels.txt\")]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARK27HEQzqrn",
        "colab_type": "text"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq1mcODizcry",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "229dd75d-a333-4919-d890-8d4490974cf1"
      },
      "source": [
        "import keras\n",
        "\n",
        "def model_arch1():\n",
        "  model = keras.models.Sequential()\n",
        "  for i in range(4):\n",
        "    added_kwarg = {}\n",
        "    if (i==0):\n",
        "      added_kwarg[\"input_shape\"] = (100,4)\n",
        "    model.add(keras.layers.Conv1D(filters=15, kernel_size=7, \n",
        "                                  activation = \"relu\",\n",
        "                                  kernel_initializer=\"he_normal\",\n",
        "                                  **added_kwarg))\n",
        "  model.add(keras.layers.GlobalAveragePooling1D())\n",
        "  \n",
        "  for i in range(2):\n",
        "    model.add(keras.layers.Dense(50, activation=\"relu\",\n",
        "                                 kernel_initializer=\"he_normal\"))\n",
        "  model.add(keras.layers.Dense(1, activation=\"linear\"))\n",
        "  adam = keras.optimizers.Adam()\n",
        "  model.compile(optimizer=adam, loss=\"mean_squared_error\")\n",
        "  return model\n",
        "\n",
        "def train_model(model_constructor, X_train, y_train, X_valid, y_valid, seed):\n",
        "  np.random.seed(seed)\n",
        "  model = model_constructor()\n",
        "  print(model.summary())\n",
        "  model.fit(x=X_train, y=y_train, batch_size=200,\n",
        "            epochs=1000,\n",
        "            validation_data=(X_valid, y_valid),\n",
        "            callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                     patience=15,\n",
        "                                                     restore_best_weights=True)])\n",
        "  return model"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urM1OclozeM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "33938967-7614-43b4-ccc0-baf1270f847a"
      },
      "source": [
        "indices_train = np.arange(0, int(0.6 * onehot_data.shape[0]))\n",
        "indices_val = np.arange(int(0.6 * onehot_data.shape[0]),\n",
        "                        int(0.8 * onehot_data.shape[0]))\n",
        "indices_test = np.arange(int(0.8 * onehot_data.shape[0]), onehot_data.shape[0])\n",
        "X_test = onehot_data[indices_test]\n",
        "y_test_pos = pos_labels[indices_test]\n",
        "oracle_test_pos = pos_oracle[indices_test]\n",
        "y_test_neg = neg_labels[indices_test]\n",
        "oracle_test_neg = neg_oracle[indices_test]\n",
        "\n",
        "pos_model1 = train_model(model_constructor=model_arch1,\n",
        "                         X_train=onehot_data[indices_train],\n",
        "                         y_train=pos_labels[indices_train],\n",
        "                         X_valid=onehot_data[indices_val],\n",
        "                         y_valid=pos_labels[indices_val],\n",
        "                         seed=1234)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_5 (Conv1D)            (None, 94, 15)            435       \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 88, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 82, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 76, 15)            1590      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 50)                800       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 8,606\n",
            "Trainable params: 8,606\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 30000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "30000/30000 [==============================] - 8s 253us/step - loss: 121.6957 - val_loss: 85.9747\n",
            "Epoch 2/1000\n",
            "30000/30000 [==============================] - 1s 43us/step - loss: 82.6834 - val_loss: 75.4774\n",
            "Epoch 3/1000\n",
            "30000/30000 [==============================] - 1s 45us/step - loss: 65.1253 - val_loss: 52.1657\n",
            "Epoch 4/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 42.1773 - val_loss: 36.6371\n",
            "Epoch 5/1000\n",
            "30000/30000 [==============================] - 1s 46us/step - loss: 34.9593 - val_loss: 31.8862\n",
            "Epoch 6/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 31.1579 - val_loss: 29.5207\n",
            "Epoch 7/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 28.2890 - val_loss: 27.5171\n",
            "Epoch 8/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 26.1037 - val_loss: 24.3041\n",
            "Epoch 9/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 23.9855 - val_loss: 23.1212\n",
            "Epoch 10/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 22.7617 - val_loss: 26.7678\n",
            "Epoch 11/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 21.5833 - val_loss: 20.4285\n",
            "Epoch 12/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 20.0314 - val_loss: 19.1788\n",
            "Epoch 13/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 19.0734 - val_loss: 18.0712\n",
            "Epoch 14/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 17.6047 - val_loss: 17.7952\n",
            "Epoch 15/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 16.4083 - val_loss: 16.0950\n",
            "Epoch 16/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 15.3866 - val_loss: 15.0177\n",
            "Epoch 17/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 14.1364 - val_loss: 13.8359\n",
            "Epoch 18/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 13.3807 - val_loss: 13.2981\n",
            "Epoch 19/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 12.7885 - val_loss: 12.7016\n",
            "Epoch 20/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 12.2459 - val_loss: 13.7240\n",
            "Epoch 21/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 11.7319 - val_loss: 12.0639\n",
            "Epoch 22/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 11.1584 - val_loss: 11.0644\n",
            "Epoch 23/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 10.7164 - val_loss: 10.8483\n",
            "Epoch 24/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 10.5184 - val_loss: 10.5067\n",
            "Epoch 25/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 10.2076 - val_loss: 10.3899\n",
            "Epoch 26/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 9.8008 - val_loss: 10.4023\n",
            "Epoch 27/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 9.4848 - val_loss: 9.6965\n",
            "Epoch 28/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 9.3217 - val_loss: 9.6408\n",
            "Epoch 29/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 9.0568 - val_loss: 8.9758\n",
            "Epoch 30/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 8.8738 - val_loss: 8.9372\n",
            "Epoch 31/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 8.5672 - val_loss: 8.7669\n",
            "Epoch 32/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 8.4472 - val_loss: 8.4546\n",
            "Epoch 33/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 8.0917 - val_loss: 8.1076\n",
            "Epoch 34/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 8.0029 - val_loss: 7.9284\n",
            "Epoch 35/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 7.6265 - val_loss: 8.1354\n",
            "Epoch 36/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 7.5407 - val_loss: 8.1637\n",
            "Epoch 37/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 7.3759 - val_loss: 7.8733\n",
            "Epoch 38/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 6.9831 - val_loss: 7.3073\n",
            "Epoch 39/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 6.8975 - val_loss: 7.2925\n",
            "Epoch 40/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 6.9934 - val_loss: 7.0609\n",
            "Epoch 41/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 6.5865 - val_loss: 6.7832\n",
            "Epoch 42/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 6.5044 - val_loss: 6.6112\n",
            "Epoch 43/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 6.4099 - val_loss: 6.5173\n",
            "Epoch 44/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 6.1453 - val_loss: 6.4028\n",
            "Epoch 45/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 6.1778 - val_loss: 6.5683\n",
            "Epoch 46/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 5.8385 - val_loss: 6.0870\n",
            "Epoch 47/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 5.7301 - val_loss: 5.8958\n",
            "Epoch 48/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 5.5465 - val_loss: 5.9142\n",
            "Epoch 49/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 5.5059 - val_loss: 5.6327\n",
            "Epoch 50/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 5.3207 - val_loss: 5.5460\n",
            "Epoch 51/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 5.1403 - val_loss: 5.4371\n",
            "Epoch 52/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 5.1344 - val_loss: 5.2223\n",
            "Epoch 53/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 4.9154 - val_loss: 5.2182\n",
            "Epoch 54/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 4.9561 - val_loss: 5.0379\n",
            "Epoch 55/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 4.7979 - val_loss: 4.9318\n",
            "Epoch 56/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 4.6586 - val_loss: 4.8237\n",
            "Epoch 57/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 4.5968 - val_loss: 5.6842\n",
            "Epoch 58/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 4.5293 - val_loss: 4.8792\n",
            "Epoch 59/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 4.4385 - val_loss: 4.5161\n",
            "Epoch 60/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 4.3356 - val_loss: 4.4590\n",
            "Epoch 61/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 4.1656 - val_loss: 4.4935\n",
            "Epoch 62/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 4.1862 - val_loss: 4.3472\n",
            "Epoch 63/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 4.0311 - val_loss: 4.2673\n",
            "Epoch 64/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 4.0499 - val_loss: 4.1439\n",
            "Epoch 65/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 4.0206 - val_loss: 4.0694\n",
            "Epoch 66/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 3.8260 - val_loss: 4.1329\n",
            "Epoch 67/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 3.9178 - val_loss: 4.2792\n",
            "Epoch 68/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 3.7648 - val_loss: 4.0560\n",
            "Epoch 69/1000\n",
            "30000/30000 [==============================] - 1s 47us/step - loss: 3.6485 - val_loss: 3.9949\n",
            "Epoch 70/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 3.5516 - val_loss: 4.0126\n",
            "Epoch 71/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 3.4981 - val_loss: 3.8738\n",
            "Epoch 72/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 3.5085 - val_loss: 3.6972\n",
            "Epoch 73/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 3.4664 - val_loss: 3.7739\n",
            "Epoch 74/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 3.4038 - val_loss: 3.8185\n",
            "Epoch 75/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 3.2922 - val_loss: 3.6830\n",
            "Epoch 76/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 3.2665 - val_loss: 3.7186\n",
            "Epoch 77/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 3.2818 - val_loss: 4.0717\n",
            "Epoch 78/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 3.2976 - val_loss: 3.6375\n",
            "Epoch 79/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 3.1769 - val_loss: 3.8817\n",
            "Epoch 80/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 3.2045 - val_loss: 3.6515\n",
            "Epoch 81/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 3.1160 - val_loss: 3.3932\n",
            "Epoch 82/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 3.0207 - val_loss: 3.5883\n",
            "Epoch 83/1000\n",
            "30000/30000 [==============================] - 2s 53us/step - loss: 3.0687 - val_loss: 3.7315\n",
            "Epoch 84/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.9993 - val_loss: 3.5096\n",
            "Epoch 85/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 2.9734 - val_loss: 3.3411\n",
            "Epoch 86/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 3.0753 - val_loss: 3.3812\n",
            "Epoch 87/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.8973 - val_loss: 3.4068\n",
            "Epoch 88/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.9689 - val_loss: 3.4998\n",
            "Epoch 89/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.8821 - val_loss: 3.2443\n",
            "Epoch 90/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.9095 - val_loss: 3.5664\n",
            "Epoch 91/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.8567 - val_loss: 3.8508\n",
            "Epoch 92/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.8769 - val_loss: 3.5798\n",
            "Epoch 93/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 2.7960 - val_loss: 3.2701\n",
            "Epoch 94/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.7781 - val_loss: 3.4480\n",
            "Epoch 95/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.7567 - val_loss: 3.1027\n",
            "Epoch 96/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 2.7517 - val_loss: 3.0683\n",
            "Epoch 97/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.7273 - val_loss: 3.2065\n",
            "Epoch 98/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.7144 - val_loss: 3.2592\n",
            "Epoch 99/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.7020 - val_loss: 3.2508\n",
            "Epoch 100/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.7025 - val_loss: 3.2338\n",
            "Epoch 101/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.6735 - val_loss: 3.2203\n",
            "Epoch 102/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.6095 - val_loss: 3.2143\n",
            "Epoch 103/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.6150 - val_loss: 3.1079\n",
            "Epoch 104/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.6445 - val_loss: 3.1072\n",
            "Epoch 105/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.5637 - val_loss: 3.0101\n",
            "Epoch 106/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 2.5371 - val_loss: 3.3719\n",
            "Epoch 107/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 2.6402 - val_loss: 3.0525\n",
            "Epoch 108/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.6108 - val_loss: 3.1706\n",
            "Epoch 109/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.5376 - val_loss: 2.9357\n",
            "Epoch 110/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.4614 - val_loss: 3.2684\n",
            "Epoch 111/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 2.4897 - val_loss: 3.2075\n",
            "Epoch 112/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.4993 - val_loss: 2.9920\n",
            "Epoch 113/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 2.4707 - val_loss: 3.1016\n",
            "Epoch 114/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 2.5204 - val_loss: 2.8787\n",
            "Epoch 115/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.4110 - val_loss: 3.1791\n",
            "Epoch 116/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 2.4868 - val_loss: 2.9599\n",
            "Epoch 117/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.3888 - val_loss: 2.9625\n",
            "Epoch 118/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 2.4278 - val_loss: 2.9295\n",
            "Epoch 119/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.4296 - val_loss: 2.8426\n",
            "Epoch 120/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.7112 - val_loss: 4.0637\n",
            "Epoch 121/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.3991 - val_loss: 2.8204\n",
            "Epoch 122/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.3391 - val_loss: 2.9906\n",
            "Epoch 123/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.3120 - val_loss: 2.9654\n",
            "Epoch 124/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.3476 - val_loss: 2.9868\n",
            "Epoch 125/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.3658 - val_loss: 2.8142\n",
            "Epoch 126/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.3587 - val_loss: 2.7881\n",
            "Epoch 127/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.3361 - val_loss: 2.7889\n",
            "Epoch 128/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.3194 - val_loss: 2.9438\n",
            "Epoch 129/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.2786 - val_loss: 2.7679\n",
            "Epoch 130/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.2223 - val_loss: 3.5890\n",
            "Epoch 131/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.3068 - val_loss: 3.1412\n",
            "Epoch 132/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.2927 - val_loss: 2.7384\n",
            "Epoch 133/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.2936 - val_loss: 2.7211\n",
            "Epoch 134/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.3473 - val_loss: 2.8030\n",
            "Epoch 135/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.2303 - val_loss: 2.9816\n",
            "Epoch 136/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.2801 - val_loss: 2.7392\n",
            "Epoch 137/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.2611 - val_loss: 2.7043\n",
            "Epoch 138/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.1527 - val_loss: 2.7218\n",
            "Epoch 139/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.2336 - val_loss: 2.8412\n",
            "Epoch 140/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 2.2003 - val_loss: 2.7544\n",
            "Epoch 141/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.1592 - val_loss: 2.6605\n",
            "Epoch 142/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.2036 - val_loss: 2.6990\n",
            "Epoch 143/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.2110 - val_loss: 2.7410\n",
            "Epoch 144/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.1591 - val_loss: 2.8786\n",
            "Epoch 145/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.1264 - val_loss: 2.7218\n",
            "Epoch 146/1000\n",
            "30000/30000 [==============================] - 2s 53us/step - loss: 2.2326 - val_loss: 2.8401\n",
            "Epoch 147/1000\n",
            "30000/30000 [==============================] - 2s 53us/step - loss: 2.1915 - val_loss: 2.8977\n",
            "Epoch 148/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.0880 - val_loss: 2.6291\n",
            "Epoch 149/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 2.1806 - val_loss: 2.7591\n",
            "Epoch 150/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.1517 - val_loss: 2.7630\n",
            "Epoch 151/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 2.1161 - val_loss: 3.2212\n",
            "Epoch 152/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 2.1033 - val_loss: 2.9339\n",
            "Epoch 153/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.1196 - val_loss: 2.6278\n",
            "Epoch 154/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.0856 - val_loss: 2.6938\n",
            "Epoch 155/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 2.0725 - val_loss: 2.9395\n",
            "Epoch 156/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.0669 - val_loss: 2.7221\n",
            "Epoch 157/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.0351 - val_loss: 2.8451\n",
            "Epoch 158/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.1000 - val_loss: 2.7613\n",
            "Epoch 159/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.0416 - val_loss: 2.6846\n",
            "Epoch 160/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.0385 - val_loss: 2.6080\n",
            "Epoch 161/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.0561 - val_loss: 2.5812\n",
            "Epoch 162/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 2.0329 - val_loss: 2.6462\n",
            "Epoch 163/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.0377 - val_loss: 2.5420\n",
            "Epoch 164/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 1.9764 - val_loss: 2.7351\n",
            "Epoch 165/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 1.9877 - val_loss: 2.6155\n",
            "Epoch 166/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.9865 - val_loss: 2.6588\n",
            "Epoch 167/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.0038 - val_loss: 2.5393\n",
            "Epoch 168/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.0043 - val_loss: 2.7757\n",
            "Epoch 169/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.9817 - val_loss: 2.7875\n",
            "Epoch 170/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.9977 - val_loss: 2.8241\n",
            "Epoch 171/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 2.0358 - val_loss: 2.5305\n",
            "Epoch 172/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.9195 - val_loss: 3.2302\n",
            "Epoch 173/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.9619 - val_loss: 2.4986\n",
            "Epoch 174/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 1.9348 - val_loss: 2.5335\n",
            "Epoch 175/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 1.9191 - val_loss: 2.4885\n",
            "Epoch 176/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 1.9102 - val_loss: 2.5456\n",
            "Epoch 177/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 2.0229 - val_loss: 2.5808\n",
            "Epoch 178/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.8994 - val_loss: 2.5301\n",
            "Epoch 179/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 1.9453 - val_loss: 2.5374\n",
            "Epoch 180/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 1.9117 - val_loss: 2.4520\n",
            "Epoch 181/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 1.9228 - val_loss: 2.4549\n",
            "Epoch 182/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.9243 - val_loss: 2.6298\n",
            "Epoch 183/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.9041 - val_loss: 2.4979\n",
            "Epoch 184/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 1.9017 - val_loss: 2.4553\n",
            "Epoch 185/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.9016 - val_loss: 2.4428\n",
            "Epoch 186/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.9183 - val_loss: 2.4420\n",
            "Epoch 187/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.8546 - val_loss: 2.4499\n",
            "Epoch 188/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.9100 - val_loss: 2.4180\n",
            "Epoch 189/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.9012 - val_loss: 2.6481\n",
            "Epoch 190/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 1.9479 - val_loss: 2.4715\n",
            "Epoch 191/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 1.8482 - val_loss: 2.4836\n",
            "Epoch 192/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.8170 - val_loss: 2.5375\n",
            "Epoch 193/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.8602 - val_loss: 2.4330\n",
            "Epoch 194/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 1.8552 - val_loss: 2.4332\n",
            "Epoch 195/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.8564 - val_loss: 2.3677\n",
            "Epoch 196/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 1.7925 - val_loss: 2.3972\n",
            "Epoch 197/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.8944 - val_loss: 2.4260\n",
            "Epoch 198/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.8328 - val_loss: 2.4871\n",
            "Epoch 199/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.8482 - val_loss: 2.4934\n",
            "Epoch 200/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 1.7911 - val_loss: 2.3993\n",
            "Epoch 201/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 1.8199 - val_loss: 2.3884\n",
            "Epoch 202/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 1.7906 - val_loss: 2.4819\n",
            "Epoch 203/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.8097 - val_loss: 2.4223\n",
            "Epoch 204/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 1.8171 - val_loss: 2.3094\n",
            "Epoch 205/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.7967 - val_loss: 2.5775\n",
            "Epoch 206/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.7927 - val_loss: 2.3482\n",
            "Epoch 207/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.7711 - val_loss: 2.5697\n",
            "Epoch 208/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.7659 - val_loss: 2.3747\n",
            "Epoch 209/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.7527 - val_loss: 2.3593\n",
            "Epoch 210/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.7710 - val_loss: 2.3449\n",
            "Epoch 211/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 1.8142 - val_loss: 2.3262\n",
            "Epoch 212/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 1.7254 - val_loss: 2.3587\n",
            "Epoch 213/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.7455 - val_loss: 2.6786\n",
            "Epoch 214/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.7605 - val_loss: 2.5347\n",
            "Epoch 215/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.8803 - val_loss: 2.2971\n",
            "Epoch 216/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.7836 - val_loss: 2.3902\n",
            "Epoch 217/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 1.8113 - val_loss: 2.4293\n",
            "Epoch 218/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.7070 - val_loss: 2.4268\n",
            "Epoch 219/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.6926 - val_loss: 2.4130\n",
            "Epoch 220/1000\n",
            "30000/30000 [==============================] - 1s 48us/step - loss: 1.7479 - val_loss: 2.5352\n",
            "Epoch 221/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 1.7632 - val_loss: 2.3152\n",
            "Epoch 222/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.7711 - val_loss: 2.3801\n",
            "Epoch 223/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 1.6996 - val_loss: 2.3388\n",
            "Epoch 224/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 1.7235 - val_loss: 2.4076\n",
            "Epoch 225/1000\n",
            "30000/30000 [==============================] - 1s 50us/step - loss: 1.7000 - val_loss: 2.3660\n",
            "Epoch 226/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.6980 - val_loss: 2.3543\n",
            "Epoch 227/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.7023 - val_loss: 2.3422\n",
            "Epoch 228/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.7624 - val_loss: 2.3482\n",
            "Epoch 229/1000\n",
            "30000/30000 [==============================] - 1s 49us/step - loss: 1.7776 - val_loss: 2.4114\n",
            "Epoch 230/1000\n",
            "30000/30000 [==============================] - 2s 50us/step - loss: 1.7306 - val_loss: 2.5265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO7MBwRX-F9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36a50754-f205-493a-f70f-c24c39f31330"
      },
      "source": [
        "neg_model1 = train_model(model_constructor=model_arch1,\n",
        "                         X_train=onehot_data[indices_train],\n",
        "                         y_train=neg_labels[indices_train],\n",
        "                         X_valid=onehot_data[indices_val],\n",
        "                         y_valid=neg_labels[indices_val],\n",
        "                         seed=1234)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_9 (Conv1D)            (None, 94, 15)            435       \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 88, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 82, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_12 (Conv1D)           (None, 76, 15)            1590      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_3 ( (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 50)                800       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 8,606\n",
            "Trainable params: 8,606\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 30000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "30000/30000 [==============================] - 2s 65us/step - loss: 126.7428 - val_loss: 77.4460\n",
            "Epoch 2/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 75.9200 - val_loss: 69.6513\n",
            "Epoch 3/1000\n",
            "30000/30000 [==============================] - 2s 53us/step - loss: 65.5094 - val_loss: 54.5786\n",
            "Epoch 4/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 46.4380 - val_loss: 37.9086\n",
            "Epoch 5/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 34.6754 - val_loss: 30.2154\n",
            "Epoch 6/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 28.9949 - val_loss: 26.4997\n",
            "Epoch 7/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 25.4363 - val_loss: 24.8192\n",
            "Epoch 8/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 23.2726 - val_loss: 21.4692\n",
            "Epoch 9/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 21.2086 - val_loss: 19.9846\n",
            "Epoch 10/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 20.0834 - val_loss: 23.3264\n",
            "Epoch 11/1000\n",
            "30000/30000 [==============================] - 2s 53us/step - loss: 18.9380 - val_loss: 18.1752\n",
            "Epoch 12/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 17.6263 - val_loss: 16.5572\n",
            "Epoch 13/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 16.4571 - val_loss: 15.8850\n",
            "Epoch 14/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 15.1898 - val_loss: 16.3392\n",
            "Epoch 15/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 14.0774 - val_loss: 13.7780\n",
            "Epoch 16/1000\n",
            "30000/30000 [==============================] - 2s 53us/step - loss: 12.8837 - val_loss: 12.9522\n",
            "Epoch 17/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 11.7269 - val_loss: 11.1906\n",
            "Epoch 18/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 10.7714 - val_loss: 10.4887\n",
            "Epoch 19/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 10.0698 - val_loss: 9.8933\n",
            "Epoch 20/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 9.6337 - val_loss: 9.7291\n",
            "Epoch 21/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 9.0999 - val_loss: 8.9772\n",
            "Epoch 22/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 8.6818 - val_loss: 8.7158\n",
            "Epoch 23/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 8.3544 - val_loss: 8.2040\n",
            "Epoch 24/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 7.9444 - val_loss: 7.9561\n",
            "Epoch 25/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 7.6553 - val_loss: 7.8134\n",
            "Epoch 26/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 7.5349 - val_loss: 7.8138\n",
            "Epoch 27/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 7.0920 - val_loss: 6.9948\n",
            "Epoch 28/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 6.8884 - val_loss: 6.7758\n",
            "Epoch 29/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 6.6704 - val_loss: 6.6354\n",
            "Epoch 30/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 6.3532 - val_loss: 6.3606\n",
            "Epoch 31/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 6.1074 - val_loss: 6.1069\n",
            "Epoch 32/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 5.8812 - val_loss: 5.9378\n",
            "Epoch 33/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 5.7890 - val_loss: 5.8425\n",
            "Epoch 34/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 5.6586 - val_loss: 5.8600\n",
            "Epoch 35/1000\n",
            "30000/30000 [==============================] - 2s 58us/step - loss: 5.3612 - val_loss: 5.8435\n",
            "Epoch 36/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 5.2727 - val_loss: 5.8711\n",
            "Epoch 37/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 5.1067 - val_loss: 5.5056\n",
            "Epoch 38/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 4.8885 - val_loss: 5.2625\n",
            "Epoch 39/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 4.8027 - val_loss: 5.4516\n",
            "Epoch 40/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 4.8024 - val_loss: 4.8933\n",
            "Epoch 41/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 4.5554 - val_loss: 4.7462\n",
            "Epoch 42/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 4.5072 - val_loss: 4.8246\n",
            "Epoch 43/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 4.3555 - val_loss: 4.8035\n",
            "Epoch 44/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 4.3061 - val_loss: 4.4063\n",
            "Epoch 45/1000\n",
            "30000/30000 [==============================] - 2s 54us/step - loss: 4.1076 - val_loss: 4.5954\n",
            "Epoch 46/1000\n",
            "30000/30000 [==============================] - 2s 54us/step - loss: 3.9874 - val_loss: 4.4391\n",
            "Epoch 47/1000\n",
            "30000/30000 [==============================] - 2s 54us/step - loss: 3.8872 - val_loss: 4.3451\n",
            "Epoch 48/1000\n",
            "30000/30000 [==============================] - 2s 54us/step - loss: 3.7763 - val_loss: 4.3097\n",
            "Epoch 49/1000\n",
            "30000/30000 [==============================] - 2s 54us/step - loss: 3.7418 - val_loss: 3.9598\n",
            "Epoch 50/1000\n",
            "30000/30000 [==============================] - 2s 54us/step - loss: 3.6442 - val_loss: 3.8559\n",
            "Epoch 51/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 3.5420 - val_loss: 3.9661\n",
            "Epoch 52/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 3.4564 - val_loss: 3.9385\n",
            "Epoch 53/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 3.4735 - val_loss: 3.6599\n",
            "Epoch 54/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 3.3407 - val_loss: 3.6375\n",
            "Epoch 55/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 3.3462 - val_loss: 3.5246\n",
            "Epoch 56/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 3.1336 - val_loss: 3.4860\n",
            "Epoch 57/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 3.1732 - val_loss: 3.6308\n",
            "Epoch 58/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 3.0561 - val_loss: 3.4448\n",
            "Epoch 59/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 3.0009 - val_loss: 3.3205\n",
            "Epoch 60/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.9643 - val_loss: 3.2055\n",
            "Epoch 61/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.8968 - val_loss: 3.5062\n",
            "Epoch 62/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.8273 - val_loss: 3.1224\n",
            "Epoch 63/1000\n",
            "30000/30000 [==============================] - 2s 53us/step - loss: 2.8278 - val_loss: 3.0703\n",
            "Epoch 64/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.7209 - val_loss: 3.0657\n",
            "Epoch 65/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.6661 - val_loss: 3.0474\n",
            "Epoch 66/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.6680 - val_loss: 2.9232\n",
            "Epoch 67/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.6381 - val_loss: 2.8429\n",
            "Epoch 68/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.6390 - val_loss: 2.8660\n",
            "Epoch 69/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.5326 - val_loss: 2.8048\n",
            "Epoch 70/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.4939 - val_loss: 2.9501\n",
            "Epoch 71/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.4539 - val_loss: 2.7375\n",
            "Epoch 72/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.4405 - val_loss: 2.7494\n",
            "Epoch 73/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.3741 - val_loss: 2.7636\n",
            "Epoch 74/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.4592 - val_loss: 2.8007\n",
            "Epoch 75/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.3961 - val_loss: 2.7060\n",
            "Epoch 76/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.3761 - val_loss: 2.8866\n",
            "Epoch 77/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.2882 - val_loss: 2.6222\n",
            "Epoch 78/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.3696 - val_loss: 2.6095\n",
            "Epoch 79/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.2670 - val_loss: 2.5368\n",
            "Epoch 80/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.2321 - val_loss: 2.5618\n",
            "Epoch 81/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.2730 - val_loss: 2.4899\n",
            "Epoch 82/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.2140 - val_loss: 2.5313\n",
            "Epoch 83/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.2250 - val_loss: 2.5649\n",
            "Epoch 84/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.1736 - val_loss: 2.4545\n",
            "Epoch 85/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.2784 - val_loss: 2.5328\n",
            "Epoch 86/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.1500 - val_loss: 2.4486\n",
            "Epoch 87/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.1313 - val_loss: 2.3854\n",
            "Epoch 88/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.1546 - val_loss: 2.4352\n",
            "Epoch 89/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.1568 - val_loss: 2.3770\n",
            "Epoch 90/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.0671 - val_loss: 2.4570\n",
            "Epoch 91/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.1104 - val_loss: 2.4605\n",
            "Epoch 92/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.1195 - val_loss: 2.3829\n",
            "Epoch 93/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.0537 - val_loss: 2.3981\n",
            "Epoch 94/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.0678 - val_loss: 2.4195\n",
            "Epoch 95/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.0155 - val_loss: 2.4380\n",
            "Epoch 96/1000\n",
            "30000/30000 [==============================] - 2s 54us/step - loss: 2.0070 - val_loss: 2.3194\n",
            "Epoch 97/1000\n",
            "30000/30000 [==============================] - 2s 54us/step - loss: 2.0282 - val_loss: 2.5862\n",
            "Epoch 98/1000\n",
            "30000/30000 [==============================] - 2s 54us/step - loss: 2.0403 - val_loss: 2.2767\n",
            "Epoch 99/1000\n",
            "30000/30000 [==============================] - 2s 53us/step - loss: 1.9992 - val_loss: 2.3427\n",
            "Epoch 100/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 1.9993 - val_loss: 2.3011\n",
            "Epoch 101/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 1.9902 - val_loss: 2.4745\n",
            "Epoch 102/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.0056 - val_loss: 2.3185\n",
            "Epoch 103/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 2.0228 - val_loss: 2.2916\n",
            "Epoch 104/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 2.0344 - val_loss: 2.3262\n",
            "Epoch 105/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.9495 - val_loss: 2.2137\n",
            "Epoch 106/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.9505 - val_loss: 2.2536\n",
            "Epoch 107/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.9292 - val_loss: 2.3398\n",
            "Epoch 108/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.9658 - val_loss: 2.4698\n",
            "Epoch 109/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.9022 - val_loss: 2.1941\n",
            "Epoch 110/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.8848 - val_loss: 2.2270\n",
            "Epoch 111/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.9554 - val_loss: 2.3909\n",
            "Epoch 112/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 1.8967 - val_loss: 2.2078\n",
            "Epoch 113/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.8457 - val_loss: 2.2645\n",
            "Epoch 114/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.8749 - val_loss: 2.2293\n",
            "Epoch 115/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.8648 - val_loss: 2.2519\n",
            "Epoch 116/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.8803 - val_loss: 2.2797\n",
            "Epoch 117/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.8896 - val_loss: 2.1961\n",
            "Epoch 118/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 1.8691 - val_loss: 2.2720\n",
            "Epoch 119/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.8160 - val_loss: 2.5588\n",
            "Epoch 120/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.8529 - val_loss: 2.1642\n",
            "Epoch 121/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.8500 - val_loss: 2.1045\n",
            "Epoch 122/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 1.7868 - val_loss: 2.3634\n",
            "Epoch 123/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.7891 - val_loss: 2.1116\n",
            "Epoch 124/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.7969 - val_loss: 2.5254\n",
            "Epoch 125/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.7921 - val_loss: 2.1213\n",
            "Epoch 126/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.8067 - val_loss: 2.0597\n",
            "Epoch 127/1000\n",
            "30000/30000 [==============================] - 2s 51us/step - loss: 1.7723 - val_loss: 2.0427\n",
            "Epoch 128/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.7993 - val_loss: 2.0738\n",
            "Epoch 129/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.7706 - val_loss: 2.0894\n",
            "Epoch 130/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.7334 - val_loss: 2.1565\n",
            "Epoch 131/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.7352 - val_loss: 2.2028\n",
            "Epoch 132/1000\n",
            "30000/30000 [==============================] - 2s 53us/step - loss: 1.7515 - val_loss: 2.0968\n",
            "Epoch 133/1000\n",
            "30000/30000 [==============================] - 2s 53us/step - loss: 1.7350 - val_loss: 2.0717\n",
            "Epoch 134/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.7545 - val_loss: 2.1057\n",
            "Epoch 135/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.7207 - val_loss: 2.0962\n",
            "Epoch 136/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.7517 - val_loss: 2.2499\n",
            "Epoch 137/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.7346 - val_loss: 2.3809\n",
            "Epoch 138/1000\n",
            "30000/30000 [==============================] - 2s 53us/step - loss: 1.7665 - val_loss: 2.1358\n",
            "Epoch 139/1000\n",
            "30000/30000 [==============================] - 2s 53us/step - loss: 1.7110 - val_loss: 2.2065\n",
            "Epoch 140/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.7284 - val_loss: 2.0517\n",
            "Epoch 141/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.7652 - val_loss: 2.1052\n",
            "Epoch 142/1000\n",
            "30000/30000 [==============================] - 2s 52us/step - loss: 1.7227 - val_loss: 2.2545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpHDqwOo69xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_model1_preds_test = pos_model1.predict(X_test)\n",
        "neg_model1_preds_test = neg_model1.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUyxcc1y7CTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "9a106fe4-634d-4fa4-aeb2-9f7ce2c7622a"
      },
      "source": [
        "def inverse_anscombe_transform(vals):\n",
        "  return np.square(vals/2.0) - 3.0/8\n",
        "\n",
        "def inv_anscombe_plot(x, y):\n",
        "  inv_x = inverse_anscombe_transform(x)\n",
        "  inv_y = inverse_anscombe_transform(y)\n",
        "  plt.plot(inv_x, inv_x, color=\"black\")\n",
        "  plt.scatter(inv_x, inv_y)\n",
        "  plt.show()\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "print(\"Positive control model:\")\n",
        "inv_anscombe_plot(pos_model1_preds_test, oracle_test_pos)\n",
        "\n",
        "print(\"Negative control model:\")\n",
        "inv_anscombe_plot(neg_model1_preds_test, oracle_test_neg)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive control model:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Negative control model:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wGfK1VW7SbC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7aef6056-c6a7-4b3a-be8e-7168d9cce545"
      },
      "source": [
        "import string\n",
        "import random\n",
        "\n",
        "barcode = ''.join(random.choice(string.ascii_lowercase) for i in range(5))\n",
        "print(barcode)\n",
        "pos_model1.save(\"pos_model1_\"+barcode+\".h5\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cesjm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTSsnf7AAJWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9c13c6a8-43b2-4e71-c3ee-45587640f316"
      },
      "source": [
        "barcode = ''.join(random.choice(string.ascii_lowercase) for i in range(5))\n",
        "print(barcode)\n",
        "neg_model1.save(\"neg_model1_\"+barcode+\".h5\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dlfym\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Pchhjs8SY5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "3a0a1208-7cfe-4c6f-86f6-aa171cd19674"
      },
      "source": [
        "!du -hs *"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1M\tneg_labels.txt\n",
            "152K\tneg_model1_dlfym.h5\n",
            "1.1M\tpos_labels.txt\n",
            "152K\tpos_model1_cesjm.h5\n",
            "55M\tsample_data\n",
            "7.4M\tsimulation.simdata\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4fzo8kb9fMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}