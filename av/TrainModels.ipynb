{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainModels.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOWxrf/cFMI2Yx1qG3t01mt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kundajelab/mfinkels_work/blob/master/av/TrainModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy6uELUUxZpx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fc550931-b051-4c21-bdf2-ba5b11eb7876"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikdAjY7YxzBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61a5fca1-f95b-4b9d-fac0-517da7a75e5d"
      },
      "source": [
        "#download raw data\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/train_simulation.simdata.gz\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/train_neg_labels.txt.gz\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/train_pos_labels.txt.gz\n",
        "\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/test_simulation.simdata.gz\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/test_neg_labels.txt.gz\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/test_pos_labels.txt.gz\n",
        "\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/toanalyze_orig_seqs.txt.gz\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/toanalyze_taloff_seqs.txt.gz\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/toanalyze_gataoff_seqs.txt.gz\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/toanalyze_bothoff_seqs.txt.gz\n",
        "\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/shuff_toanalyze_orig_seqs.txt.gz\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/shuff_toanalyze_taloff_seqs.txt.gz\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/shuff_toanalyze_gataoff_seqs.txt.gz\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/shuff_toanalyze_bothoff_seqs.txt.gz\n",
        "\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/toanalyze_orig_neg_labels.txt.gz\n",
        "!wget https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/toanalyze_orig_pos_labels.txt.gz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-18 21:30:23--  https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/train_simulation.simdata.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/train_simulation.simdata.gz [following]\n",
            "--2020-05-18 21:30:23--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/train_simulation.simdata.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2104123 (2.0M) [application/octet-stream]\n",
            "Saving to: ‘train_simulation.simdata.gz’\n",
            "\n",
            "\r          train_sim   0%[                    ]       0  --.-KB/s               \rtrain_simulation.si 100%[===================>]   2.01M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2020-05-18 21:30:24 (22.0 MB/s) - ‘train_simulation.simdata.gz’ saved [2104123/2104123]\n",
            "\n",
            "--2020-05-18 21:30:26--  https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/train_neg_labels.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/train_neg_labels.txt.gz [following]\n",
            "--2020-05-18 21:30:26--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/train_neg_labels.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 523531 (511K) [application/octet-stream]\n",
            "Saving to: ‘train_neg_labels.txt.gz’\n",
            "\n",
            "train_neg_labels.tx 100%[===================>] 511.26K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-05-18 21:30:26 (16.9 MB/s) - ‘train_neg_labels.txt.gz’ saved [523531/523531]\n",
            "\n",
            "--2020-05-18 21:30:28--  https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/train_pos_labels.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/train_pos_labels.txt.gz [following]\n",
            "--2020-05-18 21:30:28--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/train_pos_labels.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 518850 (507K) [application/octet-stream]\n",
            "Saving to: ‘train_pos_labels.txt.gz’\n",
            "\n",
            "train_pos_labels.tx 100%[===================>] 506.69K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-05-18 21:30:29 (13.9 MB/s) - ‘train_pos_labels.txt.gz’ saved [518850/518850]\n",
            "\n",
            "--2020-05-18 21:30:30--  https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/test_simulation.simdata.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/test_simulation.simdata.gz [following]\n",
            "--2020-05-18 21:30:31--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/test_simulation.simdata.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2103069 (2.0M) [application/octet-stream]\n",
            "Saving to: ‘test_simulation.simdata.gz’\n",
            "\n",
            "test_simulation.sim 100%[===================>]   2.00M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2020-05-18 21:30:31 (21.3 MB/s) - ‘test_simulation.simdata.gz’ saved [2103069/2103069]\n",
            "\n",
            "--2020-05-18 21:30:32--  https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/test_neg_labels.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/test_neg_labels.txt.gz [following]\n",
            "--2020-05-18 21:30:33--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/test_neg_labels.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 523456 (511K) [application/octet-stream]\n",
            "Saving to: ‘test_neg_labels.txt.gz’\n",
            "\n",
            "test_neg_labels.txt 100%[===================>] 511.19K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-05-18 21:30:33 (13.1 MB/s) - ‘test_neg_labels.txt.gz’ saved [523456/523456]\n",
            "\n",
            "--2020-05-18 21:30:35--  https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/test_pos_labels.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/test_pos_labels.txt.gz [following]\n",
            "--2020-05-18 21:30:35--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/test_pos_labels.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 518815 (507K) [application/octet-stream]\n",
            "Saving to: ‘test_pos_labels.txt.gz’\n",
            "\n",
            "test_pos_labels.txt 100%[===================>] 506.66K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-05-18 21:30:36 (13.8 MB/s) - ‘test_pos_labels.txt.gz’ saved [518815/518815]\n",
            "\n",
            "--2020-05-18 21:30:37--  https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/toanalyze_orig_seqs.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/toanalyze_orig_seqs.txt.gz [following]\n",
            "--2020-05-18 21:30:37--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/toanalyze_orig_seqs.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 303379 (296K) [application/octet-stream]\n",
            "Saving to: ‘toanalyze_orig_seqs.txt.gz’\n",
            "\n",
            "toanalyze_orig_seqs 100%[===================>] 296.27K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-05-18 21:30:38 (10.6 MB/s) - ‘toanalyze_orig_seqs.txt.gz’ saved [303379/303379]\n",
            "\n",
            "--2020-05-18 21:30:40--  https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/toanalyze_taloff_seqs.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/toanalyze_taloff_seqs.txt.gz [following]\n",
            "--2020-05-18 21:30:40--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/toanalyze_taloff_seqs.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 307524 (300K) [application/octet-stream]\n",
            "Saving to: ‘toanalyze_taloff_seqs.txt.gz’\n",
            "\n",
            "toanalyze_taloff_se 100%[===================>] 300.32K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-05-18 21:30:45 (12.5 MB/s) - ‘toanalyze_taloff_seqs.txt.gz’ saved [307524/307524]\n",
            "\n",
            "--2020-05-18 21:30:46--  https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/toanalyze_gataoff_seqs.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/toanalyze_gataoff_seqs.txt.gz [following]\n",
            "--2020-05-18 21:30:47--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/toanalyze_gataoff_seqs.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 306247 (299K) [application/octet-stream]\n",
            "Saving to: ‘toanalyze_gataoff_seqs.txt.gz’\n",
            "\n",
            "toanalyze_gataoff_s 100%[===================>] 299.07K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-05-18 21:30:47 (12.7 MB/s) - ‘toanalyze_gataoff_seqs.txt.gz’ saved [306247/306247]\n",
            "\n",
            "--2020-05-18 21:30:49--  https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/toanalyze_bothoff_seqs.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/toanalyze_bothoff_seqs.txt.gz [following]\n",
            "--2020-05-18 21:30:49--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/toanalyze_bothoff_seqs.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 310058 (303K) [application/octet-stream]\n",
            "Saving to: ‘toanalyze_bothoff_seqs.txt.gz’\n",
            "\n",
            "toanalyze_bothoff_s 100%[===================>] 302.79K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-05-18 21:30:49 (12.6 MB/s) - ‘toanalyze_bothoff_seqs.txt.gz’ saved [310058/310058]\n",
            "\n",
            "--2020-05-18 21:30:51--  https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/shuff_toanalyze_orig_seqs.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/shuff_toanalyze_orig_seqs.txt.gz [following]\n",
            "--2020-05-18 21:30:51--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/shuff_toanalyze_orig_seqs.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 309688 (302K) [application/octet-stream]\n",
            "Saving to: ‘shuff_toanalyze_orig_seqs.txt.gz’\n",
            "\n",
            "shuff_toanalyze_ori 100%[===================>] 302.43K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-05-18 21:30:51 (11.3 MB/s) - ‘shuff_toanalyze_orig_seqs.txt.gz’ saved [309688/309688]\n",
            "\n",
            "--2020-05-18 21:30:53--  https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/shuff_toanalyze_taloff_seqs.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/shuff_toanalyze_taloff_seqs.txt.gz [following]\n",
            "--2020-05-18 21:30:53--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/shuff_toanalyze_taloff_seqs.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 309840 (303K) [application/octet-stream]\n",
            "Saving to: ‘shuff_toanalyze_taloff_seqs.txt.gz’\n",
            "\n",
            "shuff_toanalyze_tal 100%[===================>] 302.58K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-05-18 21:30:53 (12.8 MB/s) - ‘shuff_toanalyze_taloff_seqs.txt.gz’ saved [309840/309840]\n",
            "\n",
            "--2020-05-18 21:30:55--  https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/shuff_toanalyze_gataoff_seqs.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/shuff_toanalyze_gataoff_seqs.txt.gz [following]\n",
            "--2020-05-18 21:30:55--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/shuff_toanalyze_gataoff_seqs.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 309807 (303K) [application/octet-stream]\n",
            "Saving to: ‘shuff_toanalyze_gataoff_seqs.txt.gz’\n",
            "\n",
            "shuff_toanalyze_gat 100%[===================>] 302.55K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-05-18 21:30:55 (11.1 MB/s) - ‘shuff_toanalyze_gataoff_seqs.txt.gz’ saved [309807/309807]\n",
            "\n",
            "--2020-05-18 21:30:56--  https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/shuff_toanalyze_bothoff_seqs.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/shuff_toanalyze_bothoff_seqs.txt.gz [following]\n",
            "--2020-05-18 21:30:57--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/shuff_toanalyze_bothoff_seqs.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 310130 (303K) [application/octet-stream]\n",
            "Saving to: ‘shuff_toanalyze_bothoff_seqs.txt.gz’\n",
            "\n",
            "shuff_toanalyze_bot 100%[===================>] 302.86K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-05-18 21:30:57 (11.9 MB/s) - ‘shuff_toanalyze_bothoff_seqs.txt.gz’ saved [310130/310130]\n",
            "\n",
            "--2020-05-18 21:30:59--  https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/toanalyze_orig_neg_labels.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/toanalyze_orig_neg_labels.txt.gz [following]\n",
            "--2020-05-18 21:30:59--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/toanalyze_orig_neg_labels.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9270 (9.1K) [application/octet-stream]\n",
            "Saving to: ‘toanalyze_orig_neg_labels.txt.gz’\n",
            "\n",
            "toanalyze_orig_neg_ 100%[===================>]   9.05K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-18 21:30:59 (81.3 MB/s) - ‘toanalyze_orig_neg_labels.txt.gz’ saved [9270/9270]\n",
            "\n",
            "--2020-05-18 21:31:00--  https://github.com/kundajelab/mfinkels_work/raw/f761fd8/av/data/toanalyze_orig_pos_labels.txt.gz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/toanalyze_orig_pos_labels.txt.gz [following]\n",
            "--2020-05-18 21:31:00--  https://raw.githubusercontent.com/kundajelab/mfinkels_work/f761fd8182c19931c16f7e3a5e562394dce443d2/av/data/toanalyze_orig_pos_labels.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9578 (9.4K) [application/octet-stream]\n",
            "Saving to: ‘toanalyze_orig_pos_labels.txt.gz’\n",
            "\n",
            "toanalyze_orig_pos_ 100%[===================>]   9.35K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-18 21:31:01 (87.3 MB/s) - ‘toanalyze_orig_pos_labels.txt.gz’ saved [9578/9578]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ-uVDc2tO38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gunzip *.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhBwM80nyOa8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "70ee1254-6ae5-4ac6-dca4-33e6a7b77e61"
      },
      "source": [
        "!md5sum *"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "md5sum: sample_data: Is a directory\n",
            "7aec491810595eee1a70edaa43354eec  shuff_toanalyze_bothoff_seqs.txt\n",
            "b7f652ab8b30085bb44ae2c43a9815e1  shuff_toanalyze_gataoff_seqs.txt\n",
            "a71a6c32db0e3496734a185dc67d7003  shuff_toanalyze_orig_seqs.txt\n",
            "3ea4e8b99ea51a7e47636e320aa286f7  shuff_toanalyze_taloff_seqs.txt\n",
            "0bca4454a44d8dd25d7c64faae57a8ec  test_neg_labels.txt\n",
            "292a1b03299bf7877bbc70746112d7bd  test_pos_labels.txt\n",
            "85c3688d157254921f64904e71c0372c  test_simulation.simdata\n",
            "b129a9fad60d95fc38ec69fe51c8c144  toanalyze_bothoff_seqs.txt\n",
            "7e4c3044fa2c84a8ba41b8b828d8c90b  toanalyze_gataoff_seqs.txt\n",
            "d0a47bd6481a15db2f0d489e79b19cd1  toanalyze_orig_neg_labels.txt\n",
            "71daa8ed7c814a7a0e8c495d955a27d1  toanalyze_orig_pos_labels.txt\n",
            "69c5b9185c7cfda888fee7f8884bdc2d  toanalyze_orig_seqs.txt\n",
            "b0131719a04dc89bb584fc24754078aa  toanalyze_taloff_seqs.txt\n",
            "1f2ddf5f3a74e3db548c5d2180d29a45  train_neg_labels.txt\n",
            "262ca284f5f8676b16c8bf92047cfe70  train_pos_labels.txt\n",
            "fb82dd3c7dc4b53d34b4fd456394de42  train_simulation.simdata\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBtXarlUynn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "98f6b974-22c3-4386-85ce-146e653117e2"
      },
      "source": [
        "!pip install simdna"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting simdna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/c6/dc6cc2e9ac09c85d5ec6d896c6c43c8dd5ef50bb9c14423e9290131dce27/simdna-0.4.3.2.tar.gz (634kB)\n",
            "\r\u001b[K     |▌                               | 10kB 19.6MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 4.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 5.5MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 5.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51kB 4.9MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 5.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 5.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81kB 6.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 112kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 143kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 153kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 174kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 184kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 204kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 215kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 225kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 235kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 245kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 256kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 266kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 286kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 307kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 327kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 337kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 348kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 358kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 368kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 389kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 399kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 409kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 419kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 430kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 440kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 450kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 460kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 471kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 481kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 491kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 501kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 512kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 522kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 532kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 542kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 552kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 563kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 573kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 583kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 593kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 604kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 614kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 624kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 634kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.6/dist-packages (from simdna) (1.18.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from simdna) (3.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from simdna) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->simdna) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->simdna) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->simdna) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->simdna) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->simdna) (1.12.0)\n",
            "Building wheels for collected packages: simdna\n",
            "  Building wheel for simdna (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for simdna\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for simdna\n",
            "Failed to build simdna\n",
            "Installing collected packages: simdna\n",
            "    Running setup.py install for simdna ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed simdna-0.4.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a-rv5JUzGhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import simdna\n",
        "from simdna import synthetic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDo9TZkQzKCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = synthetic.read_simdata_file(\"train_simulation.simdata\")\n",
        "test_data = synthetic.read_simdata_file(\"test_simulation.simdata\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMQPKHf1zL-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "#this is set up for 1d convolutions where examples\n",
        "#have dimensions (len, num_channels) \n",
        "#the channel axis is the axis for one-hot encoding.\n",
        "def one_hot_encode_along_channel_axis(sequence):\n",
        "    to_return = np.zeros((len(sequence),4), dtype=np.int8)\n",
        "    seq_to_one_hot_fill_in_array(zeros_array=to_return,\n",
        "                                 sequence=sequence, one_hot_axis=1)\n",
        "    return to_return\n",
        "\n",
        "\n",
        "def seq_to_one_hot_fill_in_array(zeros_array, sequence, one_hot_axis):\n",
        "    assert one_hot_axis==0 or one_hot_axis==1\n",
        "    if (one_hot_axis==0):\n",
        "        assert zeros_array.shape[1] == len(sequence)\n",
        "    elif (one_hot_axis==1): \n",
        "        assert zeros_array.shape[0] == len(sequence)\n",
        "    #will mutate zeros_array\n",
        "    for (i,char) in enumerate(sequence):\n",
        "        if (char==\"A\" or char==\"a\"):\n",
        "            char_idx = 0\n",
        "        elif (char==\"C\" or char==\"c\"):\n",
        "            char_idx = 1\n",
        "        elif (char==\"G\" or char==\"g\"):\n",
        "            char_idx = 2\n",
        "        elif (char==\"T\" or char==\"t\"):\n",
        "            char_idx = 3\n",
        "        elif (char==\"N\" or char==\"n\"):\n",
        "            continue #leave that pos as all 0's\n",
        "        else:\n",
        "            raise RuntimeError(\"Unsupported character: \"+str(char))\n",
        "        if (one_hot_axis==0):\n",
        "            zeros_array[char_idx,i] = 1\n",
        "        elif (one_hot_axis==1):\n",
        "            zeros_array[i,char_idx] = 1\n",
        "\n",
        "\n",
        "def anscombe_transform(vals):\n",
        "  return 2*np.sqrt(vals + 3.0/8)\n",
        "\n",
        "\n",
        "def inverse_anscombe_transform(vals):\n",
        "  return np.square(vals/2.0) - 3.0/8\n",
        "\n",
        "\n",
        "def read_labels_and_oracle(filename):\n",
        "  labels = anscombe_transform(np.array([float(x.split(\"\\t\")[0]) for\n",
        "                                          x in open(filename)]))\n",
        "  oracle = anscombe_transform(np.array([float(x.split(\"\\t\")[1]) for\n",
        "                                          x in open(filename)]))\n",
        "  return labels, oracle\n",
        "\n",
        "\n",
        "train_onehot_data = np.array([one_hot_encode_along_channel_axis(seq)\n",
        "                              for seq in train_data.sequences])\n",
        "test_onehot_data = np.array([one_hot_encode_along_channel_axis(seq)\n",
        "                              for seq in test_data.sequences])\n",
        "\n",
        "train_pos_labels, train_pos_oracle =\\\n",
        "  read_labels_and_oracle(\"train_pos_labels.txt\")\n",
        "train_neg_labels, train_neg_oracle =\\\n",
        "  read_labels_and_oracle(\"train_neg_labels.txt\")\n",
        "test_pos_labels, test_pos_oracle =\\\n",
        "  read_labels_and_oracle(\"test_pos_labels.txt\")\n",
        "test_neg_labels, test_neg_oracle =\\\n",
        "  read_labels_and_oracle(\"test_neg_labels.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARK27HEQzqrn",
        "colab_type": "text"
      },
      "source": [
        "Train models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq1mcODizcry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define model architectures\n",
        "\n",
        "import keras\n",
        "import string\n",
        "import random\n",
        "\n",
        "\n",
        "def model_arch1(l1_reg):\n",
        "  model = keras.models.Sequential()\n",
        "  for i in range(4):\n",
        "    added_kwarg = {}\n",
        "    if (i==0):\n",
        "      added_kwarg[\"input_shape\"] = (100,4)\n",
        "    model.add(keras.layers.Conv1D(\n",
        "                filters=15, kernel_size=7, \n",
        "                activation = \"relu\",\n",
        "                kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=keras.regularizers.l1(l1_reg),\n",
        "                **added_kwarg))\n",
        "  model.add(keras.layers.GlobalAveragePooling1D()) \n",
        "  for i in range(2):\n",
        "    model.add(keras.layers.Dense(50, activation=\"relu\",\n",
        "              kernel_initializer=\"he_normal\",\n",
        "              kernel_regularizer=keras.regularizers.l1(l1_reg)))\n",
        "  model.add(keras.layers.Dense(1, activation=\"linear\"))\n",
        "  adam = keras.optimizers.Adam()\n",
        "  model.compile(optimizer=adam, loss=\"mean_squared_error\")\n",
        "  return model\n",
        "\n",
        "\n",
        "def model_arch2(l1_reg):\n",
        "  model = keras.models.Sequential()\n",
        "  for i in range(4):\n",
        "    added_kwarg = {}\n",
        "    if (i==0):\n",
        "      added_kwarg[\"input_shape\"] = (100,4)\n",
        "    model.add(keras.layers.Conv1D(\n",
        "                filters=15, kernel_size=7, \n",
        "                activation = \"relu\",\n",
        "                kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=keras.regularizers.l1(l1_reg),\n",
        "                **added_kwarg))\n",
        "  model.add(keras.layers.GlobalAveragePooling1D()) \n",
        "  for i in range(3):\n",
        "    model.add(keras.layers.Dense(30, activation=\"relu\",\n",
        "              kernel_initializer=\"he_normal\",\n",
        "              kernel_regularizer=keras.regularizers.l1(l1_reg)))\n",
        "  model.add(keras.layers.Dense(1, activation=\"linear\"))\n",
        "  adam = keras.optimizers.Adam()\n",
        "  model.compile(optimizer=adam, loss=\"mean_squared_error\")\n",
        "  return model\n",
        "\n",
        "\n",
        "def model_arch3(l1_reg):\n",
        "  model = keras.models.Sequential()\n",
        "  for i in range(5):\n",
        "    added_kwarg = {}\n",
        "    if (i==0):\n",
        "      added_kwarg[\"input_shape\"] = (100,4)\n",
        "    model.add(keras.layers.Conv1D(\n",
        "                filters=15, kernel_size=5, \n",
        "                activation = \"relu\",\n",
        "                kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=keras.regularizers.l1(l1_reg),\n",
        "                **added_kwarg))\n",
        "  model.add(keras.layers.GlobalAveragePooling1D()) \n",
        "  for i in range(3):\n",
        "    model.add(keras.layers.Dense(30, activation=\"relu\",\n",
        "              kernel_initializer=\"he_normal\",\n",
        "              kernel_regularizer=keras.regularizers.l1(l1_reg)))\n",
        "  model.add(keras.layers.Dense(1, activation=\"linear\"))\n",
        "  adam = keras.optimizers.Adam()\n",
        "  model.compile(optimizer=adam, loss=\"mean_squared_error\")\n",
        "  return model\n",
        "\n",
        "\n",
        "def train_and_save_model(model_constructor, prefix, X_train, y_train,\n",
        "                         X_valid, y_valid, seed):\n",
        "  \n",
        "  barcode = ''.join(random.choice(string.ascii_lowercase) for i in range(5))\n",
        "  np.random.seed(seed)\n",
        "  model = model_constructor()\n",
        "  save_filename = prefix+\"_\"+barcode+\".h5\"\n",
        "  print(\"Training model\", save_filename)\n",
        "  print(model.summary())\n",
        "  model.fit(x=X_train, y=y_train, batch_size=200,\n",
        "            epochs=1000,\n",
        "            validation_data=(X_valid, y_valid),\n",
        "            callbacks=[keras.callbacks.EarlyStopping(\n",
        "                        monitor='val_loss',\n",
        "                        patience=15,\n",
        "                        restore_best_weights=True)])\n",
        "  \n",
        "  print(\"Save file name\", save_filename)\n",
        "  model.save(save_filename)\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9GIVdNb2Zk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "00f55b51-f739-49fb-95da-462c215e9916"
      },
      "source": [
        "#train several models\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIreSCrC374p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3ef67e5c-74b9-42a3-e6a4-8a0681c44eff"
      },
      "source": [
        "!ln -s /content/drive/My\\ Drive/colab_notebook_data/ ."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ln: failed to create symbolic link './colab_notebook_data': File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxMH1hCHDAXb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e774708e-b183-4c7f-ee31-aefc2a355850"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.hist(train_pos_labels, density=True, bins=20)\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ee4yVMX3ISx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d23845d4-f3ce-4a9b-eb6b-12f0dd85374e"
      },
      "source": [
        "#train the models\n",
        "\n",
        "indices_train = np.arange(0, int(0.8 * train_onehot_data.shape[0]))\n",
        "indices_valid = np.arange(int(0.8 * train_onehot_data.shape[0]),\n",
        "                              train_onehot_data.shape[0])\n",
        "\n",
        "SAVEDIR = \"colab_notebook_data/feature_interactions/trained_models\"\n",
        "\n",
        "for seed in [100, 200, 300, 400, 500]:\n",
        "  for model_constructor, archname in [(model_arch1, 'arch1'),\n",
        "                                      (model_arch2, 'arch2'),\n",
        "                                      (model_arch3, 'arch3')]:\n",
        "    for l1_reg in [0.001, 0.0001, 0.0]:\n",
        "      \n",
        "        train_and_save_model(\n",
        "            model_constructor=lambda: model_constructor(l1_reg),\n",
        "            prefix=(SAVEDIR+\"/poscontrol_model-\"+archname\n",
        "                    +\"_l1reg-\"+str(l1_reg)+\"_seed\"+str(seed)),\n",
        "            X_train=train_onehot_data[indices_train],\n",
        "            y_train=train_pos_labels[indices_train],\n",
        "            X_valid=train_onehot_data[indices_valid],\n",
        "            y_valid=train_pos_labels[indices_valid],\n",
        "            seed=seed) #vary the seed for initialization diversity\n",
        "        \n",
        "        model = model_constructor(l1_reg=l1_reg)\n",
        "        train_and_save_model(\n",
        "            model_constructor=lambda: model_constructor(l1_reg),\n",
        "            prefix=(SAVEDIR+\"/negcontrol_model-\"+archname\n",
        "                    +\"_l1reg-\"+str(l1_reg)+\"_seed\"+str(seed)),\n",
        "            X_train=train_onehot_data[indices_train],\n",
        "            y_train=train_neg_labels[indices_train],\n",
        "            X_valid=train_onehot_data[indices_valid],\n",
        "            y_valid=train_neg_labels[indices_valid],\n",
        "            seed=seed) #vary the seed for initialization diversity\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model colab_notebook_data/feature_interactions/trained_models/poscontrol_model-arch1_l1reg-0.001_seed100_hjmju.h5\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_5 (Conv1D)            (None, 94, 15)            435       \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 88, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 82, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 76, 15)            1590      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 50)                800       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 8,606\n",
            "Trainable params: 8,606\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "40000/40000 [==============================] - 2s 60us/step - loss: 104.6028 - val_loss: 77.5416\n",
            "Epoch 2/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 62.1787 - val_loss: 46.6875\n",
            "Epoch 3/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 39.2869 - val_loss: 35.8969\n",
            "Epoch 4/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 30.9614 - val_loss: 28.2792\n",
            "Epoch 5/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 26.3649 - val_loss: 25.2927\n",
            "Epoch 6/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 23.8262 - val_loss: 22.2871\n",
            "Epoch 7/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 21.5439 - val_loss: 20.9181\n",
            "Epoch 8/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 19.7612 - val_loss: 19.8209\n",
            "Epoch 9/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 18.6427 - val_loss: 17.5101\n",
            "Epoch 10/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 16.8674 - val_loss: 16.5094\n",
            "Epoch 11/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 15.6362 - val_loss: 14.8601\n",
            "Epoch 12/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 14.4212 - val_loss: 13.6043\n",
            "Epoch 13/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 13.1322 - val_loss: 12.8779\n",
            "Epoch 14/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 11.7910 - val_loss: 11.0422\n",
            "Epoch 15/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 10.3845 - val_loss: 10.3861\n",
            "Epoch 16/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 9.5175 - val_loss: 9.1937\n",
            "Epoch 17/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 9.0220 - val_loss: 8.6717\n",
            "Epoch 18/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 8.5344 - val_loss: 8.4841\n",
            "Epoch 19/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 8.1366 - val_loss: 8.0609\n",
            "Epoch 20/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 7.6267 - val_loss: 7.5411\n",
            "Epoch 21/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 7.3396 - val_loss: 7.3234\n",
            "Epoch 22/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 7.0646 - val_loss: 6.8756\n",
            "Epoch 23/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 6.7968 - val_loss: 7.0955\n",
            "Epoch 24/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 6.5344 - val_loss: 6.5055\n",
            "Epoch 25/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 6.3975 - val_loss: 6.0566\n",
            "Epoch 26/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 6.0986 - val_loss: 6.1828\n",
            "Epoch 27/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 5.8668 - val_loss: 5.7388\n",
            "Epoch 28/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 5.6471 - val_loss: 5.5524\n",
            "Epoch 29/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 5.5747 - val_loss: 5.3269\n",
            "Epoch 30/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 5.3751 - val_loss: 5.3998\n",
            "Epoch 31/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 5.2288 - val_loss: 5.1762\n",
            "Epoch 32/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 5.1653 - val_loss: 5.0504\n",
            "Epoch 33/1000\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 4.9408 - val_loss: 5.2049\n",
            "Epoch 34/1000\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 4.8857 - val_loss: 5.1811\n",
            "Epoch 35/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.8265 - val_loss: 4.7310\n",
            "Epoch 36/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.6334 - val_loss: 4.7583\n",
            "Epoch 37/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 4.6344 - val_loss: 4.5062\n",
            "Epoch 38/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 4.4915 - val_loss: 4.4826\n",
            "Epoch 39/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 4.4281 - val_loss: 5.1030\n",
            "Epoch 40/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.3908 - val_loss: 4.4751\n",
            "Epoch 41/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 4.2522 - val_loss: 4.3193\n",
            "Epoch 42/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 4.1284 - val_loss: 4.3346\n",
            "Epoch 43/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 4.0963 - val_loss: 4.1747\n",
            "Epoch 44/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.0794 - val_loss: 4.0803\n",
            "Epoch 45/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.9910 - val_loss: 4.0711\n",
            "Epoch 46/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.9387 - val_loss: 3.9549\n",
            "Epoch 47/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.9183 - val_loss: 4.0376\n",
            "Epoch 48/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.8908 - val_loss: 4.0414\n",
            "Epoch 49/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.8579 - val_loss: 4.4616\n",
            "Epoch 50/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.8104 - val_loss: 4.2457\n",
            "Epoch 51/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.8111 - val_loss: 3.8486\n",
            "Epoch 52/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.7729 - val_loss: 3.8354\n",
            "Epoch 53/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.6975 - val_loss: 3.8044\n",
            "Epoch 54/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.6636 - val_loss: 3.9301\n",
            "Epoch 55/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.6510 - val_loss: 4.8701\n",
            "Epoch 56/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.6095 - val_loss: 3.7975\n",
            "Epoch 57/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.5697 - val_loss: 3.6015\n",
            "Epoch 58/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.5580 - val_loss: 3.6138\n",
            "Epoch 59/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.5501 - val_loss: 3.6423\n",
            "Epoch 60/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.5081 - val_loss: 3.7710\n",
            "Epoch 61/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.5746 - val_loss: 3.7641\n",
            "Epoch 62/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.4580 - val_loss: 3.6494\n",
            "Epoch 63/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.4331 - val_loss: 3.4947\n",
            "Epoch 64/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.3699 - val_loss: 3.4654\n",
            "Epoch 65/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.4666 - val_loss: 3.4454\n",
            "Epoch 66/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.3474 - val_loss: 3.5130\n",
            "Epoch 67/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.3156 - val_loss: 3.5261\n",
            "Epoch 68/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.4194 - val_loss: 3.5371\n",
            "Epoch 69/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.3454 - val_loss: 3.7935\n",
            "Epoch 70/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.2634 - val_loss: 3.3668\n",
            "Epoch 71/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.3638 - val_loss: 3.4002\n",
            "Epoch 72/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.2241 - val_loss: 3.3337\n",
            "Epoch 73/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.2836 - val_loss: 3.4737\n",
            "Epoch 74/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.2821 - val_loss: 3.3712\n",
            "Epoch 75/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.2567 - val_loss: 3.5269\n",
            "Epoch 76/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.2527 - val_loss: 3.6935\n",
            "Epoch 77/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.2072 - val_loss: 3.2621\n",
            "Epoch 78/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.1694 - val_loss: 3.2306\n",
            "Epoch 79/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.1452 - val_loss: 3.2904\n",
            "Epoch 80/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.2277 - val_loss: 3.2692\n",
            "Epoch 81/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 3.1519 - val_loss: 3.2424\n",
            "Epoch 82/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.1279 - val_loss: 3.3259\n",
            "Epoch 83/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.1078 - val_loss: 3.1201\n",
            "Epoch 84/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.1195 - val_loss: 3.2045\n",
            "Epoch 85/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.0793 - val_loss: 3.2054\n",
            "Epoch 86/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.0909 - val_loss: 3.1416\n",
            "Epoch 87/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.0675 - val_loss: 3.2442\n",
            "Epoch 88/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.0893 - val_loss: 3.6050\n",
            "Epoch 89/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.0084 - val_loss: 3.0703\n",
            "Epoch 90/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.0448 - val_loss: 3.2063\n",
            "Epoch 91/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.0237 - val_loss: 3.0355\n",
            "Epoch 92/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.0241 - val_loss: 3.0584\n",
            "Epoch 93/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.0303 - val_loss: 3.0438\n",
            "Epoch 94/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9776 - val_loss: 3.1386\n",
            "Epoch 95/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9938 - val_loss: 3.0966\n",
            "Epoch 96/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9829 - val_loss: 3.1094\n",
            "Epoch 97/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9347 - val_loss: 3.0591\n",
            "Epoch 98/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9843 - val_loss: 3.3375\n",
            "Epoch 99/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.9984 - val_loss: 3.0670\n",
            "Epoch 100/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.9335 - val_loss: 3.1735\n",
            "Epoch 101/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9226 - val_loss: 2.9379\n",
            "Epoch 102/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8948 - val_loss: 2.9633\n",
            "Epoch 103/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9453 - val_loss: 3.0368\n",
            "Epoch 104/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9075 - val_loss: 3.0605\n",
            "Epoch 105/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8861 - val_loss: 3.0407\n",
            "Epoch 106/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8964 - val_loss: 3.0148\n",
            "Epoch 107/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8320 - val_loss: 2.9110\n",
            "Epoch 108/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8415 - val_loss: 2.9842\n",
            "Epoch 109/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.8905 - val_loss: 2.9462\n",
            "Epoch 110/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.8708 - val_loss: 2.9241\n",
            "Epoch 111/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.8270 - val_loss: 3.1398\n",
            "Epoch 112/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.8668 - val_loss: 3.2109\n",
            "Epoch 113/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.8283 - val_loss: 2.8981\n",
            "Epoch 114/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8479 - val_loss: 2.9397\n",
            "Epoch 115/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8863 - val_loss: 3.0358\n",
            "Epoch 116/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.8300 - val_loss: 3.0473\n",
            "Epoch 117/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.7920 - val_loss: 3.6155\n",
            "Epoch 118/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8084 - val_loss: 3.5452\n",
            "Epoch 119/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7877 - val_loss: 2.9428\n",
            "Epoch 120/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.8096 - val_loss: 3.0528\n",
            "Epoch 121/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8014 - val_loss: 2.9539\n",
            "Epoch 122/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7484 - val_loss: 2.8829\n",
            "Epoch 123/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7671 - val_loss: 2.8734\n",
            "Epoch 124/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7968 - val_loss: 2.8388\n",
            "Epoch 125/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.7671 - val_loss: 3.1218\n",
            "Epoch 126/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7564 - val_loss: 2.8446\n",
            "Epoch 127/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7560 - val_loss: 2.8128\n",
            "Epoch 128/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7125 - val_loss: 2.8035\n",
            "Epoch 129/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7348 - val_loss: 3.0702\n",
            "Epoch 130/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7394 - val_loss: 2.8778\n",
            "Epoch 131/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.7172 - val_loss: 2.7717\n",
            "Epoch 132/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6802 - val_loss: 2.8081\n",
            "Epoch 133/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.7045 - val_loss: 2.7730\n",
            "Epoch 134/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6956 - val_loss: 2.8216\n",
            "Epoch 135/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6914 - val_loss: 2.8168\n",
            "Epoch 136/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6791 - val_loss: 2.8083\n",
            "Epoch 137/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6828 - val_loss: 2.8194\n",
            "Epoch 138/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6738 - val_loss: 3.1514\n",
            "Epoch 139/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6462 - val_loss: 2.8504\n",
            "Epoch 140/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6702 - val_loss: 2.8145\n",
            "Epoch 141/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7028 - val_loss: 2.8832\n",
            "Epoch 142/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6690 - val_loss: 3.0367\n",
            "Epoch 143/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6664 - val_loss: 2.7160\n",
            "Epoch 144/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6975 - val_loss: 2.7252\n",
            "Epoch 145/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6129 - val_loss: 2.7371\n",
            "Epoch 146/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6166 - val_loss: 2.8900\n",
            "Epoch 147/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6271 - val_loss: 2.7646\n",
            "Epoch 148/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6731 - val_loss: 2.7361\n",
            "Epoch 149/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6158 - val_loss: 2.9677\n",
            "Epoch 150/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6332 - val_loss: 2.7844\n",
            "Epoch 151/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6358 - val_loss: 2.7625\n",
            "Epoch 152/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6247 - val_loss: 2.6678\n",
            "Epoch 153/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.6721 - val_loss: 2.7925\n",
            "Epoch 154/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5550 - val_loss: 2.7183\n",
            "Epoch 155/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5741 - val_loss: 2.6805\n",
            "Epoch 156/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6097 - val_loss: 2.6665\n",
            "Epoch 157/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5459 - val_loss: 2.6610\n",
            "Epoch 158/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5764 - val_loss: 2.6487\n",
            "Epoch 159/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5956 - val_loss: 2.9714\n",
            "Epoch 160/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5710 - val_loss: 2.7519\n",
            "Epoch 161/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6176 - val_loss: 2.9035\n",
            "Epoch 162/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5839 - val_loss: 2.6275\n",
            "Epoch 163/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5784 - val_loss: 2.7271\n",
            "Epoch 164/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5624 - val_loss: 2.6142\n",
            "Epoch 165/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5563 - val_loss: 2.8555\n",
            "Epoch 166/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5501 - val_loss: 2.6669\n",
            "Epoch 167/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5428 - val_loss: 2.6569\n",
            "Epoch 168/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5478 - val_loss: 2.7425\n",
            "Epoch 169/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5093 - val_loss: 2.6919\n",
            "Epoch 170/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5067 - val_loss: 2.6440\n",
            "Epoch 171/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5479 - val_loss: 2.6511\n",
            "Epoch 172/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5665 - val_loss: 2.5826\n",
            "Epoch 173/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5587 - val_loss: 2.6419\n",
            "Epoch 174/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.5614 - val_loss: 2.6246\n",
            "Epoch 175/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5587 - val_loss: 2.6606\n",
            "Epoch 176/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4959 - val_loss: 2.7490\n",
            "Epoch 177/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5589 - val_loss: 2.6795\n",
            "Epoch 178/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4875 - val_loss: 2.7163\n",
            "Epoch 179/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5256 - val_loss: 2.6630\n",
            "Epoch 180/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5154 - val_loss: 2.6068\n",
            "Epoch 181/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5286 - val_loss: 2.5557\n",
            "Epoch 182/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4826 - val_loss: 2.6783\n",
            "Epoch 183/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5023 - val_loss: 2.6190\n",
            "Epoch 184/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5073 - val_loss: 2.7762\n",
            "Epoch 185/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5490 - val_loss: 2.5811\n",
            "Epoch 186/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4778 - val_loss: 2.6107\n",
            "Epoch 187/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5126 - val_loss: 2.5656\n",
            "Epoch 188/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4827 - val_loss: 2.5474\n",
            "Epoch 189/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4900 - val_loss: 2.6654\n",
            "Epoch 190/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4666 - val_loss: 2.6603\n",
            "Epoch 191/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5044 - val_loss: 2.5870\n",
            "Epoch 192/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4839 - val_loss: 2.5654\n",
            "Epoch 193/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5027 - val_loss: 2.5608\n",
            "Epoch 194/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4348 - val_loss: 2.7753\n",
            "Epoch 195/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4757 - val_loss: 2.6162\n",
            "Epoch 196/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4793 - val_loss: 2.6019\n",
            "Epoch 197/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4287 - val_loss: 2.7815\n",
            "Epoch 198/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4523 - val_loss: 2.5856\n",
            "Epoch 199/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4843 - val_loss: 2.9442\n",
            "Epoch 200/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4554 - val_loss: 2.5300\n",
            "Epoch 201/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4531 - val_loss: 2.6351\n",
            "Epoch 202/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4567 - val_loss: 2.5853\n",
            "Epoch 203/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4051 - val_loss: 2.6564\n",
            "Epoch 204/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4467 - val_loss: 2.7181\n",
            "Epoch 205/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4828 - val_loss: 2.4968\n",
            "Epoch 206/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4289 - val_loss: 2.4769\n",
            "Epoch 207/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3844 - val_loss: 2.5434\n",
            "Epoch 208/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.4352 - val_loss: 2.5228\n",
            "Epoch 209/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4106 - val_loss: 2.5072\n",
            "Epoch 210/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4561 - val_loss: 2.7172\n",
            "Epoch 211/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4361 - val_loss: 2.5390\n",
            "Epoch 212/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4052 - val_loss: 2.5162\n",
            "Epoch 213/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4008 - val_loss: 2.6203\n",
            "Epoch 214/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4401 - val_loss: 2.6269\n",
            "Epoch 215/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4545 - val_loss: 2.5280\n",
            "Epoch 216/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4031 - val_loss: 2.7888\n",
            "Epoch 217/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4034 - val_loss: 2.5425\n",
            "Epoch 218/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3597 - val_loss: 2.5476\n",
            "Epoch 219/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3816 - val_loss: 2.5410\n",
            "Epoch 220/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3867 - val_loss: 2.5204\n",
            "Epoch 221/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4127 - val_loss: 2.6520\n",
            "Save file name colab_notebook_data/feature_interactions/trained_models/poscontrol_model-arch1_l1reg-0.001_seed100_hjmju.h5\n",
            "Training model colab_notebook_data/feature_interactions/trained_models/negcontrol_model-arch1_l1reg-0.001_seed100_ltffs.h5\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_13 (Conv1D)           (None, 94, 15)            435       \n",
            "_________________________________________________________________\n",
            "conv1d_14 (Conv1D)           (None, 88, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_15 (Conv1D)           (None, 82, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_16 (Conv1D)           (None, 76, 15)            1590      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_4 ( (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 50)                800       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 8,606\n",
            "Trainable params: 8,606\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "40000/40000 [==============================] - 2s 57us/step - loss: 121.4611 - val_loss: 75.7856\n",
            "Epoch 2/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 64.6535 - val_loss: 46.1147\n",
            "Epoch 3/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 33.7578 - val_loss: 26.2239\n",
            "Epoch 4/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 23.7753 - val_loss: 21.1283\n",
            "Epoch 5/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 19.3580 - val_loss: 17.4510\n",
            "Epoch 6/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 15.8614 - val_loss: 14.7559\n",
            "Epoch 7/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 13.3848 - val_loss: 12.7174\n",
            "Epoch 8/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 12.0449 - val_loss: 11.5729\n",
            "Epoch 9/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 10.8698 - val_loss: 10.8620\n",
            "Epoch 10/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 9.9536 - val_loss: 10.2827\n",
            "Epoch 11/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 9.4380 - val_loss: 9.4147\n",
            "Epoch 12/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 8.9347 - val_loss: 8.7948\n",
            "Epoch 13/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 8.5873 - val_loss: 8.7473\n",
            "Epoch 14/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 8.2772 - val_loss: 8.1824\n",
            "Epoch 15/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 7.8935 - val_loss: 7.8535\n",
            "Epoch 16/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 7.6030 - val_loss: 7.5207\n",
            "Epoch 17/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 7.3686 - val_loss: 7.1907\n",
            "Epoch 18/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 7.2060 - val_loss: 7.2345\n",
            "Epoch 19/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 6.8935 - val_loss: 6.8223\n",
            "Epoch 20/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 6.7877 - val_loss: 6.6801\n",
            "Epoch 21/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 6.6083 - val_loss: 6.4718\n",
            "Epoch 22/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 6.4021 - val_loss: 6.7947\n",
            "Epoch 23/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 6.1968 - val_loss: 6.8619\n",
            "Epoch 24/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 5.9717 - val_loss: 5.9302\n",
            "Epoch 25/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 5.6839 - val_loss: 5.5116\n",
            "Epoch 26/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 5.2394 - val_loss: 5.0049\n",
            "Epoch 27/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 4.8600 - val_loss: 4.7137\n",
            "Epoch 28/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 4.4671 - val_loss: 4.4560\n",
            "Epoch 29/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 4.2544 - val_loss: 4.1878\n",
            "Epoch 30/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 4.1148 - val_loss: 4.1029\n",
            "Epoch 31/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 4.0448 - val_loss: 3.9919\n",
            "Epoch 32/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.9657 - val_loss: 4.0092\n",
            "Epoch 33/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.8988 - val_loss: 3.9147\n",
            "Epoch 34/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.9151 - val_loss: 3.8424\n",
            "Epoch 35/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 3.8215 - val_loss: 3.9597\n",
            "Epoch 36/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.7550 - val_loss: 3.7635\n",
            "Epoch 37/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.6591 - val_loss: 3.7648\n",
            "Epoch 38/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.6813 - val_loss: 3.6361\n",
            "Epoch 39/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.6177 - val_loss: 4.0304\n",
            "Epoch 40/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.6123 - val_loss: 3.7018\n",
            "Epoch 41/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.5351 - val_loss: 3.7546\n",
            "Epoch 42/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.5437 - val_loss: 3.7465\n",
            "Epoch 43/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.4465 - val_loss: 3.5248\n",
            "Epoch 44/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.3954 - val_loss: 3.8231\n",
            "Epoch 45/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.3809 - val_loss: 4.0147\n",
            "Epoch 46/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.4598 - val_loss: 3.5644\n",
            "Epoch 47/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.3356 - val_loss: 3.4303\n",
            "Epoch 48/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.3000 - val_loss: 3.4114\n",
            "Epoch 49/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.2869 - val_loss: 3.5848\n",
            "Epoch 50/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.4344 - val_loss: 3.4437\n",
            "Epoch 51/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.3096 - val_loss: 3.5068\n",
            "Epoch 52/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.2499 - val_loss: 3.5310\n",
            "Epoch 53/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.2226 - val_loss: 3.2299\n",
            "Epoch 54/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.1744 - val_loss: 3.2720\n",
            "Epoch 55/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.2284 - val_loss: 3.6029\n",
            "Epoch 56/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.1814 - val_loss: 3.1808\n",
            "Epoch 57/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.1740 - val_loss: 3.2184\n",
            "Epoch 58/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.1073 - val_loss: 3.3501\n",
            "Epoch 59/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.0768 - val_loss: 3.1381\n",
            "Epoch 60/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.1221 - val_loss: 3.2349\n",
            "Epoch 61/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.1186 - val_loss: 3.1443\n",
            "Epoch 62/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.0430 - val_loss: 3.4160\n",
            "Epoch 63/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.0777 - val_loss: 3.2981\n",
            "Epoch 64/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.0695 - val_loss: 3.1406\n",
            "Epoch 65/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.0845 - val_loss: 3.0499\n",
            "Epoch 66/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.0183 - val_loss: 3.0786\n",
            "Epoch 67/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.9947 - val_loss: 3.3715\n",
            "Epoch 68/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.0114 - val_loss: 3.2314\n",
            "Epoch 69/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.0360 - val_loss: 2.9925\n",
            "Epoch 70/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.9629 - val_loss: 3.0614\n",
            "Epoch 71/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.9898 - val_loss: 3.2097\n",
            "Epoch 72/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.9485 - val_loss: 2.9658\n",
            "Epoch 73/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.0010 - val_loss: 3.2473\n",
            "Epoch 74/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.9760 - val_loss: 2.9975\n",
            "Epoch 75/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.9152 - val_loss: 3.3416\n",
            "Epoch 76/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.9314 - val_loss: 3.0096\n",
            "Epoch 77/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.9205 - val_loss: 2.9534\n",
            "Epoch 78/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.8702 - val_loss: 2.9660\n",
            "Epoch 79/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.8996 - val_loss: 3.0370\n",
            "Epoch 80/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.8693 - val_loss: 2.9063\n",
            "Epoch 81/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.9104 - val_loss: 3.4025\n",
            "Epoch 82/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8448 - val_loss: 3.0399\n",
            "Epoch 83/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9497 - val_loss: 2.9019\n",
            "Epoch 84/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8514 - val_loss: 2.8684\n",
            "Epoch 85/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.8420 - val_loss: 2.9327\n",
            "Epoch 86/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.8380 - val_loss: 2.8562\n",
            "Epoch 87/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.8510 - val_loss: 3.0935\n",
            "Epoch 88/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.8195 - val_loss: 2.9514\n",
            "Epoch 89/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.8178 - val_loss: 2.8829\n",
            "Epoch 90/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.8098 - val_loss: 2.8094\n",
            "Epoch 91/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.8192 - val_loss: 2.8614\n",
            "Epoch 92/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7712 - val_loss: 3.0155\n",
            "Epoch 93/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.7737 - val_loss: 2.9035\n",
            "Epoch 94/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.7467 - val_loss: 2.7843\n",
            "Epoch 95/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.7413 - val_loss: 2.7948\n",
            "Epoch 96/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.7541 - val_loss: 2.8861\n",
            "Epoch 97/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.7875 - val_loss: 2.8191\n",
            "Epoch 98/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.7348 - val_loss: 2.8967\n",
            "Epoch 99/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.7368 - val_loss: 2.8004\n",
            "Epoch 100/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.7349 - val_loss: 2.8048\n",
            "Epoch 101/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.7126 - val_loss: 3.1110\n",
            "Epoch 102/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.7124 - val_loss: 2.8576\n",
            "Epoch 103/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.7514 - val_loss: 2.8463\n",
            "Epoch 104/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.7082 - val_loss: 2.9167\n",
            "Epoch 105/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6655 - val_loss: 2.7850\n",
            "Epoch 106/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6809 - val_loss: 2.7056\n",
            "Epoch 107/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6843 - val_loss: 2.7295\n",
            "Epoch 108/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6827 - val_loss: 2.7475\n",
            "Epoch 109/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6807 - val_loss: 2.8052\n",
            "Epoch 110/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6367 - val_loss: 2.7360\n",
            "Epoch 111/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.6289 - val_loss: 2.7708\n",
            "Epoch 112/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6642 - val_loss: 2.7841\n",
            "Epoch 113/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6199 - val_loss: 2.7057\n",
            "Epoch 114/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.6454 - val_loss: 2.7169\n",
            "Epoch 115/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6276 - val_loss: 2.7203\n",
            "Epoch 116/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6297 - val_loss: 2.6685\n",
            "Epoch 117/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6021 - val_loss: 2.6348\n",
            "Epoch 118/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.6103 - val_loss: 2.6888\n",
            "Epoch 119/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6514 - val_loss: 2.7763\n",
            "Epoch 120/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.5754 - val_loss: 2.6800\n",
            "Epoch 121/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6251 - val_loss: 2.6703\n",
            "Epoch 122/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5841 - val_loss: 2.6333\n",
            "Epoch 123/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5611 - val_loss: 2.6298\n",
            "Epoch 124/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6336 - val_loss: 2.8923\n",
            "Epoch 125/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.5764 - val_loss: 2.8568\n",
            "Epoch 126/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.5566 - val_loss: 2.6983\n",
            "Epoch 127/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.5653 - val_loss: 2.7192\n",
            "Epoch 128/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5672 - val_loss: 2.5722\n",
            "Epoch 129/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5610 - val_loss: 2.6721\n",
            "Epoch 130/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5590 - val_loss: 2.5896\n",
            "Epoch 131/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.5426 - val_loss: 2.6349\n",
            "Epoch 132/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5441 - val_loss: 2.6383\n",
            "Epoch 133/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5146 - val_loss: 2.6690\n",
            "Epoch 134/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5367 - val_loss: 2.5456\n",
            "Epoch 135/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5186 - val_loss: 2.6067\n",
            "Epoch 136/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.4821 - val_loss: 2.6278\n",
            "Epoch 137/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5289 - val_loss: 2.6564\n",
            "Epoch 138/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5377 - val_loss: 2.6165\n",
            "Epoch 139/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4982 - val_loss: 2.5413\n",
            "Epoch 140/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4692 - val_loss: 2.5938\n",
            "Epoch 141/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4626 - val_loss: 2.6035\n",
            "Epoch 142/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.4701 - val_loss: 2.5846\n",
            "Epoch 143/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.4489 - val_loss: 2.5673\n",
            "Epoch 144/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.4450 - val_loss: 2.5170\n",
            "Epoch 145/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.4892 - val_loss: 2.4797\n",
            "Epoch 146/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4454 - val_loss: 2.8639\n",
            "Epoch 147/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.4726 - val_loss: 2.7243\n",
            "Epoch 148/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.4520 - val_loss: 2.5181\n",
            "Epoch 149/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4380 - val_loss: 2.5543\n",
            "Epoch 150/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4156 - val_loss: 2.5392\n",
            "Epoch 151/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.4499 - val_loss: 2.9152\n",
            "Epoch 152/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4338 - val_loss: 2.5345\n",
            "Epoch 153/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4113 - val_loss: 2.4718\n",
            "Epoch 154/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.3875 - val_loss: 2.5227\n",
            "Epoch 155/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.4277 - val_loss: 2.5165\n",
            "Epoch 156/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3895 - val_loss: 2.5639\n",
            "Epoch 157/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.3808 - val_loss: 2.4876\n",
            "Epoch 158/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.3641 - val_loss: 2.4315\n",
            "Epoch 159/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.3818 - val_loss: 2.4711\n",
            "Epoch 160/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.3712 - val_loss: 2.5559\n",
            "Epoch 161/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.3726 - val_loss: 2.7135\n",
            "Epoch 162/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3825 - val_loss: 2.5228\n",
            "Epoch 163/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3534 - val_loss: 2.4445\n",
            "Epoch 164/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.3947 - val_loss: 2.4084\n",
            "Epoch 165/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3471 - val_loss: 2.4123\n",
            "Epoch 166/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3934 - val_loss: 2.4556\n",
            "Epoch 167/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3768 - val_loss: 2.4182\n",
            "Epoch 168/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.3257 - val_loss: 2.4320\n",
            "Epoch 169/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.3506 - val_loss: 2.4008\n",
            "Epoch 170/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3493 - val_loss: 2.3724\n",
            "Epoch 171/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3101 - val_loss: 2.3624\n",
            "Epoch 172/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.3338 - val_loss: 2.5671\n",
            "Epoch 173/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.3187 - val_loss: 2.4141\n",
            "Epoch 174/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2929 - val_loss: 2.5747\n",
            "Epoch 175/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.3004 - val_loss: 2.3717\n",
            "Epoch 176/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3089 - val_loss: 2.3883\n",
            "Epoch 177/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2813 - val_loss: 2.3556\n",
            "Epoch 178/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2878 - val_loss: 2.4625\n",
            "Epoch 179/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3062 - val_loss: 2.3486\n",
            "Epoch 180/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.3020 - val_loss: 2.4087\n",
            "Epoch 181/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2962 - val_loss: 2.8111\n",
            "Epoch 182/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3065 - val_loss: 2.6941\n",
            "Epoch 183/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2873 - val_loss: 2.3346\n",
            "Epoch 184/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2702 - val_loss: 2.4829\n",
            "Epoch 185/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2737 - val_loss: 2.2951\n",
            "Epoch 186/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2640 - val_loss: 2.5509\n",
            "Epoch 187/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.3172 - val_loss: 2.3078\n",
            "Epoch 188/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2473 - val_loss: 2.3603\n",
            "Epoch 189/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2611 - val_loss: 2.3856\n",
            "Epoch 190/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2442 - val_loss: 2.3154\n",
            "Epoch 191/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2757 - val_loss: 2.4347\n",
            "Epoch 192/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2677 - val_loss: 2.2778\n",
            "Epoch 193/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2330 - val_loss: 2.2983\n",
            "Epoch 194/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2551 - val_loss: 2.3202\n",
            "Epoch 195/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2727 - val_loss: 2.2926\n",
            "Epoch 196/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2608 - val_loss: 2.4010\n",
            "Epoch 197/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2104 - val_loss: 2.4490\n",
            "Epoch 198/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2367 - val_loss: 2.3089\n",
            "Epoch 199/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2135 - val_loss: 2.3111\n",
            "Epoch 200/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2085 - val_loss: 2.3237\n",
            "Epoch 201/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2575 - val_loss: 2.4765\n",
            "Epoch 202/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2166 - val_loss: 2.4757\n",
            "Epoch 203/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2236 - val_loss: 2.4554\n",
            "Epoch 204/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2566 - val_loss: 2.2977\n",
            "Epoch 205/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2309 - val_loss: 2.2669\n",
            "Epoch 206/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2110 - val_loss: 2.4590\n",
            "Epoch 207/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2483 - val_loss: 2.2640\n",
            "Epoch 208/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2203 - val_loss: 2.3897\n",
            "Epoch 209/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2107 - val_loss: 2.2534\n",
            "Epoch 210/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2136 - val_loss: 2.2934\n",
            "Epoch 211/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2022 - val_loss: 2.5852\n",
            "Epoch 212/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1912 - val_loss: 2.2511\n",
            "Epoch 213/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2069 - val_loss: 2.2630\n",
            "Epoch 214/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2120 - val_loss: 2.2560\n",
            "Epoch 215/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1898 - val_loss: 2.2744\n",
            "Epoch 216/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2098 - val_loss: 2.3688\n",
            "Epoch 217/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1870 - val_loss: 2.2369\n",
            "Epoch 218/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2208 - val_loss: 2.3078\n",
            "Epoch 219/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1748 - val_loss: 2.2789\n",
            "Epoch 220/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1750 - val_loss: 2.3234\n",
            "Epoch 221/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1691 - val_loss: 2.2724\n",
            "Epoch 222/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2192 - val_loss: 2.3885\n",
            "Epoch 223/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1850 - val_loss: 2.3480\n",
            "Epoch 224/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1634 - val_loss: 2.2125\n",
            "Epoch 225/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1745 - val_loss: 2.2438\n",
            "Epoch 226/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1794 - val_loss: 2.2664\n",
            "Epoch 227/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1704 - val_loss: 2.2105\n",
            "Epoch 228/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1936 - val_loss: 2.2498\n",
            "Epoch 229/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1477 - val_loss: 2.5432\n",
            "Epoch 230/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1991 - val_loss: 2.3656\n",
            "Epoch 231/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1559 - val_loss: 2.2109\n",
            "Epoch 232/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1514 - val_loss: 2.5251\n",
            "Epoch 233/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1369 - val_loss: 2.2459\n",
            "Epoch 234/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1811 - val_loss: 2.4614\n",
            "Epoch 235/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1899 - val_loss: 2.2666\n",
            "Epoch 236/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1462 - val_loss: 2.3649\n",
            "Epoch 237/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1454 - val_loss: 2.3318\n",
            "Epoch 238/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1443 - val_loss: 2.3137\n",
            "Epoch 239/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1379 - val_loss: 2.3297\n",
            "Epoch 240/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1480 - val_loss: 2.2812\n",
            "Epoch 241/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1554 - val_loss: 2.1862\n",
            "Epoch 242/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1347 - val_loss: 2.2577\n",
            "Epoch 243/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1399 - val_loss: 2.2211\n",
            "Epoch 244/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1334 - val_loss: 2.2302\n",
            "Epoch 245/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1266 - val_loss: 2.2390\n",
            "Epoch 246/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1464 - val_loss: 2.1860\n",
            "Epoch 247/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1543 - val_loss: 2.2305\n",
            "Epoch 248/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1362 - val_loss: 2.2173\n",
            "Epoch 249/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1336 - val_loss: 2.2432\n",
            "Epoch 250/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1289 - val_loss: 2.4579\n",
            "Epoch 251/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.1591 - val_loss: 2.1690\n",
            "Epoch 252/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1142 - val_loss: 2.1893\n",
            "Epoch 253/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1527 - val_loss: 2.2423\n",
            "Epoch 254/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1023 - val_loss: 2.1665\n",
            "Epoch 255/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1100 - val_loss: 2.1863\n",
            "Epoch 256/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1166 - val_loss: 2.1670\n",
            "Epoch 257/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1032 - val_loss: 2.1936\n",
            "Epoch 258/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1056 - val_loss: 2.2271\n",
            "Epoch 259/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1068 - val_loss: 2.1668\n",
            "Epoch 260/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1237 - val_loss: 2.3731\n",
            "Epoch 261/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1141 - val_loss: 2.1915\n",
            "Epoch 262/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1204 - val_loss: 2.1770\n",
            "Epoch 263/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1263 - val_loss: 2.1831\n",
            "Epoch 264/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1444 - val_loss: 2.2336\n",
            "Epoch 265/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0983 - val_loss: 2.2000\n",
            "Epoch 266/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1297 - val_loss: 2.1475\n",
            "Epoch 267/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0822 - val_loss: 2.2138\n",
            "Epoch 268/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0878 - val_loss: 2.2984\n",
            "Epoch 269/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.1222 - val_loss: 2.1617\n",
            "Epoch 270/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1044 - val_loss: 2.1816\n",
            "Epoch 271/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0891 - val_loss: 2.2160\n",
            "Epoch 272/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0987 - val_loss: 2.1704\n",
            "Epoch 273/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0834 - val_loss: 2.1708\n",
            "Epoch 274/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1042 - val_loss: 2.2601\n",
            "Epoch 275/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0706 - val_loss: 2.2522\n",
            "Epoch 276/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1635 - val_loss: 2.1595\n",
            "Epoch 277/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1073 - val_loss: 2.2985\n",
            "Epoch 278/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0985 - val_loss: 2.2622\n",
            "Epoch 279/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0892 - val_loss: 2.1241\n",
            "Epoch 280/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0931 - val_loss: 2.1597\n",
            "Epoch 281/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.0918 - val_loss: 2.2252\n",
            "Epoch 282/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0628 - val_loss: 2.2160\n",
            "Epoch 283/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0936 - val_loss: 2.2581\n",
            "Epoch 284/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.0749 - val_loss: 2.3008\n",
            "Epoch 285/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.0904 - val_loss: 2.1905\n",
            "Epoch 286/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0665 - val_loss: 2.1553\n",
            "Epoch 287/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0745 - val_loss: 2.1750\n",
            "Epoch 288/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0778 - val_loss: 2.1723\n",
            "Epoch 289/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0626 - val_loss: 2.2327\n",
            "Epoch 290/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0731 - val_loss: 2.2786\n",
            "Epoch 291/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0928 - val_loss: 2.1222\n",
            "Epoch 292/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0626 - val_loss: 2.1784\n",
            "Epoch 293/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0349 - val_loss: 2.2077\n",
            "Epoch 294/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0629 - val_loss: 2.1353\n",
            "Epoch 295/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0743 - val_loss: 2.1500\n",
            "Epoch 296/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0712 - val_loss: 2.1832\n",
            "Epoch 297/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.0639 - val_loss: 2.3263\n",
            "Epoch 298/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.0579 - val_loss: 2.2114\n",
            "Epoch 299/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0434 - val_loss: 2.1799\n",
            "Epoch 300/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0519 - val_loss: 2.2431\n",
            "Epoch 301/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0609 - val_loss: 2.1421\n",
            "Epoch 302/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0383 - val_loss: 2.1342\n",
            "Epoch 303/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0679 - val_loss: 2.1170\n",
            "Epoch 304/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0600 - val_loss: 2.1512\n",
            "Epoch 305/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1076 - val_loss: 2.1415\n",
            "Epoch 306/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0357 - val_loss: 2.1757\n",
            "Epoch 307/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0391 - val_loss: 2.2263\n",
            "Epoch 308/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0439 - val_loss: 2.1049\n",
            "Epoch 309/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0761 - val_loss: 2.1736\n",
            "Epoch 310/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0477 - val_loss: 2.1568\n",
            "Epoch 311/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0294 - val_loss: 2.0793\n",
            "Epoch 312/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0455 - val_loss: 2.1395\n",
            "Epoch 313/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0368 - val_loss: 2.0910\n",
            "Epoch 314/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0521 - val_loss: 2.0907\n",
            "Epoch 315/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0393 - val_loss: 2.1023\n",
            "Epoch 316/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0500 - val_loss: 2.1280\n",
            "Epoch 317/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0221 - val_loss: 2.3537\n",
            "Epoch 318/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0550 - val_loss: 2.1274\n",
            "Epoch 319/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0640 - val_loss: 2.0686\n",
            "Epoch 320/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0065 - val_loss: 2.1452\n",
            "Epoch 321/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0617 - val_loss: 2.1892\n",
            "Epoch 322/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0486 - val_loss: 2.1560\n",
            "Epoch 323/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0383 - val_loss: 2.0996\n",
            "Epoch 324/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0258 - val_loss: 2.0895\n",
            "Epoch 325/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0196 - val_loss: 2.0988\n",
            "Epoch 326/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0175 - val_loss: 2.2163\n",
            "Epoch 327/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0575 - val_loss: 2.1060\n",
            "Epoch 328/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0124 - val_loss: 2.3828\n",
            "Epoch 329/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0370 - val_loss: 2.1611\n",
            "Epoch 330/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0394 - val_loss: 2.2663\n",
            "Epoch 331/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0240 - val_loss: 2.1789\n",
            "Epoch 332/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0329 - val_loss: 2.1285\n",
            "Epoch 333/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0136 - val_loss: 2.0660\n",
            "Epoch 334/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0278 - val_loss: 2.0769\n",
            "Epoch 335/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0008 - val_loss: 2.1639\n",
            "Epoch 336/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0319 - val_loss: 2.1565\n",
            "Epoch 337/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0095 - val_loss: 2.2477\n",
            "Epoch 338/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0278 - val_loss: 2.0676\n",
            "Epoch 339/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0160 - val_loss: 2.0975\n",
            "Epoch 340/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0237 - val_loss: 2.1339\n",
            "Epoch 341/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.9980 - val_loss: 2.0593\n",
            "Epoch 342/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0146 - val_loss: 2.1362\n",
            "Epoch 343/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0164 - val_loss: 2.0787\n",
            "Epoch 344/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0158 - val_loss: 2.0851\n",
            "Epoch 345/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9990 - val_loss: 2.1808\n",
            "Epoch 346/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9980 - val_loss: 2.0536\n",
            "Epoch 347/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0159 - val_loss: 2.0386\n",
            "Epoch 348/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0004 - val_loss: 2.1274\n",
            "Epoch 349/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9877 - val_loss: 2.0570\n",
            "Epoch 350/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9942 - val_loss: 2.1896\n",
            "Epoch 351/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0088 - val_loss: 2.1308\n",
            "Epoch 352/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9899 - val_loss: 2.0694\n",
            "Epoch 353/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9829 - val_loss: 2.0950\n",
            "Epoch 354/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0368 - val_loss: 2.0934\n",
            "Epoch 355/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9773 - val_loss: 2.0469\n",
            "Epoch 356/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.9803 - val_loss: 2.0771\n",
            "Epoch 357/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0005 - val_loss: 2.0934\n",
            "Epoch 358/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.9957 - val_loss: 2.1021\n",
            "Epoch 359/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9947 - val_loss: 2.0910\n",
            "Epoch 360/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.9897 - val_loss: 2.1629\n",
            "Epoch 361/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.9807 - val_loss: 2.0504\n",
            "Epoch 362/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0167 - val_loss: 2.1247\n",
            "Save file name colab_notebook_data/feature_interactions/trained_models/negcontrol_model-arch1_l1reg-0.001_seed100_ltffs.h5\n",
            "Training model colab_notebook_data/feature_interactions/trained_models/poscontrol_model-arch1_l1reg-0.0001_seed100_aomas.h5\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_17 (Conv1D)           (None, 94, 15)            435       \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 88, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_19 (Conv1D)           (None, 82, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_20 (Conv1D)           (None, 76, 15)            1590      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_5 ( (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 50)                800       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 8,606\n",
            "Trainable params: 8,606\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "40000/40000 [==============================] - 2s 55us/step - loss: 103.8900 - val_loss: 83.5257\n",
            "Epoch 2/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 75.1409 - val_loss: 60.7294\n",
            "Epoch 3/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 46.9184 - val_loss: 41.9268\n",
            "Epoch 4/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 36.8381 - val_loss: 34.0537\n",
            "Epoch 5/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 32.5120 - val_loss: 30.6390\n",
            "Epoch 6/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 29.7999 - val_loss: 27.9165\n",
            "Epoch 7/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 26.9058 - val_loss: 26.7309\n",
            "Epoch 8/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 24.8126 - val_loss: 24.6999\n",
            "Epoch 9/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 23.5240 - val_loss: 23.0309\n",
            "Epoch 10/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 21.9068 - val_loss: 23.1699\n",
            "Epoch 11/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 21.0145 - val_loss: 20.9374\n",
            "Epoch 12/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 19.9534 - val_loss: 19.8733\n",
            "Epoch 13/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 19.0023 - val_loss: 21.4342\n",
            "Epoch 14/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 18.1097 - val_loss: 18.8455\n",
            "Epoch 15/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 16.9186 - val_loss: 17.0728\n",
            "Epoch 16/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 16.0958 - val_loss: 17.9212\n",
            "Epoch 17/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 15.6111 - val_loss: 15.2253\n",
            "Epoch 18/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 14.5300 - val_loss: 14.5682\n",
            "Epoch 19/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 13.8512 - val_loss: 13.6876\n",
            "Epoch 20/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 13.2553 - val_loss: 13.0272\n",
            "Epoch 21/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 12.7197 - val_loss: 12.4907\n",
            "Epoch 22/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 12.2461 - val_loss: 12.3276\n",
            "Epoch 23/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 11.7493 - val_loss: 11.8335\n",
            "Epoch 24/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 11.2533 - val_loss: 11.1184\n",
            "Epoch 25/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 10.7825 - val_loss: 10.4195\n",
            "Epoch 26/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 9.9241 - val_loss: 10.3409\n",
            "Epoch 27/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 9.3486 - val_loss: 9.1444\n",
            "Epoch 28/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 8.8149 - val_loss: 8.8101\n",
            "Epoch 29/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 8.5159 - val_loss: 8.6617\n",
            "Epoch 30/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 8.1576 - val_loss: 8.2481\n",
            "Epoch 31/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 7.9463 - val_loss: 8.0147\n",
            "Epoch 32/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 7.6899 - val_loss: 7.9724\n",
            "Epoch 33/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 7.4041 - val_loss: 7.5720\n",
            "Epoch 34/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 7.2645 - val_loss: 7.4430\n",
            "Epoch 35/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 7.2016 - val_loss: 7.2385\n",
            "Epoch 36/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 6.8934 - val_loss: 7.1172\n",
            "Epoch 37/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 6.8355 - val_loss: 7.5613\n",
            "Epoch 38/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 6.5538 - val_loss: 6.8131\n",
            "Epoch 39/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 6.4638 - val_loss: 6.5795\n",
            "Epoch 40/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 6.2322 - val_loss: 7.1690\n",
            "Epoch 41/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 6.0640 - val_loss: 6.3459\n",
            "Epoch 42/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 6.0821 - val_loss: 6.1986\n",
            "Epoch 43/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 5.6704 - val_loss: 5.9868\n",
            "Epoch 44/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 5.5824 - val_loss: 5.9027\n",
            "Epoch 45/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 5.5139 - val_loss: 6.1400\n",
            "Epoch 46/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 5.4715 - val_loss: 5.8912\n",
            "Epoch 47/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 5.2579 - val_loss: 5.5617\n",
            "Epoch 48/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 5.1353 - val_loss: 5.6675\n",
            "Epoch 49/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 5.1208 - val_loss: 5.8515\n",
            "Epoch 50/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 4.8473 - val_loss: 5.2902\n",
            "Epoch 51/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 4.8399 - val_loss: 5.3139\n",
            "Epoch 52/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.7229 - val_loss: 4.8961\n",
            "Epoch 53/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.5914 - val_loss: 4.7291\n",
            "Epoch 54/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.4711 - val_loss: 4.7430\n",
            "Epoch 55/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 4.3135 - val_loss: 4.9265\n",
            "Epoch 56/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 4.1703 - val_loss: 4.6877\n",
            "Epoch 57/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 4.1360 - val_loss: 4.6487\n",
            "Epoch 58/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 4.0814 - val_loss: 4.6325\n",
            "Epoch 59/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 4.0437 - val_loss: 4.2449\n",
            "Epoch 60/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.9630 - val_loss: 4.6784\n",
            "Epoch 61/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.8686 - val_loss: 4.1445\n",
            "Epoch 62/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.7027 - val_loss: 4.0517\n",
            "Epoch 63/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.7020 - val_loss: 4.1036\n",
            "Epoch 64/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.5953 - val_loss: 4.0286\n",
            "Epoch 65/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.5904 - val_loss: 3.9471\n",
            "Epoch 66/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.4703 - val_loss: 3.8627\n",
            "Epoch 67/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.3950 - val_loss: 3.9143\n",
            "Epoch 68/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.3516 - val_loss: 3.6770\n",
            "Epoch 69/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.3036 - val_loss: 4.1649\n",
            "Epoch 70/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.3190 - val_loss: 3.6392\n",
            "Epoch 71/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.2799 - val_loss: 3.6191\n",
            "Epoch 72/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.1917 - val_loss: 3.4278\n",
            "Epoch 73/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.2447 - val_loss: 3.5885\n",
            "Epoch 74/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.1902 - val_loss: 3.3441\n",
            "Epoch 75/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.1284 - val_loss: 3.7674\n",
            "Epoch 76/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.1110 - val_loss: 3.2753\n",
            "Epoch 77/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.9497 - val_loss: 3.3077\n",
            "Epoch 78/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.9826 - val_loss: 3.2209\n",
            "Epoch 79/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.0307 - val_loss: 3.6005\n",
            "Epoch 80/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.9050 - val_loss: 3.2584\n",
            "Epoch 81/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9043 - val_loss: 3.0873\n",
            "Epoch 82/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.8986 - val_loss: 3.1400\n",
            "Epoch 83/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8822 - val_loss: 3.2353\n",
            "Epoch 84/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.7764 - val_loss: 3.0114\n",
            "Epoch 85/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.7669 - val_loss: 3.1954\n",
            "Epoch 86/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.7453 - val_loss: 3.1799\n",
            "Epoch 87/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.7056 - val_loss: 3.0584\n",
            "Epoch 88/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.7226 - val_loss: 3.2792\n",
            "Epoch 89/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.6679 - val_loss: 2.9132\n",
            "Epoch 90/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.5978 - val_loss: 2.9486\n",
            "Epoch 91/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.6018 - val_loss: 2.8778\n",
            "Epoch 92/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.5525 - val_loss: 2.9321\n",
            "Epoch 93/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.6133 - val_loss: 2.9601\n",
            "Epoch 94/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.5911 - val_loss: 3.0926\n",
            "Epoch 95/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.5046 - val_loss: 2.7787\n",
            "Epoch 96/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5482 - val_loss: 2.8452\n",
            "Epoch 97/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.5230 - val_loss: 2.7965\n",
            "Epoch 98/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.4944 - val_loss: 3.2345\n",
            "Epoch 99/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4641 - val_loss: 2.8956\n",
            "Epoch 100/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.4214 - val_loss: 2.9160\n",
            "Epoch 101/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.4036 - val_loss: 2.7646\n",
            "Epoch 102/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.4064 - val_loss: 2.7373\n",
            "Epoch 103/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4406 - val_loss: 2.7146\n",
            "Epoch 104/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4224 - val_loss: 2.6239\n",
            "Epoch 105/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3339 - val_loss: 2.9490\n",
            "Epoch 106/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3376 - val_loss: 2.5625\n",
            "Epoch 107/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.3004 - val_loss: 2.5516\n",
            "Epoch 108/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.2956 - val_loss: 2.7774\n",
            "Epoch 109/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3517 - val_loss: 2.8263\n",
            "Epoch 110/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3162 - val_loss: 2.6214\n",
            "Epoch 111/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2659 - val_loss: 2.5700\n",
            "Epoch 112/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2335 - val_loss: 2.6625\n",
            "Epoch 113/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3086 - val_loss: 2.5308\n",
            "Epoch 114/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2213 - val_loss: 2.7109\n",
            "Epoch 115/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2856 - val_loss: 2.4707\n",
            "Epoch 116/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1638 - val_loss: 2.5668\n",
            "Epoch 117/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1751 - val_loss: 2.4101\n",
            "Epoch 118/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2052 - val_loss: 2.5524\n",
            "Epoch 119/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1938 - val_loss: 2.5135\n",
            "Epoch 120/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1423 - val_loss: 2.4772\n",
            "Epoch 121/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1721 - val_loss: 2.4897\n",
            "Epoch 122/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1383 - val_loss: 2.4670\n",
            "Epoch 123/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2452 - val_loss: 2.3925\n",
            "Epoch 124/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1672 - val_loss: 2.4404\n",
            "Epoch 125/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1418 - val_loss: 2.8306\n",
            "Epoch 126/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1391 - val_loss: 2.4649\n",
            "Epoch 127/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1073 - val_loss: 2.5839\n",
            "Epoch 128/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0720 - val_loss: 2.3615\n",
            "Epoch 129/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0863 - val_loss: 2.3571\n",
            "Epoch 130/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1044 - val_loss: 2.4328\n",
            "Epoch 131/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.0768 - val_loss: 2.5102\n",
            "Epoch 132/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0317 - val_loss: 2.5433\n",
            "Epoch 133/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0459 - val_loss: 2.3093\n",
            "Epoch 134/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0270 - val_loss: 2.2838\n",
            "Epoch 135/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0564 - val_loss: 2.3951\n",
            "Epoch 136/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0064 - val_loss: 2.4436\n",
            "Epoch 137/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9827 - val_loss: 2.2482\n",
            "Epoch 138/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9898 - val_loss: 2.4501\n",
            "Epoch 139/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0294 - val_loss: 2.3124\n",
            "Epoch 140/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0265 - val_loss: 2.5125\n",
            "Epoch 141/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9965 - val_loss: 2.2970\n",
            "Epoch 142/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.9757 - val_loss: 2.3917\n",
            "Epoch 143/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9535 - val_loss: 2.2161\n",
            "Epoch 144/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.9616 - val_loss: 2.3094\n",
            "Epoch 145/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9585 - val_loss: 2.2164\n",
            "Epoch 146/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9527 - val_loss: 2.4686\n",
            "Epoch 147/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9454 - val_loss: 2.2159\n",
            "Epoch 148/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9305 - val_loss: 2.1779\n",
            "Epoch 149/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.9317 - val_loss: 2.3146\n",
            "Epoch 150/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.9384 - val_loss: 2.2323\n",
            "Epoch 151/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.9243 - val_loss: 2.3414\n",
            "Epoch 152/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.9082 - val_loss: 2.3673\n",
            "Epoch 153/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9596 - val_loss: 2.3632\n",
            "Epoch 154/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8824 - val_loss: 2.2031\n",
            "Epoch 155/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8900 - val_loss: 2.3610\n",
            "Epoch 156/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8822 - val_loss: 2.2190\n",
            "Epoch 157/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8570 - val_loss: 2.2907\n",
            "Epoch 158/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8717 - val_loss: 2.2562\n",
            "Epoch 159/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8987 - val_loss: 2.4091\n",
            "Epoch 160/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8826 - val_loss: 2.2183\n",
            "Epoch 161/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8797 - val_loss: 2.3014\n",
            "Epoch 162/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8934 - val_loss: 2.2830\n",
            "Epoch 163/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8432 - val_loss: 2.1747\n",
            "Epoch 164/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8951 - val_loss: 2.1419\n",
            "Epoch 165/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.9017 - val_loss: 2.2632\n",
            "Epoch 166/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8501 - val_loss: 2.2479\n",
            "Epoch 167/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8419 - val_loss: 2.3209\n",
            "Epoch 168/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 1.8924 - val_loss: 2.5285\n",
            "Epoch 169/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8467 - val_loss: 2.1610\n",
            "Epoch 170/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8222 - val_loss: 2.1369\n",
            "Epoch 171/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8270 - val_loss: 2.1658\n",
            "Epoch 172/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8037 - val_loss: 2.1002\n",
            "Epoch 173/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8363 - val_loss: 2.1199\n",
            "Epoch 174/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8444 - val_loss: 2.1591\n",
            "Epoch 175/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8176 - val_loss: 2.1135\n",
            "Epoch 176/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8121 - val_loss: 2.3711\n",
            "Epoch 177/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8452 - val_loss: 2.3079\n",
            "Epoch 178/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7953 - val_loss: 2.1154\n",
            "Epoch 179/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8224 - val_loss: 2.2103\n",
            "Epoch 180/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8313 - val_loss: 2.1530\n",
            "Epoch 181/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7924 - val_loss: 2.0603\n",
            "Epoch 182/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8077 - val_loss: 2.3293\n",
            "Epoch 183/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7800 - val_loss: 2.1000\n",
            "Epoch 184/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7627 - val_loss: 2.0711\n",
            "Epoch 185/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8057 - val_loss: 2.0349\n",
            "Epoch 186/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7760 - val_loss: 2.0813\n",
            "Epoch 187/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8207 - val_loss: 2.0994\n",
            "Epoch 188/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7728 - val_loss: 2.1036\n",
            "Epoch 189/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7473 - val_loss: 2.1507\n",
            "Epoch 190/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7737 - val_loss: 2.2324\n",
            "Epoch 191/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7574 - val_loss: 2.2641\n",
            "Epoch 192/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7662 - val_loss: 2.0796\n",
            "Epoch 193/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7227 - val_loss: 2.0506\n",
            "Epoch 194/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7511 - val_loss: 2.0681\n",
            "Epoch 195/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7284 - val_loss: 2.0729\n",
            "Epoch 196/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7216 - val_loss: 2.0883\n",
            "Epoch 197/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7357 - val_loss: 2.0859\n",
            "Epoch 198/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7346 - val_loss: 2.0038\n",
            "Epoch 199/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7823 - val_loss: 2.3857\n",
            "Epoch 200/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7439 - val_loss: 2.0794\n",
            "Epoch 201/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7446 - val_loss: 2.0851\n",
            "Epoch 202/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7706 - val_loss: 2.1159\n",
            "Epoch 203/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7046 - val_loss: 2.1923\n",
            "Epoch 204/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7175 - val_loss: 2.1017\n",
            "Epoch 205/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7083 - val_loss: 2.0055\n",
            "Epoch 206/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7163 - val_loss: 2.0072\n",
            "Epoch 207/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6672 - val_loss: 2.0918\n",
            "Epoch 208/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7179 - val_loss: 1.9955\n",
            "Epoch 209/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7246 - val_loss: 2.0410\n",
            "Epoch 210/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6759 - val_loss: 2.0541\n",
            "Epoch 211/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6708 - val_loss: 1.9909\n",
            "Epoch 212/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7148 - val_loss: 2.1381\n",
            "Epoch 213/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 1.6887 - val_loss: 2.2190\n",
            "Epoch 214/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 1.7076 - val_loss: 2.0345\n",
            "Epoch 215/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 1.6922 - val_loss: 2.1217\n",
            "Epoch 216/1000\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6800 - val_loss: 2.0620\n",
            "Epoch 217/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 1.7052 - val_loss: 2.1809\n",
            "Epoch 218/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6396 - val_loss: 2.1165\n",
            "Epoch 219/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6616 - val_loss: 2.0162\n",
            "Epoch 220/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6785 - val_loss: 2.0758\n",
            "Epoch 221/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6778 - val_loss: 2.0329\n",
            "Epoch 222/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7466 - val_loss: 2.1071\n",
            "Epoch 223/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6681 - val_loss: 2.1397\n",
            "Epoch 224/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6443 - val_loss: 2.0197\n",
            "Epoch 225/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6652 - val_loss: 2.0534\n",
            "Epoch 226/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6886 - val_loss: 2.1030\n",
            "Save file name colab_notebook_data/feature_interactions/trained_models/poscontrol_model-arch1_l1reg-0.0001_seed100_aomas.h5\n",
            "Training model colab_notebook_data/feature_interactions/trained_models/negcontrol_model-arch1_l1reg-0.0001_seed100_onrdk.h5\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_25 (Conv1D)           (None, 94, 15)            435       \n",
            "_________________________________________________________________\n",
            "conv1d_26 (Conv1D)           (None, 88, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_27 (Conv1D)           (None, 82, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_28 (Conv1D)           (None, 76, 15)            1590      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_7 ( (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 50)                800       \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 8,606\n",
            "Trainable params: 8,606\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "40000/40000 [==============================] - 2s 56us/step - loss: 113.6545 - val_loss: 77.9029\n",
            "Epoch 2/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 69.3536 - val_loss: 54.8630\n",
            "Epoch 3/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 37.5575 - val_loss: 27.4712\n",
            "Epoch 4/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 23.2306 - val_loss: 20.9088\n",
            "Epoch 5/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 19.1547 - val_loss: 19.8290\n",
            "Epoch 6/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 17.3926 - val_loss: 16.6535\n",
            "Epoch 7/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 15.4855 - val_loss: 15.3915\n",
            "Epoch 8/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 14.1869 - val_loss: 13.8064\n",
            "Epoch 9/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 13.0166 - val_loss: 12.9329\n",
            "Epoch 10/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 11.9071 - val_loss: 11.2658\n",
            "Epoch 11/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 10.6830 - val_loss: 10.0006\n",
            "Epoch 12/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 9.6350 - val_loss: 9.2776\n",
            "Epoch 13/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 8.7720 - val_loss: 8.4727\n",
            "Epoch 14/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 8.1707 - val_loss: 8.0215\n",
            "Epoch 15/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 7.5369 - val_loss: 7.3666\n",
            "Epoch 16/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 7.0243 - val_loss: 7.1324\n",
            "Epoch 17/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 6.5789 - val_loss: 6.3466\n",
            "Epoch 18/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 6.1797 - val_loss: 6.1165\n",
            "Epoch 19/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 5.7292 - val_loss: 5.5440\n",
            "Epoch 20/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 5.4615 - val_loss: 5.2393\n",
            "Epoch 21/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 5.3173 - val_loss: 5.4002\n",
            "Epoch 22/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 5.0897 - val_loss: 5.0016\n",
            "Epoch 23/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 4.9048 - val_loss: 5.1741\n",
            "Epoch 24/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 4.7208 - val_loss: 4.6320\n",
            "Epoch 25/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 4.5738 - val_loss: 4.4367\n",
            "Epoch 26/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 4.3678 - val_loss: 4.2759\n",
            "Epoch 27/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 4.0642 - val_loss: 3.9940\n",
            "Epoch 28/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.8908 - val_loss: 3.7565\n",
            "Epoch 29/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.7368 - val_loss: 3.5318\n",
            "Epoch 30/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.5191 - val_loss: 3.5325\n",
            "Epoch 31/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.3562 - val_loss: 3.3549\n",
            "Epoch 32/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.2952 - val_loss: 3.4639\n",
            "Epoch 33/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.1616 - val_loss: 3.0898\n",
            "Epoch 34/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.1532 - val_loss: 3.0459\n",
            "Epoch 35/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.9500 - val_loss: 2.9423\n",
            "Epoch 36/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.8519 - val_loss: 2.8281\n",
            "Epoch 37/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.7550 - val_loss: 2.8058\n",
            "Epoch 38/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6766 - val_loss: 2.7387\n",
            "Epoch 39/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.6598 - val_loss: 3.2946\n",
            "Epoch 40/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.6101 - val_loss: 2.7112\n",
            "Epoch 41/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.5373 - val_loss: 2.7849\n",
            "Epoch 42/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.4876 - val_loss: 2.6936\n",
            "Epoch 43/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.4251 - val_loss: 2.3887\n",
            "Epoch 44/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.3601 - val_loss: 2.7894\n",
            "Epoch 45/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.3194 - val_loss: 2.5779\n",
            "Epoch 46/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2863 - val_loss: 2.7597\n",
            "Epoch 47/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2570 - val_loss: 2.4767\n",
            "Epoch 48/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.2686 - val_loss: 2.4638\n",
            "Epoch 49/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2175 - val_loss: 2.2364\n",
            "Epoch 50/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.2460 - val_loss: 2.2202\n",
            "Epoch 51/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.1510 - val_loss: 2.3455\n",
            "Epoch 52/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1335 - val_loss: 2.5354\n",
            "Epoch 53/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0999 - val_loss: 2.1453\n",
            "Epoch 54/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0784 - val_loss: 2.1646\n",
            "Epoch 55/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.1036 - val_loss: 2.1644\n",
            "Epoch 56/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.0401 - val_loss: 2.1593\n",
            "Epoch 57/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0074 - val_loss: 2.1202\n",
            "Epoch 58/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0318 - val_loss: 2.0559\n",
            "Epoch 59/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9607 - val_loss: 2.0828\n",
            "Epoch 60/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.0206 - val_loss: 2.1820\n",
            "Epoch 61/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9576 - val_loss: 2.0527\n",
            "Epoch 62/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.9700 - val_loss: 2.2197\n",
            "Epoch 63/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9711 - val_loss: 2.0892\n",
            "Epoch 64/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.9289 - val_loss: 2.0257\n",
            "Epoch 65/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.9098 - val_loss: 2.0836\n",
            "Epoch 66/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9040 - val_loss: 2.0778\n",
            "Epoch 67/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8779 - val_loss: 2.3385\n",
            "Epoch 68/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.8651 - val_loss: 2.1185\n",
            "Epoch 69/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9002 - val_loss: 2.0364\n",
            "Epoch 70/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8353 - val_loss: 1.9547\n",
            "Epoch 71/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8938 - val_loss: 2.6870\n",
            "Epoch 72/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8696 - val_loss: 1.8937\n",
            "Epoch 73/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8389 - val_loss: 2.2000\n",
            "Epoch 74/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8588 - val_loss: 1.9569\n",
            "Epoch 75/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8033 - val_loss: 1.9614\n",
            "Epoch 76/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8273 - val_loss: 1.8524\n",
            "Epoch 77/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8398 - val_loss: 1.9649\n",
            "Epoch 78/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7848 - val_loss: 1.9497\n",
            "Epoch 79/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8126 - val_loss: 2.0008\n",
            "Epoch 80/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7633 - val_loss: 1.8326\n",
            "Epoch 81/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7506 - val_loss: 2.1786\n",
            "Epoch 82/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8068 - val_loss: 2.0205\n",
            "Epoch 83/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8068 - val_loss: 2.0376\n",
            "Epoch 84/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7441 - val_loss: 1.9121\n",
            "Epoch 85/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7836 - val_loss: 1.9979\n",
            "Epoch 86/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8048 - val_loss: 1.8583\n",
            "Epoch 87/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7944 - val_loss: 1.8681\n",
            "Epoch 88/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7377 - val_loss: 1.8618\n",
            "Epoch 89/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7581 - val_loss: 1.8087\n",
            "Epoch 90/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 1.7143 - val_loss: 2.0252\n",
            "Epoch 91/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7081 - val_loss: 1.8283\n",
            "Epoch 92/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7074 - val_loss: 1.9870\n",
            "Epoch 93/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7279 - val_loss: 1.7695\n",
            "Epoch 94/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6903 - val_loss: 1.8782\n",
            "Epoch 95/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7006 - val_loss: 1.8694\n",
            "Epoch 96/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7329 - val_loss: 1.7587\n",
            "Epoch 97/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6828 - val_loss: 1.7875\n",
            "Epoch 98/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7042 - val_loss: 1.9400\n",
            "Epoch 99/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6955 - val_loss: 1.7917\n",
            "Epoch 100/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7252 - val_loss: 1.8068\n",
            "Epoch 101/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6951 - val_loss: 1.9247\n",
            "Epoch 102/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7041 - val_loss: 2.0233\n",
            "Epoch 103/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6803 - val_loss: 2.0463\n",
            "Epoch 104/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7176 - val_loss: 1.8354\n",
            "Epoch 105/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6528 - val_loss: 1.7965\n",
            "Epoch 106/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6602 - val_loss: 1.8318\n",
            "Epoch 107/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6708 - val_loss: 1.7257\n",
            "Epoch 108/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6575 - val_loss: 1.7696\n",
            "Epoch 109/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6831 - val_loss: 1.9932\n",
            "Epoch 110/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6723 - val_loss: 1.7874\n",
            "Epoch 111/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6337 - val_loss: 1.7514\n",
            "Epoch 112/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6497 - val_loss: 1.9219\n",
            "Epoch 113/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6439 - val_loss: 1.7385\n",
            "Epoch 114/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6364 - val_loss: 1.7545\n",
            "Epoch 115/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6649 - val_loss: 1.7531\n",
            "Epoch 116/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6608 - val_loss: 1.7217\n",
            "Epoch 117/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6346 - val_loss: 1.7213\n",
            "Epoch 118/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6351 - val_loss: 1.8805\n",
            "Epoch 119/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6171 - val_loss: 1.8797\n",
            "Epoch 120/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6321 - val_loss: 1.7581\n",
            "Epoch 121/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6260 - val_loss: 1.7011\n",
            "Epoch 122/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6078 - val_loss: 1.7807\n",
            "Epoch 123/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6156 - val_loss: 1.8002\n",
            "Epoch 124/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6629 - val_loss: 1.8460\n",
            "Epoch 125/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6642 - val_loss: 1.7563\n",
            "Epoch 126/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6341 - val_loss: 1.7213\n",
            "Epoch 127/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6424 - val_loss: 1.6993\n",
            "Epoch 128/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6380 - val_loss: 1.7432\n",
            "Epoch 129/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6544 - val_loss: 1.7179\n",
            "Epoch 130/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6436 - val_loss: 1.7008\n",
            "Epoch 131/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.5882 - val_loss: 1.7754\n",
            "Epoch 132/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.5978 - val_loss: 1.7653\n",
            "Epoch 133/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6086 - val_loss: 1.7884\n",
            "Epoch 134/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6156 - val_loss: 1.7085\n",
            "Epoch 135/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6157 - val_loss: 1.7855\n",
            "Epoch 136/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.5658 - val_loss: 1.8604\n",
            "Epoch 137/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.6028 - val_loss: 1.8201\n",
            "Epoch 138/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6487 - val_loss: 1.6953\n",
            "Epoch 139/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.5761 - val_loss: 1.7064\n",
            "Epoch 140/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.5737 - val_loss: 1.7063\n",
            "Epoch 141/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.5650 - val_loss: 1.7205\n",
            "Epoch 142/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.5771 - val_loss: 1.9092\n",
            "Epoch 143/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.5737 - val_loss: 1.7715\n",
            "Epoch 144/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.5626 - val_loss: 1.8497\n",
            "Epoch 145/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.6182 - val_loss: 1.7467\n",
            "Epoch 146/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.5663 - val_loss: 1.9379\n",
            "Epoch 147/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.5933 - val_loss: 1.8236\n",
            "Epoch 148/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.5780 - val_loss: 1.8205\n",
            "Epoch 149/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 1.6028 - val_loss: 1.7405\n",
            "Epoch 150/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 1.5753 - val_loss: 1.7924\n",
            "Epoch 151/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.5804 - val_loss: 1.9923\n",
            "Epoch 152/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 1.5649 - val_loss: 1.7162\n",
            "Epoch 153/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 1.5547 - val_loss: 1.7042\n",
            "Save file name colab_notebook_data/feature_interactions/trained_models/negcontrol_model-arch1_l1reg-0.0001_seed100_onrdk.h5\n",
            "Training model colab_notebook_data/feature_interactions/trained_models/poscontrol_model-arch1_l1reg-0.0_seed100_amzeg.h5\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_29 (Conv1D)           (None, 94, 15)            435       \n",
            "_________________________________________________________________\n",
            "conv1d_30 (Conv1D)           (None, 88, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_31 (Conv1D)           (None, 82, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_32 (Conv1D)           (None, 76, 15)            1590      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_8 ( (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 50)                800       \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 8,606\n",
            "Trainable params: 8,606\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 123.6997 - val_loss: 81.3138\n",
            "Epoch 2/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 60.2926 - val_loss: 42.9317\n",
            "Epoch 3/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 36.3364 - val_loss: 32.0413\n",
            "Epoch 4/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 28.8287 - val_loss: 26.5620\n",
            "Epoch 5/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 25.1856 - val_loss: 23.9861\n",
            "Epoch 6/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 22.9350 - val_loss: 22.0302\n",
            "Epoch 7/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 21.0645 - val_loss: 21.2959\n",
            "Epoch 8/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 19.5402 - val_loss: 20.3349\n",
            "Epoch 9/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 18.7234 - val_loss: 17.8731\n",
            "Epoch 10/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 17.2343 - val_loss: 16.6670\n",
            "Epoch 11/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 16.0393 - val_loss: 15.4258\n",
            "Epoch 12/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 14.7800 - val_loss: 14.2816\n",
            "Epoch 13/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 13.5996 - val_loss: 13.7315\n",
            "Epoch 14/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 12.0981 - val_loss: 11.8085\n",
            "Epoch 15/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 10.8767 - val_loss: 10.4888\n",
            "Epoch 16/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 10.0240 - val_loss: 9.8054\n",
            "Epoch 17/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 9.2488 - val_loss: 9.3216\n",
            "Epoch 18/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 8.7624 - val_loss: 8.4419\n",
            "Epoch 19/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 8.1169 - val_loss: 8.0240\n",
            "Epoch 20/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 7.6027 - val_loss: 7.5453\n",
            "Epoch 21/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 7.2817 - val_loss: 7.7601\n",
            "Epoch 22/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 6.8336 - val_loss: 7.0483\n",
            "Epoch 23/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 6.5804 - val_loss: 6.9304\n",
            "Epoch 24/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 6.2184 - val_loss: 6.2396\n",
            "Epoch 25/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 5.9488 - val_loss: 5.9117\n",
            "Epoch 26/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 5.7344 - val_loss: 6.0372\n",
            "Epoch 27/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 5.4610 - val_loss: 5.5901\n",
            "Epoch 28/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 5.2933 - val_loss: 5.4210\n",
            "Epoch 29/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 5.2296 - val_loss: 5.1442\n",
            "Epoch 30/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 4.9410 - val_loss: 5.0941\n",
            "Epoch 31/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 4.8794 - val_loss: 5.1287\n",
            "Epoch 32/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 4.7963 - val_loss: 4.9403\n",
            "Epoch 33/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 4.5833 - val_loss: 4.7994\n",
            "Epoch 34/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 4.5472 - val_loss: 4.8484\n",
            "Epoch 35/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 4.5448 - val_loss: 4.6197\n",
            "Epoch 36/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 4.3701 - val_loss: 4.5763\n",
            "Epoch 37/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 4.3996 - val_loss: 4.4856\n",
            "Epoch 38/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 4.2538 - val_loss: 4.4891\n",
            "Epoch 39/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 4.3297 - val_loss: 4.5275\n",
            "Epoch 40/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 4.2050 - val_loss: 4.4425\n",
            "Epoch 41/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 4.0640 - val_loss: 4.2964\n",
            "Epoch 42/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 4.0114 - val_loss: 4.2878\n",
            "Epoch 43/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.9622 - val_loss: 4.1896\n",
            "Epoch 44/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.9077 - val_loss: 4.1913\n",
            "Epoch 45/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.8460 - val_loss: 4.2108\n",
            "Epoch 46/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.8650 - val_loss: 4.1471\n",
            "Epoch 47/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.8140 - val_loss: 4.1509\n",
            "Epoch 48/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.9002 - val_loss: 4.4018\n",
            "Epoch 49/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.7300 - val_loss: 4.5669\n",
            "Epoch 50/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.7131 - val_loss: 4.3281\n",
            "Epoch 51/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.6733 - val_loss: 4.0486\n",
            "Epoch 52/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.5878 - val_loss: 3.8956\n",
            "Epoch 53/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.5608 - val_loss: 4.1270\n",
            "Epoch 54/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.5838 - val_loss: 3.9320\n",
            "Epoch 55/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.5169 - val_loss: 4.1433\n",
            "Epoch 56/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.4750 - val_loss: 4.1197\n",
            "Epoch 57/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.5021 - val_loss: 3.8390\n",
            "Epoch 58/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.3849 - val_loss: 3.9115\n",
            "Epoch 59/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.4684 - val_loss: 3.7919\n",
            "Epoch 60/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.4065 - val_loss: 3.7970\n",
            "Epoch 61/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.4727 - val_loss: 3.8315\n",
            "Epoch 62/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.2933 - val_loss: 3.7248\n",
            "Epoch 63/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.3814 - val_loss: 3.6938\n",
            "Epoch 64/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.2807 - val_loss: 3.6969\n",
            "Epoch 65/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.3050 - val_loss: 3.9415\n",
            "Epoch 66/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.2090 - val_loss: 4.1803\n",
            "Epoch 67/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.2176 - val_loss: 3.7020\n",
            "Epoch 68/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.2416 - val_loss: 3.8402\n",
            "Epoch 69/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.2976 - val_loss: 3.8705\n",
            "Epoch 70/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.1630 - val_loss: 3.5557\n",
            "Epoch 71/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.2228 - val_loss: 3.6891\n",
            "Epoch 72/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.1834 - val_loss: 3.5681\n",
            "Epoch 73/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.1489 - val_loss: 3.6411\n",
            "Epoch 74/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.0829 - val_loss: 3.5783\n",
            "Epoch 75/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.1602 - val_loss: 3.7985\n",
            "Epoch 76/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.1699 - val_loss: 3.5268\n",
            "Epoch 77/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.0366 - val_loss: 3.6118\n",
            "Epoch 78/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.1208 - val_loss: 3.6363\n",
            "Epoch 79/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.0620 - val_loss: 3.4683\n",
            "Epoch 80/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.0444 - val_loss: 3.6927\n",
            "Epoch 81/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.1068 - val_loss: 3.6571\n",
            "Epoch 82/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.1005 - val_loss: 3.5837\n",
            "Epoch 83/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.9811 - val_loss: 3.3812\n",
            "Epoch 84/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 3.0009 - val_loss: 3.4839\n",
            "Epoch 85/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.9546 - val_loss: 3.4480\n",
            "Epoch 86/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.9525 - val_loss: 3.5181\n",
            "Epoch 87/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.9659 - val_loss: 3.4495\n",
            "Epoch 88/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.9677 - val_loss: 3.7325\n",
            "Epoch 89/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.8959 - val_loss: 3.5490\n",
            "Epoch 90/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.9174 - val_loss: 3.3064\n",
            "Epoch 91/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.8364 - val_loss: 3.3123\n",
            "Epoch 92/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.7963 - val_loss: 3.2688\n",
            "Epoch 93/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.7983 - val_loss: 3.3264\n",
            "Epoch 94/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.7216 - val_loss: 3.6162\n",
            "Epoch 95/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.6723 - val_loss: 3.1018\n",
            "Epoch 96/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.6576 - val_loss: 3.1240\n",
            "Epoch 97/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.6330 - val_loss: 3.0528\n",
            "Epoch 98/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.5730 - val_loss: 3.6585\n",
            "Epoch 99/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.5936 - val_loss: 2.9103\n",
            "Epoch 100/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.5812 - val_loss: 3.0232\n",
            "Epoch 101/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.5275 - val_loss: 3.0932\n",
            "Epoch 102/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.4987 - val_loss: 2.8039\n",
            "Epoch 103/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.4215 - val_loss: 2.8059\n",
            "Epoch 104/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.4163 - val_loss: 2.9361\n",
            "Epoch 105/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.3845 - val_loss: 2.8222\n",
            "Epoch 106/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.3995 - val_loss: 2.8345\n",
            "Epoch 107/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.3530 - val_loss: 2.6967\n",
            "Epoch 108/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.3216 - val_loss: 2.8027\n",
            "Epoch 109/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.3206 - val_loss: 2.7335\n",
            "Epoch 110/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.3019 - val_loss: 2.6833\n",
            "Epoch 111/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.2702 - val_loss: 2.8748\n",
            "Epoch 112/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.2607 - val_loss: 2.6309\n",
            "Epoch 113/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.2440 - val_loss: 2.5665\n",
            "Epoch 114/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.2331 - val_loss: 2.7744\n",
            "Epoch 115/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.2453 - val_loss: 2.7293\n",
            "Epoch 116/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.1782 - val_loss: 2.6600\n",
            "Epoch 117/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.1988 - val_loss: 2.6789\n",
            "Epoch 118/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.1574 - val_loss: 2.7374\n",
            "Epoch 119/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.2200 - val_loss: 2.9039\n",
            "Epoch 120/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.1728 - val_loss: 2.6236\n",
            "Epoch 121/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.1513 - val_loss: 2.5517\n",
            "Epoch 122/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.1302 - val_loss: 3.1169\n",
            "Epoch 123/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.1964 - val_loss: 2.5629\n",
            "Epoch 124/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.0933 - val_loss: 2.4605\n",
            "Epoch 125/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.0900 - val_loss: 2.6372\n",
            "Epoch 126/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.1313 - val_loss: 2.5361\n",
            "Epoch 127/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.1054 - val_loss: 2.4333\n",
            "Epoch 128/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.0716 - val_loss: 2.4536\n",
            "Epoch 129/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.0699 - val_loss: 2.5437\n",
            "Epoch 130/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.0901 - val_loss: 2.4984\n",
            "Epoch 131/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.1382 - val_loss: 2.4839\n",
            "Epoch 132/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.0669 - val_loss: 2.9078\n",
            "Epoch 133/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.0916 - val_loss: 2.4235\n",
            "Epoch 134/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.9984 - val_loss: 2.4159\n",
            "Epoch 135/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9948 - val_loss: 2.4383\n",
            "Epoch 136/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.0379 - val_loss: 2.4446\n",
            "Epoch 137/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9768 - val_loss: 2.3507\n",
            "Epoch 138/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9846 - val_loss: 2.8155\n",
            "Epoch 139/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.9608 - val_loss: 2.3982\n",
            "Epoch 140/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.0178 - val_loss: 2.3704\n",
            "Epoch 141/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9444 - val_loss: 2.4040\n",
            "Epoch 142/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9892 - val_loss: 2.4795\n",
            "Epoch 143/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9637 - val_loss: 2.3691\n",
            "Epoch 144/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9776 - val_loss: 2.3464\n",
            "Epoch 145/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.8992 - val_loss: 2.3035\n",
            "Epoch 146/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9497 - val_loss: 2.5017\n",
            "Epoch 147/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9240 - val_loss: 2.2977\n",
            "Epoch 148/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.9944 - val_loss: 2.3712\n",
            "Epoch 149/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9331 - val_loss: 2.3272\n",
            "Epoch 150/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9205 - val_loss: 2.5029\n",
            "Epoch 151/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9062 - val_loss: 2.3799\n",
            "Epoch 152/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9215 - val_loss: 2.2664\n",
            "Epoch 153/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9077 - val_loss: 2.3051\n",
            "Epoch 154/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.8601 - val_loss: 2.3070\n",
            "Epoch 155/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.8671 - val_loss: 2.2669\n",
            "Epoch 156/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.9112 - val_loss: 2.3794\n",
            "Epoch 157/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9019 - val_loss: 2.4748\n",
            "Epoch 158/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9231 - val_loss: 2.6573\n",
            "Epoch 159/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.8481 - val_loss: 2.7490\n",
            "Epoch 160/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.8413 - val_loss: 2.3730\n",
            "Epoch 161/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.8641 - val_loss: 2.3098\n",
            "Epoch 162/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.8831 - val_loss: 2.2946\n",
            "Epoch 163/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.8489 - val_loss: 2.2347\n",
            "Epoch 164/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.8512 - val_loss: 2.2867\n",
            "Epoch 165/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9345 - val_loss: 2.2854\n",
            "Epoch 166/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7935 - val_loss: 2.3115\n",
            "Epoch 167/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8194 - val_loss: 2.2642\n",
            "Epoch 168/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8217 - val_loss: 2.3226\n",
            "Epoch 169/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.8064 - val_loss: 2.3731\n",
            "Epoch 170/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.8170 - val_loss: 2.2519\n",
            "Epoch 171/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.8014 - val_loss: 2.4029\n",
            "Epoch 172/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.8758 - val_loss: 2.3259\n",
            "Epoch 173/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7943 - val_loss: 2.2196\n",
            "Epoch 174/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.8239 - val_loss: 2.2332\n",
            "Epoch 175/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.8450 - val_loss: 2.2418\n",
            "Epoch 176/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.7684 - val_loss: 2.2781\n",
            "Epoch 177/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.7920 - val_loss: 2.2505\n",
            "Epoch 178/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7981 - val_loss: 2.2365\n",
            "Epoch 179/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7788 - val_loss: 2.2569\n",
            "Epoch 180/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8235 - val_loss: 2.2209\n",
            "Epoch 181/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.7777 - val_loss: 2.1806\n",
            "Epoch 182/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7563 - val_loss: 2.1615\n",
            "Epoch 183/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.7459 - val_loss: 2.2818\n",
            "Epoch 184/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.8094 - val_loss: 2.1610\n",
            "Epoch 185/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7926 - val_loss: 2.1947\n",
            "Epoch 186/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7601 - val_loss: 2.4443\n",
            "Epoch 187/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.7947 - val_loss: 2.2211\n",
            "Epoch 188/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7422 - val_loss: 2.1710\n",
            "Epoch 189/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.7746 - val_loss: 2.3055\n",
            "Epoch 190/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7329 - val_loss: 2.5391\n",
            "Epoch 191/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 1.7605 - val_loss: 2.1573\n",
            "Epoch 192/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7709 - val_loss: 2.1567\n",
            "Epoch 193/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7042 - val_loss: 2.1421\n",
            "Epoch 194/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.7131 - val_loss: 2.1707\n",
            "Epoch 195/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7389 - val_loss: 2.1757\n",
            "Epoch 196/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7102 - val_loss: 2.2217\n",
            "Epoch 197/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7206 - val_loss: 2.3403\n",
            "Epoch 198/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7053 - val_loss: 2.1362\n",
            "Epoch 199/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.7584 - val_loss: 2.1709\n",
            "Epoch 200/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.7325 - val_loss: 2.1538\n",
            "Epoch 201/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7051 - val_loss: 2.4915\n",
            "Epoch 202/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7347 - val_loss: 2.1428\n",
            "Epoch 203/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.6618 - val_loss: 2.4280\n",
            "Epoch 204/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.6908 - val_loss: 2.4870\n",
            "Epoch 205/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.6934 - val_loss: 2.1496\n",
            "Epoch 206/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7274 - val_loss: 2.1093\n",
            "Epoch 207/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.6367 - val_loss: 2.1015\n",
            "Epoch 208/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.6613 - val_loss: 2.1499\n",
            "Epoch 209/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7141 - val_loss: 2.1244\n",
            "Epoch 210/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.6399 - val_loss: 2.0810\n",
            "Epoch 211/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.6478 - val_loss: 2.1591\n",
            "Epoch 212/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.6566 - val_loss: 2.3767\n",
            "Epoch 213/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.6449 - val_loss: 2.0203\n",
            "Epoch 214/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.6243 - val_loss: 2.1398\n",
            "Epoch 215/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.6907 - val_loss: 2.0155\n",
            "Epoch 216/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.6037 - val_loss: 2.0922\n",
            "Epoch 217/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.6335 - val_loss: 2.0846\n",
            "Epoch 218/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.6127 - val_loss: 2.1339\n",
            "Epoch 219/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.6131 - val_loss: 2.0903\n",
            "Epoch 220/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.6334 - val_loss: 2.1207\n",
            "Epoch 221/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.6177 - val_loss: 2.1433\n",
            "Epoch 222/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.6315 - val_loss: 2.0035\n",
            "Epoch 223/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.6158 - val_loss: 2.4717\n",
            "Epoch 224/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.6200 - val_loss: 2.0210\n",
            "Epoch 225/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.5887 - val_loss: 1.9777\n",
            "Epoch 226/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.6473 - val_loss: 2.0760\n",
            "Epoch 227/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.6060 - val_loss: 2.0521\n",
            "Epoch 228/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.5951 - val_loss: 2.2712\n",
            "Epoch 229/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.5550 - val_loss: 1.9673\n",
            "Epoch 230/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.5426 - val_loss: 2.1643\n",
            "Epoch 231/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.6380 - val_loss: 2.0016\n",
            "Epoch 232/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.5693 - val_loss: 1.9827\n",
            "Epoch 233/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.5533 - val_loss: 2.0574\n",
            "Epoch 234/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.5629 - val_loss: 2.1104\n",
            "Epoch 235/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.5541 - val_loss: 2.0547\n",
            "Epoch 236/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.5846 - val_loss: 2.0129\n",
            "Epoch 237/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.5641 - val_loss: 2.0775\n",
            "Epoch 238/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.5688 - val_loss: 1.9904\n",
            "Epoch 239/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.5506 - val_loss: 2.1080\n",
            "Epoch 240/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.5525 - val_loss: 2.0997\n",
            "Epoch 241/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.5269 - val_loss: 2.2663\n",
            "Epoch 242/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.5365 - val_loss: 2.0021\n",
            "Epoch 243/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 1.5412 - val_loss: 1.9837\n",
            "Epoch 244/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.5753 - val_loss: 2.0943\n",
            "Save file name colab_notebook_data/feature_interactions/trained_models/poscontrol_model-arch1_l1reg-0.0_seed100_amzeg.h5\n",
            "Training model colab_notebook_data/feature_interactions/trained_models/negcontrol_model-arch1_l1reg-0.0_seed100_nespm.h5\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_37 (Conv1D)           (None, 94, 15)            435       \n",
            "_________________________________________________________________\n",
            "conv1d_38 (Conv1D)           (None, 88, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_39 (Conv1D)           (None, 82, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_40 (Conv1D)           (None, 76, 15)            1590      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_10  (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 50)                800       \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 8,606\n",
            "Trainable params: 8,606\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 99.8670 - val_loss: 77.3504\n",
            "Epoch 2/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 73.3895 - val_loss: 69.6633\n",
            "Epoch 3/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 56.2218 - val_loss: 42.8315\n",
            "Epoch 4/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 35.2321 - val_loss: 30.4831\n",
            "Epoch 5/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 26.6099 - val_loss: 24.3141\n",
            "Epoch 6/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 22.5421 - val_loss: 20.7058\n",
            "Epoch 7/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 19.4988 - val_loss: 18.6331\n",
            "Epoch 8/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 17.2779 - val_loss: 17.4129\n",
            "Epoch 9/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 15.2327 - val_loss: 14.9104\n",
            "Epoch 10/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 13.6292 - val_loss: 13.0106\n",
            "Epoch 11/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 12.5492 - val_loss: 12.2152\n",
            "Epoch 12/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 11.7374 - val_loss: 11.2139\n",
            "Epoch 13/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 10.9766 - val_loss: 10.6796\n",
            "Epoch 14/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 10.3005 - val_loss: 9.8394\n",
            "Epoch 15/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 9.6450 - val_loss: 9.2606\n",
            "Epoch 16/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 8.8678 - val_loss: 8.7411\n",
            "Epoch 17/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 8.3225 - val_loss: 8.0193\n",
            "Epoch 18/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 7.5060 - val_loss: 7.1461\n",
            "Epoch 19/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 6.6934 - val_loss: 6.3606\n",
            "Epoch 20/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 6.1500 - val_loss: 5.8556\n",
            "Epoch 21/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 5.7718 - val_loss: 5.4089\n",
            "Epoch 22/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 5.2042 - val_loss: 5.2173\n",
            "Epoch 23/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 5.0225 - val_loss: 4.9683\n",
            "Epoch 24/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 4.6278 - val_loss: 4.6341\n",
            "Epoch 25/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 4.4264 - val_loss: 4.4949\n",
            "Epoch 26/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 4.2053 - val_loss: 4.1060\n",
            "Epoch 27/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 4.0016 - val_loss: 3.9267\n",
            "Epoch 28/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.8978 - val_loss: 3.8805\n",
            "Epoch 29/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.7773 - val_loss: 3.8845\n",
            "Epoch 30/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.6255 - val_loss: 3.5443\n",
            "Epoch 31/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.5201 - val_loss: 3.5201\n",
            "Epoch 32/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 3.3919 - val_loss: 3.7320\n",
            "Epoch 33/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.3067 - val_loss: 3.2677\n",
            "Epoch 34/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.3209 - val_loss: 3.3073\n",
            "Epoch 35/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.1736 - val_loss: 3.3810\n",
            "Epoch 36/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.1057 - val_loss: 3.0710\n",
            "Epoch 37/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 3.0297 - val_loss: 3.0501\n",
            "Epoch 38/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.9717 - val_loss: 2.9767\n",
            "Epoch 39/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.9549 - val_loss: 3.7570\n",
            "Epoch 40/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.9952 - val_loss: 2.9947\n",
            "Epoch 41/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.7938 - val_loss: 3.0981\n",
            "Epoch 42/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 2.8336 - val_loss: 3.0036\n",
            "Epoch 43/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.7696 - val_loss: 2.7874\n",
            "Epoch 44/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.6886 - val_loss: 3.0913\n",
            "Epoch 45/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.6594 - val_loss: 2.8807\n",
            "Epoch 46/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.7004 - val_loss: 2.7111\n",
            "Epoch 47/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.6065 - val_loss: 2.8122\n",
            "Epoch 48/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.5909 - val_loss: 2.8223\n",
            "Epoch 49/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.6064 - val_loss: 2.6395\n",
            "Epoch 50/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.6151 - val_loss: 2.6882\n",
            "Epoch 51/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.5697 - val_loss: 2.5778\n",
            "Epoch 52/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.5527 - val_loss: 2.7047\n",
            "Epoch 53/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.4497 - val_loss: 2.6876\n",
            "Epoch 54/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.4814 - val_loss: 2.5955\n",
            "Epoch 55/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.5071 - val_loss: 2.4848\n",
            "Epoch 56/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.3976 - val_loss: 2.4354\n",
            "Epoch 57/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.4197 - val_loss: 2.4676\n",
            "Epoch 58/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.4102 - val_loss: 2.6446\n",
            "Epoch 59/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.3175 - val_loss: 2.3675\n",
            "Epoch 60/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.3215 - val_loss: 2.4319\n",
            "Epoch 61/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.3101 - val_loss: 2.5966\n",
            "Epoch 62/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.2745 - val_loss: 2.4943\n",
            "Epoch 63/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.2878 - val_loss: 2.3447\n",
            "Epoch 64/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.2570 - val_loss: 2.2997\n",
            "Epoch 65/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.2267 - val_loss: 2.4045\n",
            "Epoch 66/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.1793 - val_loss: 2.2609\n",
            "Epoch 67/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.1693 - val_loss: 2.5478\n",
            "Epoch 68/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.1765 - val_loss: 2.3701\n",
            "Epoch 69/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.1400 - val_loss: 2.2048\n",
            "Epoch 70/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.1101 - val_loss: 2.3022\n",
            "Epoch 71/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.1572 - val_loss: 2.2596\n",
            "Epoch 72/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.1352 - val_loss: 2.3648\n",
            "Epoch 73/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.1312 - val_loss: 2.3913\n",
            "Epoch 74/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.0655 - val_loss: 2.2424\n",
            "Epoch 75/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.0563 - val_loss: 2.6195\n",
            "Epoch 76/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.0566 - val_loss: 2.1381\n",
            "Epoch 77/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.0787 - val_loss: 2.0979\n",
            "Epoch 78/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.0026 - val_loss: 2.1379\n",
            "Epoch 79/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.0336 - val_loss: 2.1035\n",
            "Epoch 80/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.9875 - val_loss: 2.0553\n",
            "Epoch 81/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.0111 - val_loss: 2.5536\n",
            "Epoch 82/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 2.0075 - val_loss: 2.1952\n",
            "Epoch 83/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 2.0178 - val_loss: 2.0477\n",
            "Epoch 84/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9250 - val_loss: 2.1853\n",
            "Epoch 85/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.9651 - val_loss: 2.0296\n",
            "Epoch 86/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.9108 - val_loss: 2.0682\n",
            "Epoch 87/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.9409 - val_loss: 2.0257\n",
            "Epoch 88/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.9437 - val_loss: 2.0951\n",
            "Epoch 89/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.9083 - val_loss: 2.2812\n",
            "Epoch 90/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8590 - val_loss: 2.2477\n",
            "Epoch 91/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8820 - val_loss: 2.0705\n",
            "Epoch 92/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.8615 - val_loss: 1.9975\n",
            "Epoch 93/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.8583 - val_loss: 2.0542\n",
            "Epoch 94/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.8334 - val_loss: 1.9021\n",
            "Epoch 95/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.8497 - val_loss: 2.0505\n",
            "Epoch 96/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.8495 - val_loss: 1.9133\n",
            "Epoch 97/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.8108 - val_loss: 1.9155\n",
            "Epoch 98/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.8269 - val_loss: 2.0896\n",
            "Epoch 99/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.8326 - val_loss: 1.8990\n",
            "Epoch 100/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.8051 - val_loss: 1.9213\n",
            "Epoch 101/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7894 - val_loss: 1.9769\n",
            "Epoch 102/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.7721 - val_loss: 1.8692\n",
            "Epoch 103/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7882 - val_loss: 2.1816\n",
            "Epoch 104/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.7971 - val_loss: 1.9473\n",
            "Epoch 105/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.7124 - val_loss: 1.9119\n",
            "Epoch 106/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.7639 - val_loss: 1.8061\n",
            "Epoch 107/1000\n",
            "40000/40000 [==============================] - 2s 44us/step - loss: 1.7325 - val_loss: 1.9725\n",
            "Epoch 108/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7328 - val_loss: 1.8406\n",
            "Epoch 109/1000\n",
            "40000/40000 [==============================] - 2s 44us/step - loss: 1.7370 - val_loss: 1.8204\n",
            "Epoch 110/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.7690 - val_loss: 1.8725\n",
            "Epoch 111/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.6941 - val_loss: 1.8886\n",
            "Epoch 112/1000\n",
            "40000/40000 [==============================] - 2s 47us/step - loss: 1.7386 - val_loss: 2.1114\n",
            "Epoch 113/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.7148 - val_loss: 1.8112\n",
            "Epoch 114/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.7205 - val_loss: 1.9441\n",
            "Epoch 115/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.7084 - val_loss: 1.8358\n",
            "Epoch 116/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.6854 - val_loss: 1.9200\n",
            "Epoch 117/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.6710 - val_loss: 1.8104\n",
            "Epoch 118/1000\n",
            "40000/40000 [==============================] - 2s 46us/step - loss: 1.6817 - val_loss: 1.8634\n",
            "Epoch 119/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.6729 - val_loss: 1.9442\n",
            "Epoch 120/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.6588 - val_loss: 1.8557\n",
            "Epoch 121/1000\n",
            "40000/40000 [==============================] - 2s 45us/step - loss: 1.6956 - val_loss: 1.9959\n",
            "Save file name colab_notebook_data/feature_interactions/trained_models/negcontrol_model-arch1_l1reg-0.0_seed100_nespm.h5\n",
            "Training model colab_notebook_data/feature_interactions/trained_models/poscontrol_model-arch2_l1reg-0.001_seed100_ebzhv.h5\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_41 (Conv1D)           (None, 94, 15)            435       \n",
            "_________________________________________________________________\n",
            "conv1d_42 (Conv1D)           (None, 88, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_43 (Conv1D)           (None, 82, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_44 (Conv1D)           (None, 76, 15)            1590      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_11  (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 30)                480       \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 7,576\n",
            "Trainable params: 7,576\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "40000/40000 [==============================] - 2s 58us/step - loss: 111.6350 - val_loss: 84.3808\n",
            "Epoch 2/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 70.2751 - val_loss: 52.3480\n",
            "Epoch 3/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 43.2137 - val_loss: 38.6902\n",
            "Epoch 4/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 31.9104 - val_loss: 28.2543\n",
            "Epoch 5/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 26.4876 - val_loss: 25.3617\n",
            "Epoch 6/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 23.6293 - val_loss: 22.5432\n",
            "Epoch 7/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 21.3513 - val_loss: 20.8686\n",
            "Epoch 8/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 19.1530 - val_loss: 18.3272\n",
            "Epoch 9/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 17.4537 - val_loss: 16.6844\n",
            "Epoch 10/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 15.7082 - val_loss: 15.2667\n",
            "Epoch 11/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 14.3107 - val_loss: 14.3136\n",
            "Epoch 12/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 13.2666 - val_loss: 13.1712\n",
            "Epoch 13/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 12.3581 - val_loss: 12.7130\n",
            "Epoch 14/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 11.8987 - val_loss: 11.8056\n",
            "Epoch 15/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 11.2777 - val_loss: 12.0490\n",
            "Epoch 16/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 10.8393 - val_loss: 11.1447\n",
            "Epoch 17/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 10.1358 - val_loss: 9.7757\n",
            "Epoch 18/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 8.9396 - val_loss: 8.6249\n",
            "Epoch 19/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 8.2683 - val_loss: 8.5533\n",
            "Epoch 20/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 7.9227 - val_loss: 8.0742\n",
            "Epoch 21/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 7.7790 - val_loss: 7.9316\n",
            "Epoch 22/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 7.5807 - val_loss: 7.6611\n",
            "Epoch 23/1000\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 7.3871 - val_loss: 7.7107\n",
            "Epoch 24/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 7.3101 - val_loss: 7.6313\n",
            "Epoch 25/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 7.1919 - val_loss: 7.3240\n",
            "Epoch 26/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 7.0989 - val_loss: 7.4162\n",
            "Epoch 27/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 6.9799 - val_loss: 7.0577\n",
            "Epoch 28/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 6.7990 - val_loss: 6.9219\n",
            "Epoch 29/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 6.6602 - val_loss: 6.9271\n",
            "Epoch 30/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 6.3520 - val_loss: 6.3637\n",
            "Epoch 31/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 6.1532 - val_loss: 6.1021\n",
            "Epoch 32/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 5.9734 - val_loss: 6.0104\n",
            "Epoch 33/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 5.6661 - val_loss: 6.5108\n",
            "Epoch 34/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 5.5675 - val_loss: 5.6440\n",
            "Epoch 35/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 5.4775 - val_loss: 5.4053\n",
            "Epoch 36/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 5.3130 - val_loss: 5.5670\n",
            "Epoch 37/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 5.1983 - val_loss: 5.2166\n",
            "Epoch 38/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 5.0596 - val_loss: 5.2456\n",
            "Epoch 39/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.9076 - val_loss: 5.1701\n",
            "Epoch 40/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 4.7331 - val_loss: 5.1439\n",
            "Epoch 41/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 4.6675 - val_loss: 4.6468\n",
            "Epoch 42/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 4.4511 - val_loss: 4.5523\n",
            "Epoch 43/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 4.3677 - val_loss: 4.6376\n",
            "Epoch 44/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.3501 - val_loss: 4.4076\n",
            "Epoch 45/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 4.2453 - val_loss: 4.8696\n",
            "Epoch 46/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.2304 - val_loss: 4.6747\n",
            "Epoch 47/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.0747 - val_loss: 4.1515\n",
            "Epoch 48/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.0288 - val_loss: 4.4945\n",
            "Epoch 49/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.0046 - val_loss: 5.3587\n",
            "Epoch 50/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.9779 - val_loss: 4.1690\n",
            "Epoch 51/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.9496 - val_loss: 3.9651\n",
            "Epoch 52/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.8326 - val_loss: 4.0907\n",
            "Epoch 53/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.7646 - val_loss: 3.8176\n",
            "Epoch 54/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.7827 - val_loss: 3.9629\n",
            "Epoch 55/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.8271 - val_loss: 4.4259\n",
            "Epoch 56/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.6944 - val_loss: 3.9000\n",
            "Epoch 57/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.6437 - val_loss: 3.9162\n",
            "Epoch 58/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.6225 - val_loss: 3.7201\n",
            "Epoch 59/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.5998 - val_loss: 3.7010\n",
            "Epoch 60/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.5197 - val_loss: 3.7582\n",
            "Epoch 61/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.5669 - val_loss: 3.7130\n",
            "Epoch 62/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.5165 - val_loss: 3.5887\n",
            "Epoch 63/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.4352 - val_loss: 3.6181\n",
            "Epoch 64/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.4401 - val_loss: 3.7279\n",
            "Epoch 65/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.4720 - val_loss: 3.7040\n",
            "Epoch 66/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.3691 - val_loss: 3.5374\n",
            "Epoch 67/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.3104 - val_loss: 3.7860\n",
            "Epoch 68/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.3828 - val_loss: 3.4022\n",
            "Epoch 69/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.2623 - val_loss: 3.6048\n",
            "Epoch 70/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 3.3092 - val_loss: 3.6407\n",
            "Epoch 71/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.2389 - val_loss: 3.4046\n",
            "Epoch 72/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.2387 - val_loss: 4.3094\n",
            "Epoch 73/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.2114 - val_loss: 3.4339\n",
            "Epoch 74/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.1781 - val_loss: 3.3654\n",
            "Epoch 75/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.1989 - val_loss: 3.3119\n",
            "Epoch 76/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.1333 - val_loss: 3.3056\n",
            "Epoch 77/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.1136 - val_loss: 3.2861\n",
            "Epoch 78/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.1162 - val_loss: 3.2245\n",
            "Epoch 79/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.1154 - val_loss: 3.4688\n",
            "Epoch 80/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.0501 - val_loss: 3.2051\n",
            "Epoch 81/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 3.0841 - val_loss: 3.2518\n",
            "Epoch 82/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.0383 - val_loss: 3.2366\n",
            "Epoch 83/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.0982 - val_loss: 3.1571\n",
            "Epoch 84/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.0044 - val_loss: 3.1804\n",
            "Epoch 85/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9758 - val_loss: 3.1787\n",
            "Epoch 86/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.0341 - val_loss: 3.1776\n",
            "Epoch 87/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 3.0351 - val_loss: 3.1399\n",
            "Epoch 88/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.9691 - val_loss: 3.2787\n",
            "Epoch 89/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.9828 - val_loss: 3.1114\n",
            "Epoch 90/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9256 - val_loss: 3.0244\n",
            "Epoch 91/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.8589 - val_loss: 3.1138\n",
            "Epoch 92/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8720 - val_loss: 2.9959\n",
            "Epoch 93/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9006 - val_loss: 3.0382\n",
            "Epoch 94/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8540 - val_loss: 3.0438\n",
            "Epoch 95/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8455 - val_loss: 3.0831\n",
            "Epoch 96/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.8346 - val_loss: 3.0559\n",
            "Epoch 97/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8055 - val_loss: 2.9746\n",
            "Epoch 98/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9030 - val_loss: 2.9672\n",
            "Epoch 99/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8010 - val_loss: 3.0508\n",
            "Epoch 100/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7679 - val_loss: 3.2066\n",
            "Epoch 101/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7709 - val_loss: 2.8938\n",
            "Epoch 102/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.7769 - val_loss: 2.8946\n",
            "Epoch 103/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7681 - val_loss: 3.1661\n",
            "Epoch 104/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7618 - val_loss: 2.9336\n",
            "Epoch 105/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7571 - val_loss: 2.8235\n",
            "Epoch 106/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7596 - val_loss: 3.0265\n",
            "Epoch 107/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7560 - val_loss: 2.8549\n",
            "Epoch 108/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7352 - val_loss: 3.0707\n",
            "Epoch 109/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.7985 - val_loss: 2.8856\n",
            "Epoch 110/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7000 - val_loss: 2.8357\n",
            "Epoch 111/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6763 - val_loss: 2.7901\n",
            "Epoch 112/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7068 - val_loss: 3.1166\n",
            "Epoch 113/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.7184 - val_loss: 2.7754\n",
            "Epoch 114/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6692 - val_loss: 2.9290\n",
            "Epoch 115/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6914 - val_loss: 2.9474\n",
            "Epoch 116/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6492 - val_loss: 2.8861\n",
            "Epoch 117/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6516 - val_loss: 2.8534\n",
            "Epoch 118/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6427 - val_loss: 2.8970\n",
            "Epoch 119/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6438 - val_loss: 2.7722\n",
            "Epoch 120/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6425 - val_loss: 3.0344\n",
            "Epoch 121/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6707 - val_loss: 2.8213\n",
            "Epoch 122/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6156 - val_loss: 2.7610\n",
            "Epoch 123/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6445 - val_loss: 2.8071\n",
            "Epoch 124/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6640 - val_loss: 2.7483\n",
            "Epoch 125/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6134 - val_loss: 2.8107\n",
            "Epoch 126/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6173 - val_loss: 2.9403\n",
            "Epoch 127/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.6302 - val_loss: 2.7208\n",
            "Epoch 128/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.6023 - val_loss: 2.8920\n",
            "Epoch 129/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6157 - val_loss: 2.9797\n",
            "Epoch 130/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.6525 - val_loss: 2.9498\n",
            "Epoch 131/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.5793 - val_loss: 2.8005\n",
            "Epoch 132/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5501 - val_loss: 2.6817\n",
            "Epoch 133/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.5341 - val_loss: 2.6822\n",
            "Epoch 134/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5503 - val_loss: 2.6717\n",
            "Epoch 135/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.5399 - val_loss: 2.7768\n",
            "Epoch 136/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6009 - val_loss: 2.7122\n",
            "Epoch 137/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5375 - val_loss: 2.8618\n",
            "Epoch 138/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5517 - val_loss: 2.6701\n",
            "Epoch 139/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5373 - val_loss: 2.7515\n",
            "Epoch 140/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5683 - val_loss: 2.6205\n",
            "Epoch 141/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5532 - val_loss: 2.8342\n",
            "Epoch 142/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.5944 - val_loss: 2.7107\n",
            "Epoch 143/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5351 - val_loss: 2.7181\n",
            "Epoch 144/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.5432 - val_loss: 2.7023\n",
            "Epoch 145/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.5563 - val_loss: 2.6483\n",
            "Epoch 146/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.5126 - val_loss: 2.6706\n",
            "Epoch 147/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4983 - val_loss: 2.6969\n",
            "Epoch 148/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5235 - val_loss: 2.6442\n",
            "Epoch 149/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4618 - val_loss: 2.6456\n",
            "Epoch 150/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4953 - val_loss: 2.6259\n",
            "Epoch 151/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5418 - val_loss: 2.8593\n",
            "Epoch 152/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4615 - val_loss: 2.5950\n",
            "Epoch 153/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5773 - val_loss: 2.7639\n",
            "Epoch 154/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.4628 - val_loss: 2.7234\n",
            "Epoch 155/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4639 - val_loss: 2.6342\n",
            "Epoch 156/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4517 - val_loss: 2.5921\n",
            "Epoch 157/1000\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 2.4899 - val_loss: 2.6677\n",
            "Epoch 158/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4652 - val_loss: 2.6407\n",
            "Epoch 159/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4524 - val_loss: 2.6262\n",
            "Epoch 160/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4664 - val_loss: 2.5895\n",
            "Epoch 161/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4482 - val_loss: 2.5829\n",
            "Epoch 162/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4546 - val_loss: 2.5801\n",
            "Epoch 163/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4948 - val_loss: 2.5809\n",
            "Epoch 164/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4737 - val_loss: 2.5647\n",
            "Epoch 165/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4735 - val_loss: 2.6701\n",
            "Epoch 166/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4224 - val_loss: 2.5583\n",
            "Epoch 167/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4181 - val_loss: 2.7526\n",
            "Epoch 168/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4221 - val_loss: 2.6130\n",
            "Epoch 169/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4613 - val_loss: 2.6365\n",
            "Epoch 170/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4583 - val_loss: 2.5837\n",
            "Epoch 171/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4340 - val_loss: 2.6597\n",
            "Epoch 172/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4081 - val_loss: 2.5236\n",
            "Epoch 173/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4163 - val_loss: 2.5347\n",
            "Epoch 174/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4599 - val_loss: 2.6446\n",
            "Epoch 175/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4813 - val_loss: 2.5426\n",
            "Epoch 176/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3961 - val_loss: 2.5465\n",
            "Epoch 177/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4139 - val_loss: 2.5297\n",
            "Epoch 178/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.3981 - val_loss: 2.5218\n",
            "Epoch 179/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4079 - val_loss: 2.5228\n",
            "Epoch 180/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4683 - val_loss: 2.6106\n",
            "Epoch 181/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4000 - val_loss: 2.5488\n",
            "Epoch 182/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4192 - val_loss: 2.4794\n",
            "Epoch 183/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3779 - val_loss: 2.5110\n",
            "Epoch 184/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3834 - val_loss: 2.5938\n",
            "Epoch 185/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3926 - val_loss: 2.5657\n",
            "Epoch 186/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3863 - val_loss: 2.5570\n",
            "Epoch 187/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4048 - val_loss: 2.5090\n",
            "Epoch 188/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3645 - val_loss: 2.4950\n",
            "Epoch 189/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3833 - val_loss: 2.4877\n",
            "Epoch 190/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3754 - val_loss: 2.5150\n",
            "Epoch 191/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3654 - val_loss: 2.5755\n",
            "Epoch 192/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4087 - val_loss: 2.5216\n",
            "Epoch 193/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3730 - val_loss: 2.5065\n",
            "Epoch 194/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3399 - val_loss: 2.5131\n",
            "Epoch 195/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3287 - val_loss: 2.6472\n",
            "Epoch 196/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3711 - val_loss: 2.5343\n",
            "Epoch 197/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3577 - val_loss: 2.5511\n",
            "Save file name colab_notebook_data/feature_interactions/trained_models/poscontrol_model-arch2_l1reg-0.001_seed100_ebzhv.h5\n",
            "Training model colab_notebook_data/feature_interactions/trained_models/negcontrol_model-arch2_l1reg-0.001_seed100_paesj.h5\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_49 (Conv1D)           (None, 94, 15)            435       \n",
            "_________________________________________________________________\n",
            "conv1d_50 (Conv1D)           (None, 88, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_51 (Conv1D)           (None, 82, 15)            1590      \n",
            "_________________________________________________________________\n",
            "conv1d_52 (Conv1D)           (None, 76, 15)            1590      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_13  (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 30)                480       \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 7,576\n",
            "Trainable params: 7,576\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "40000/40000 [==============================] - 2s 58us/step - loss: 112.9179 - val_loss: 76.3137\n",
            "Epoch 2/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 69.1038 - val_loss: 56.6715\n",
            "Epoch 3/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 45.2542 - val_loss: 38.2515\n",
            "Epoch 4/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 32.5173 - val_loss: 29.1415\n",
            "Epoch 5/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 27.2388 - val_loss: 25.7478\n",
            "Epoch 6/1000\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 24.1285 - val_loss: 23.2560\n",
            "Epoch 7/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 21.5483 - val_loss: 21.9083\n",
            "Epoch 8/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 19.2712 - val_loss: 18.6669\n",
            "Epoch 9/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 17.3992 - val_loss: 16.3803\n",
            "Epoch 10/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 15.4332 - val_loss: 15.1146\n",
            "Epoch 11/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 14.3396 - val_loss: 13.8739\n",
            "Epoch 12/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 13.2354 - val_loss: 12.9968\n",
            "Epoch 13/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 12.2887 - val_loss: 12.6831\n",
            "Epoch 14/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 11.4119 - val_loss: 11.4378\n",
            "Epoch 15/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 10.5310 - val_loss: 10.4656\n",
            "Epoch 16/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 9.9299 - val_loss: 10.4812\n",
            "Epoch 17/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 9.2946 - val_loss: 8.8305\n",
            "Epoch 18/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 8.6261 - val_loss: 8.2646\n",
            "Epoch 19/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 8.0401 - val_loss: 7.9647\n",
            "Epoch 20/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 7.6056 - val_loss: 7.3021\n",
            "Epoch 21/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 7.0940 - val_loss: 6.9380\n",
            "Epoch 22/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 6.6611 - val_loss: 6.4413\n",
            "Epoch 23/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 6.2913 - val_loss: 6.5963\n",
            "Epoch 24/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 5.9033 - val_loss: 5.7063\n",
            "Epoch 25/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 5.5107 - val_loss: 5.2734\n",
            "Epoch 26/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 5.2497 - val_loss: 5.0386\n",
            "Epoch 27/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 5.0081 - val_loss: 4.7871\n",
            "Epoch 28/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 4.8711 - val_loss: 4.7385\n",
            "Epoch 29/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 4.5328 - val_loss: 4.3704\n",
            "Epoch 30/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.4288 - val_loss: 4.3995\n",
            "Epoch 31/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.2560 - val_loss: 4.8425\n",
            "Epoch 32/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.1647 - val_loss: 4.3535\n",
            "Epoch 33/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 4.0542 - val_loss: 4.1637\n",
            "Epoch 34/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 4.0979 - val_loss: 4.0597\n",
            "Epoch 35/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.8907 - val_loss: 4.0317\n",
            "Epoch 36/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.8524 - val_loss: 3.6748\n",
            "Epoch 37/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.7267 - val_loss: 3.6537\n",
            "Epoch 38/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.7858 - val_loss: 3.7009\n",
            "Epoch 39/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.6669 - val_loss: 3.5245\n",
            "Epoch 40/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.5983 - val_loss: 3.5330\n",
            "Epoch 41/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.6165 - val_loss: 3.6861\n",
            "Epoch 42/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 3.5244 - val_loss: 3.5794\n",
            "Epoch 43/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.4500 - val_loss: 3.4276\n",
            "Epoch 44/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.4275 - val_loss: 3.3869\n",
            "Epoch 45/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.3779 - val_loss: 3.4808\n",
            "Epoch 46/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.3591 - val_loss: 3.6119\n",
            "Epoch 47/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.3446 - val_loss: 3.3625\n",
            "Epoch 48/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.3543 - val_loss: 3.3340\n",
            "Epoch 49/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.2826 - val_loss: 4.0362\n",
            "Epoch 50/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.3696 - val_loss: 3.2643\n",
            "Epoch 51/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.2916 - val_loss: 3.2232\n",
            "Epoch 52/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.2414 - val_loss: 3.1547\n",
            "Epoch 53/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.2173 - val_loss: 3.1784\n",
            "Epoch 54/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.1684 - val_loss: 3.3404\n",
            "Epoch 55/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.1850 - val_loss: 3.0861\n",
            "Epoch 56/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.1243 - val_loss: 3.1821\n",
            "Epoch 57/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.1235 - val_loss: 3.4643\n",
            "Epoch 58/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.1143 - val_loss: 3.0614\n",
            "Epoch 59/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.1095 - val_loss: 3.0538\n",
            "Epoch 60/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.0816 - val_loss: 3.4088\n",
            "Epoch 61/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.0818 - val_loss: 3.1249\n",
            "Epoch 62/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.0361 - val_loss: 3.2210\n",
            "Epoch 63/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.1141 - val_loss: 3.9599\n",
            "Epoch 64/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 3.0992 - val_loss: 2.9951\n",
            "Epoch 65/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 3.0285 - val_loss: 3.1042\n",
            "Epoch 66/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9563 - val_loss: 2.9612\n",
            "Epoch 67/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9382 - val_loss: 3.2522\n",
            "Epoch 68/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9414 - val_loss: 3.6532\n",
            "Epoch 69/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.9948 - val_loss: 2.9330\n",
            "Epoch 70/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9329 - val_loss: 2.9959\n",
            "Epoch 71/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.9667 - val_loss: 3.1141\n",
            "Epoch 72/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.9289 - val_loss: 2.8958\n",
            "Epoch 73/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9106 - val_loss: 3.2594\n",
            "Epoch 74/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9088 - val_loss: 2.9446\n",
            "Epoch 75/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.9607 - val_loss: 3.1961\n",
            "Epoch 76/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8795 - val_loss: 2.9719\n",
            "Epoch 77/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8910 - val_loss: 3.1744\n",
            "Epoch 78/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8545 - val_loss: 2.9625\n",
            "Epoch 79/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.9160 - val_loss: 2.8548\n",
            "Epoch 80/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8106 - val_loss: 2.9363\n",
            "Epoch 81/1000\n",
            "40000/40000 [==============================] - 2s 48us/step - loss: 2.8288 - val_loss: 2.8490\n",
            "Epoch 82/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8498 - val_loss: 2.8706\n",
            "Epoch 83/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.8625 - val_loss: 3.1464\n",
            "Epoch 84/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.8010 - val_loss: 2.9273\n",
            "Epoch 85/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.8130 - val_loss: 2.8593\n",
            "Epoch 86/1000\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 2.8116 - val_loss: 2.8063\n",
            "Epoch 87/1000\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 2.7619 - val_loss: 2.7551\n",
            "Epoch 88/1000\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 2.7695 - val_loss: 2.9064\n",
            "Epoch 89/1000\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 2.8234 - val_loss: 2.7918\n",
            "Epoch 90/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.7665 - val_loss: 2.8207\n",
            "Epoch 91/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.7569 - val_loss: 2.8754\n",
            "Epoch 92/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.7578 - val_loss: 2.7739\n",
            "Epoch 93/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.7706 - val_loss: 2.9221\n",
            "Epoch 94/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6946 - val_loss: 2.7117\n",
            "Epoch 95/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7164 - val_loss: 2.7503\n",
            "Epoch 96/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7156 - val_loss: 2.7799\n",
            "Epoch 97/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.7327 - val_loss: 2.7900\n",
            "Epoch 98/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.7366 - val_loss: 2.8539\n",
            "Epoch 99/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.7140 - val_loss: 2.7500\n",
            "Epoch 100/1000\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 2.6823 - val_loss: 2.7515\n",
            "Epoch 101/1000\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 2.7099 - val_loss: 3.3362\n",
            "Epoch 102/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.7364 - val_loss: 2.8366\n",
            "Epoch 103/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.7076 - val_loss: 2.8914\n",
            "Epoch 104/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6804 - val_loss: 2.9334\n",
            "Epoch 105/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6442 - val_loss: 2.6744\n",
            "Epoch 106/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6530 - val_loss: 2.7763\n",
            "Epoch 107/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6697 - val_loss: 2.7089\n",
            "Epoch 108/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6362 - val_loss: 2.6599\n",
            "Epoch 109/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6643 - val_loss: 2.7317\n",
            "Epoch 110/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6740 - val_loss: 2.6619\n",
            "Epoch 111/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6093 - val_loss: 2.6783\n",
            "Epoch 112/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6392 - val_loss: 2.7664\n",
            "Epoch 113/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6182 - val_loss: 2.7602\n",
            "Epoch 114/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6129 - val_loss: 2.6599\n",
            "Epoch 115/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6164 - val_loss: 2.6699\n",
            "Epoch 116/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6379 - val_loss: 2.7028\n",
            "Epoch 117/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5607 - val_loss: 2.6880\n",
            "Epoch 118/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5944 - val_loss: 2.6483\n",
            "Epoch 119/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5994 - val_loss: 2.8061\n",
            "Epoch 120/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.6372 - val_loss: 2.6158\n",
            "Epoch 121/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5782 - val_loss: 2.5875\n",
            "Epoch 122/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5571 - val_loss: 2.5764\n",
            "Epoch 123/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5857 - val_loss: 2.6099\n",
            "Epoch 124/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5766 - val_loss: 2.7189\n",
            "Epoch 125/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.6156 - val_loss: 2.7279\n",
            "Epoch 126/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5381 - val_loss: 2.5541\n",
            "Epoch 127/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5450 - val_loss: 2.5608\n",
            "Epoch 128/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5981 - val_loss: 2.6672\n",
            "Epoch 129/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5304 - val_loss: 2.5705\n",
            "Epoch 130/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5754 - val_loss: 2.5963\n",
            "Epoch 131/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.5273 - val_loss: 2.5758\n",
            "Epoch 132/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.5058 - val_loss: 2.5827\n",
            "Epoch 133/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5270 - val_loss: 2.6421\n",
            "Epoch 134/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5732 - val_loss: 2.6584\n",
            "Epoch 135/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.5345 - val_loss: 2.5951\n",
            "Epoch 136/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5126 - val_loss: 2.6133\n",
            "Epoch 137/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.5044 - val_loss: 2.8850\n",
            "Epoch 138/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5254 - val_loss: 2.6373\n",
            "Epoch 139/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4599 - val_loss: 2.5411\n",
            "Epoch 140/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.5275 - val_loss: 2.5436\n",
            "Epoch 141/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4683 - val_loss: 2.6010\n",
            "Epoch 142/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4855 - val_loss: 2.5301\n",
            "Epoch 143/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4696 - val_loss: 2.5429\n",
            "Epoch 144/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4571 - val_loss: 2.6195\n",
            "Epoch 145/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4947 - val_loss: 2.4729\n",
            "Epoch 146/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4337 - val_loss: 2.5412\n",
            "Epoch 147/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.5195 - val_loss: 2.6490\n",
            "Epoch 148/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4578 - val_loss: 2.4967\n",
            "Epoch 149/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4649 - val_loss: 2.6883\n",
            "Epoch 150/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4696 - val_loss: 2.7270\n",
            "Epoch 151/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4960 - val_loss: 2.7660\n",
            "Epoch 152/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4510 - val_loss: 2.6937\n",
            "Epoch 153/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4609 - val_loss: 2.4560\n",
            "Epoch 154/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4204 - val_loss: 2.5022\n",
            "Epoch 155/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4144 - val_loss: 2.4901\n",
            "Epoch 156/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4400 - val_loss: 2.5005\n",
            "Epoch 157/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3948 - val_loss: 2.5479\n",
            "Epoch 158/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4394 - val_loss: 2.5253\n",
            "Epoch 159/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4046 - val_loss: 2.4738\n",
            "Epoch 160/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4105 - val_loss: 2.4846\n",
            "Epoch 161/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4074 - val_loss: 2.6098\n",
            "Epoch 162/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4356 - val_loss: 2.6058\n",
            "Epoch 163/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.4228 - val_loss: 2.5087\n",
            "Epoch 164/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3968 - val_loss: 2.4834\n",
            "Epoch 165/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.4017 - val_loss: 2.5296\n",
            "Epoch 166/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3955 - val_loss: 2.6719\n",
            "Epoch 167/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3434 - val_loss: 2.4162\n",
            "Epoch 168/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3693 - val_loss: 2.5046\n",
            "Epoch 169/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3886 - val_loss: 2.4995\n",
            "Epoch 170/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3569 - val_loss: 2.5005\n",
            "Epoch 171/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3701 - val_loss: 2.4213\n",
            "Epoch 172/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3929 - val_loss: 2.4413\n",
            "Epoch 173/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3417 - val_loss: 2.4767\n",
            "Epoch 174/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3672 - val_loss: 2.5999\n",
            "Epoch 175/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3632 - val_loss: 2.4267\n",
            "Epoch 176/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3587 - val_loss: 2.4398\n",
            "Epoch 177/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3794 - val_loss: 2.4312\n",
            "Epoch 178/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3425 - val_loss: 2.6678\n",
            "Epoch 179/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3342 - val_loss: 2.4000\n",
            "Epoch 180/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3426 - val_loss: 2.5334\n",
            "Epoch 181/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3296 - val_loss: 2.4197\n",
            "Epoch 182/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3581 - val_loss: 2.4296\n",
            "Epoch 183/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3187 - val_loss: 2.4925\n",
            "Epoch 184/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3169 - val_loss: 2.4730\n",
            "Epoch 185/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3027 - val_loss: 2.3888\n",
            "Epoch 186/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2986 - val_loss: 2.4579\n",
            "Epoch 187/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3167 - val_loss: 2.4744\n",
            "Epoch 188/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3268 - val_loss: 2.3660\n",
            "Epoch 189/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3044 - val_loss: 2.4057\n",
            "Epoch 190/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3224 - val_loss: 2.4237\n",
            "Epoch 191/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3334 - val_loss: 2.5765\n",
            "Epoch 192/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3297 - val_loss: 2.4013\n",
            "Epoch 193/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.2816 - val_loss: 2.4260\n",
            "Epoch 194/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.2929 - val_loss: 2.3682\n",
            "Epoch 195/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.2967 - val_loss: 2.5380\n",
            "Epoch 196/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2865 - val_loss: 2.3736\n",
            "Epoch 197/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.2772 - val_loss: 2.4069\n",
            "Epoch 198/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.3062 - val_loss: 2.3283\n",
            "Epoch 199/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2728 - val_loss: 2.3883\n",
            "Epoch 200/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.2539 - val_loss: 2.4304\n",
            "Epoch 201/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.3342 - val_loss: 2.4772\n",
            "Epoch 202/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2625 - val_loss: 2.3344\n",
            "Epoch 203/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2904 - val_loss: 2.3252\n",
            "Epoch 204/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2630 - val_loss: 2.4143\n",
            "Epoch 205/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2561 - val_loss: 2.3402\n",
            "Epoch 206/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2585 - val_loss: 2.3330\n",
            "Epoch 207/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2670 - val_loss: 2.3582\n",
            "Epoch 208/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2596 - val_loss: 2.5345\n",
            "Epoch 209/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2606 - val_loss: 2.3559\n",
            "Epoch 210/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2557 - val_loss: 2.3394\n",
            "Epoch 211/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2327 - val_loss: 2.3716\n",
            "Epoch 212/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2369 - val_loss: 2.3985\n",
            "Epoch 213/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2288 - val_loss: 2.5587\n",
            "Epoch 214/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.2218 - val_loss: 2.4355\n",
            "Epoch 215/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.2308 - val_loss: 2.4082\n",
            "Epoch 216/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2624 - val_loss: 2.3953\n",
            "Epoch 217/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.2324 - val_loss: 2.2988\n",
            "Epoch 218/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2150 - val_loss: 2.3284\n",
            "Epoch 219/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.2303 - val_loss: 2.3396\n",
            "Epoch 220/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.2018 - val_loss: 2.3248\n",
            "Epoch 221/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1899 - val_loss: 2.4375\n",
            "Epoch 222/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2266 - val_loss: 2.4710\n",
            "Epoch 223/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2148 - val_loss: 2.4670\n",
            "Epoch 224/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.1974 - val_loss: 2.3248\n",
            "Epoch 225/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2067 - val_loss: 2.4731\n",
            "Epoch 226/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2210 - val_loss: 2.4021\n",
            "Epoch 227/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2113 - val_loss: 2.2790\n",
            "Epoch 228/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.2457 - val_loss: 2.3875\n",
            "Epoch 229/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1777 - val_loss: 2.4169\n",
            "Epoch 230/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.2179 - val_loss: 2.5261\n",
            "Epoch 231/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1968 - val_loss: 2.4056\n",
            "Epoch 232/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1952 - val_loss: 2.3899\n",
            "Epoch 233/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1640 - val_loss: 2.4930\n",
            "Epoch 234/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1828 - val_loss: 2.4501\n",
            "Epoch 235/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.1886 - val_loss: 2.6361\n",
            "Epoch 236/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1772 - val_loss: 2.4162\n",
            "Epoch 237/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1774 - val_loss: 2.4171\n",
            "Epoch 238/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1640 - val_loss: 2.2531\n",
            "Epoch 239/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1581 - val_loss: 2.2352\n",
            "Epoch 240/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.1820 - val_loss: 2.2774\n",
            "Epoch 241/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.1460 - val_loss: 2.2725\n",
            "Epoch 242/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.2009 - val_loss: 2.3414\n",
            "Epoch 243/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.1617 - val_loss: 2.3275\n",
            "Epoch 244/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.1431 - val_loss: 2.2372\n",
            "Epoch 245/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.1685 - val_loss: 2.2275\n",
            "Epoch 246/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.1503 - val_loss: 2.2733\n",
            "Epoch 247/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1475 - val_loss: 2.2332\n",
            "Epoch 248/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1465 - val_loss: 2.2790\n",
            "Epoch 249/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.1470 - val_loss: 2.3048\n",
            "Epoch 250/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1450 - val_loss: 2.2213\n",
            "Epoch 251/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1465 - val_loss: 2.2576\n",
            "Epoch 252/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.1224 - val_loss: 2.3048\n",
            "Epoch 253/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.1633 - val_loss: 2.2928\n",
            "Epoch 254/1000\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.1402 - val_loss: 2.2243\n",
            "Epoch 255/1000\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 2.1139 - val_loss: 2.2552\n",
            "Epoch 256/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.1349 - val_loss: 2.3005\n",
            "Epoch 257/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1245 - val_loss: 2.2223\n",
            "Epoch 258/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.1086 - val_loss: 2.1941\n",
            "Epoch 259/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.1158 - val_loss: 2.2100\n",
            "Epoch 260/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.1685 - val_loss: 2.3341\n",
            "Epoch 261/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.1262 - val_loss: 2.2661\n",
            "Epoch 262/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.1306 - val_loss: 2.2107\n",
            "Epoch 263/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.1011 - val_loss: 2.2334\n",
            "Epoch 264/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.0948 - val_loss: 2.2519\n",
            "Epoch 265/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1007 - val_loss: 2.2469\n",
            "Epoch 266/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.0952 - val_loss: 2.1605\n",
            "Epoch 267/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1221 - val_loss: 2.1829\n",
            "Epoch 268/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1112 - val_loss: 2.3239\n",
            "Epoch 269/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1118 - val_loss: 2.2051\n",
            "Epoch 270/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1156 - val_loss: 2.2285\n",
            "Epoch 271/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.0788 - val_loss: 2.2760\n",
            "Epoch 272/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.0958 - val_loss: 2.2300\n",
            "Epoch 273/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1085 - val_loss: 2.2037\n",
            "Epoch 274/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.1345 - val_loss: 2.2068\n",
            "Epoch 275/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.0717 - val_loss: 2.1803\n",
            "Epoch 276/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.1135 - val_loss: 2.1520\n",
            "Epoch 277/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.0999 - val_loss: 2.5439\n",
            "Epoch 278/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.0816 - val_loss: 2.2161\n",
            "Epoch 279/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.0634 - val_loss: 2.1540\n",
            "Epoch 280/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.0643 - val_loss: 2.3142\n",
            "Epoch 281/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.0866 - val_loss: 2.2441\n",
            "Epoch 282/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.0686 - val_loss: 2.1831\n",
            "Epoch 283/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.0744 - val_loss: 2.1664\n",
            "Epoch 284/1000\n",
            "40000/40000 [==============================] - 2s 50us/step - loss: 2.0642 - val_loss: 2.2956\n",
            "Epoch 285/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.0508 - val_loss: 2.2036\n",
            "Epoch 286/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.0657 - val_loss: 2.3335\n",
            "Epoch 287/1000\n",
            "40000/40000 [==============================] - 2s 49us/step - loss: 2.0703 - val_loss: 2.2950\n",
            "Epoch 288/1000\n",
            "11000/40000 [=======>......................] - ETA: 1s - loss: 2.0776Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu12Jq6fC5XQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4fzo8kb9fMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}